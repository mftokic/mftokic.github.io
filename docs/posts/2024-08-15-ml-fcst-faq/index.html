<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.45">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mike Tokic">
<meta name="dcterms.date" content="2024-08-15">
<meta name="description" content="Straightforward answers to all of your ML forecast questions">

<title>FAQ on Machine Learning Forecasting – Thoughts on Things</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LPFFKTCPJX"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LPFFKTCPJX', { 'anonymize_ip': true});
</script>
<meta name="quarto:status" content="draft">


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Thoughts on Things - FAQ on Machine Learning Forecasting">
<meta property="og:description" content="Straightforward answers to all of your ML forecast questions">
<meta property="og:image" content="https://mftokic.github.io/posts/2024-08-15-ml-fcst-faq/image.png">
<meta property="og:site_name" content="Thoughts on Things">
<meta name="twitter:title" content="Thoughts on Things - FAQ on Machine Learning Forecasting">
<meta name="twitter:description" content="Straightforward answers to all of your ML forecast questions">
<meta name="twitter:image" content="https://mftokic.github.io/posts/2024-08-15-ml-fcst-faq/image.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Thoughts on Things</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../start_here.html"> 
<span class="menu-text">Start Here</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mftokic"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">FAQ on Machine Learning Forecasting</h1>
                  <div>
        <div class="description">
          Straightforward answers to all of your ML forecast questions
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">finance</div>
                <div class="quarto-category">machine-learning</div>
                <div class="quarto-category">forecasting</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Mike Tokic </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 15, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Over the last few years I’ve presented to hundreds of people outside of Microsoft around how we approach machine learning (ML) forecasting within Microsoft finance. A lot of great questions were asked during those conversations. With many overlaps around common themes. In this post I want to highlight some of the most commonly asked questions and my take on answering them. Hopefully this can be a quick reference for anyone ML curious or want to deepen the ML work being done on their teams. Use the table of contents to skip around to the sections you’re most interested in. If there are any topics missing please reach out to me via <a href="https://www.linkedin.com/in/michaeltokic/">LinkedIn</a> and I will continue to update this post.</p>
<section id="toc" class="level2">
<h2 class="anchored" data-anchor-id="toc">FAQ Table of Contents</h2>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data"><a href="#data">Data</a></h3>
<ul>
<li><a href="#historical-data">Getting high quality historical data</a></li>
<li><a href="#third-party-data">Using third party data</a></li>
<li><a href="#one-time-events">New info not found in the training data, one time events</a></li>
<li><a href="#outliers">Handling outliers</a></li>
</ul>
</section>
<section id="technical" class="level3">
<h3 class="anchored" data-anchor-id="technical"><a href="#technical">Technical</a></h3>
<ul>
<li><a href="#black-box">Interpreting the black box</a></li>
<li><a href="#models">What models to use, should we use deep learning</a></li>
<li><a href="#language">What programming language or framework to use</a></li>
<li><a href="#llm">Using large language models like ChatGPT to forecast</a></li>
<li><a href="#accuracy">What level of accuracy is good</a></li>
</ul>
</section>
<section id="humans" class="level3">
<h3 class="anchored" data-anchor-id="humans"><a href="#humans">Humans</a></h3>
<ul>
<li><a href="#accountability">How to make forecast owners accountable for the ML number</a></li>
<li><a href="#trust">Building Trust in the ML forecast</a></li>
<li><a href="#ownership">Who owns the ML creation process</a></li>
<li><a href="#starting">How to get started with ML</a></li>
<li><a href="#migrating">Going from ML as a triangulation point to replacing manual human forecasts</a></li>
<li><a href="#talent">Building data science talent in finance</a></li>
</ul>
</section>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<section id="historical-data" class="level3">
<h3 class="anchored" data-anchor-id="historical-data">Getting high quality historical data</h3>
<p><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage in, garbage out</a>. That’s probably the most common saying in the world of ML. If you cannot get high quality historical data, then there is no easy way to produce an accurate ML forecast. You can’t work your way around noisy or incomplete data. If your data is messy, hard to find, and comes from 10 different systems, then ML is not something you should be worried about. Fix your data first, then focus on using that data in combination with other things like ML. A nice bow on top of a pile of crap is still a pile of crap. Fix your data first, then focus on ML after.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="third-party-data" class="level3">
<h3 class="anchored" data-anchor-id="third-party-data">Using third party data</h3>
<p>Your company’s business is most likely impacted by greater market forces outside of your control. For example the health of the economy or how much money customers have to spend. Adding data from outside of your company (third party data) as features in your ML models is a good way to improve forecast accuracy, while also being able to describe what outside forces impact your business the most. Some data is freely available, while others have to be paid for. What data you use is up to your domain knowledge of your business.</p>
<p>Free Data</p>
<ul>
<li><a href="https://fred.stlouisfed.org/">FRED</a></li>
<li><a href="https://data.worldbank.org/">World Bank</a></li>
<li><a href="https://data.imf.org/?sk=388dfa60-1d26-4ade-b505-a05a558d9a42">International Monetary Fund</a></li>
<li><a href="https://data.un.org/">United Nations</a></li>
<li><a href="https://trends.google.com/trends/">Google Trends</a></li>
</ul>
<p>Paid Data</p>
<ul>
<li><a href="https://www.idc.com/data-analytics">IDC</a></li>
<li><a href="https://tradingeconomics.com/indicators">Trading Economics</a></li>
</ul>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="one-time-events" class="level3">
<h3 class="anchored" data-anchor-id="one-time-events">New info not found in training data and one time events</h3>
<p>If you are changing the price of your product in three months, this is most likely going to impact your future revenue forecast. But if you have never changed the price of your product before, then a ML model cannot learn from that information. For a model to learn from one time events, it needs to be present in the historical data a model is trained on. <a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The future must always learn from the past</a>.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="outliers" class="level3">
<h3 class="anchored" data-anchor-id="outliers">Handling Outliers</h3>
<p><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">Outliers</a> in your data can have a bad impact on your future forecast. It can hurt accuracy or give false signals of the future. There are many ways to deal with outliers. The easiest way is to use statistical methods to identify and remove them. Treating them as a missing value you can then replace. Sometimes outliers are more subtle, and take a trained eye to spot them. This is where the <a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">domain expertise</a> of a person comes into play.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
</section>
<section id="technical" class="level2">
<h2 class="anchored" data-anchor-id="technical">Technical</h2>
<section id="black-box" class="level3">
<h3 class="anchored" data-anchor-id="black-box">Interpreting the black box</h3>
<p>This one is a toughie. When a person creates a forecast manually, most often using excel, someone else can come into that financial model and trace cell by cell exactly what’s going on. Going from input data, to assumptions, to the formulas that create the final output. This is the kind of exactitude that allows accountants to sleep peacefully at night. Everything is in order and everything is perfectly understood. But we are not accountants. This is finance. We have to make calls about the future that are uncertain. We can never have 100% certainty that something is going to happen. If that’s the case then your company is doing something illegal. Get out now!</p>
<p>The biggest paradigm shift someone has to make with machine learning is giving up this total control of the forecast. And in essence take a <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/#leap-of-faith">leap of faith</a>. Machine learning models are enigmas. Sometimes akin to magic. The cannot be perfectly understood because the capture non-linear relationships in data that a human never could. That’s why we have them, because they can work better and faster than our human brains in some tasks.</p>
<p>There are ways to understand these models, but they cannot be perfectly audited like a manual forecast done in excel. Instead they have to be interrogated. Not like a criminal wanted for war crimes but more like a therapist talking to their patient. There is no way to know exactly what’s going on inside of their patients mind. But they can start to ask questions that can give clues into what’s going on and see why the person has past decisions in their life.</p>
<p>The best resource I know on explaining ML models is <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a> by Christoph Molnar. Here’s a quick overview of the method’s described in the book.</p>
<ul>
<li><strong>Model Specific:</strong> These are models like linear regression or a single decision tree where we can see exactly what’s going on under the hood. The model structure is more like an excel formula we can trace step by step. But because they are easy to explain, they are simple in nature and may not produce the most accurate forecast. That is the tradeoff between having a forecast that can be easily explained versus having a forecast that is the most accurate. The more accurate the forecast, the more likely you cannot explain it perfectly.</li>
<li><strong>Model Agnostic:</strong> For more advanced models like gradient boosted trees and deep learning, we can use methods that approximate what’s going on under the hood of a complex model. This is when we have to act like a therapist and start asking questions to our model and see what answers it gives back. There are two ways of doing this.
<ul>
<li><strong>Global Interpretability:</strong> This uses methods that can see overall what’s impacting the model the most. For example you can see what input variable (or feature) is the most important in the model overall.<br>
</li>
<li><strong>Local Interpretability:</strong> This uses methods to see what’s going on for each individual forecast data point. For example you can see for a specific future forecast what’s impact that number the most.</li>
</ul></li>
</ul>
<p>The last thought I’d leave you with is this. Have you ever not used ChatGPT because you couldn’t get an explanation of its answer? For example maybe you asked it to help you write some excel formulas to format dates. Do you trust the output it gave you because the excel formula was correct or because it could tell you exactly how it came to that conclusion? What if the explanation it gave was made up or a hallucination? If the excel formula is correct you would still use it right? Even the CEO of OpenAI, Sam Altman, cannot explain how models like GPT-4 think under the hood. But hey, ChatGPT was still the fastest growing product of all time. Sometimes imperfect interpretability is ok. But maybe your CEO is demanding an explanation of the forecast numbers, so this is <a href="https://mftokic.github.io/posts/2023-02-11-three-levels-of-ml-adoption/">still a hard problem to solve in finance</a>.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">What models to use, should we use deep learning</h3>
<p>People are always attracted to the hot new thing, and I can’t blame them. New is exciting. When it comes to ML forecasting, new isn’t always better. The newest trend in ML is all about deep learning. Or models that can mimic the human brain. While they work really well for things like analyzing photos and text, using them on tabular data (aka excel data) hasn’t always worked out well. That’s why I <a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">recommend using deep learning last</a>.</p>
<p>Here are the models to use first, then you can always resort to deep learning if need be.</p>
<ul>
<li><strong>Univariate Models</strong>: These are the simplest forecasting models. Since they only need one variable, hence the name univariate. If you want to forecast revenue, then you only need historical revenue and you’re off and running. They run extremely fast and can scale to millions of data combinations without spending too much on cloud compute. Here are a few popular ones.
<ul>
<li><strong>ARIMA</strong>: An ARIMA (AutoRegressive Integrated Moving Average) model predicts future values in a time series by combining differencing (modeling the difference between periods), autoregression (using past values), and moving averages (using past forecast errors). It’s the most common univariate model in the forecasting game.</li>
<li><strong>Exponential Smoothing</strong>: Forecasts future values in a time series by applying decreasingly weighted averages of past observations, giving more importance to recent data points to capture trends and seasonal patterns.</li>
<li><strong>Seasonal Naive</strong>: Predicts future values by simply repeating the observations from the same season of the previous period, assuming that future patterns will mimic past seasonal cycles. Don’t sleep on this one! You’d be surprised how often it comes in handy as a good benchmarking model to compare with more complicated models.</li>
</ul></li>
<li><strong>Traditional ML Models</strong>: After trying univariate models, it’s time to try more traditional machine learning models. These are models built specifically for tabular data, or data that can live in a SQL table or excel spreadsheet. These models are multivariate, which allow them to incorporate outside variables as features to improve their forecast accuracy. They require more handling than a model like ARIMA, since they need <a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">feature engineering</a> and proper <a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">time series cross-validation</a>. Multivariate models can also learn across multiple time series at the same time, instead of being trained on just a single time series like a univariate model. Here are a few common multivariate models.
<ul>
<li><strong>Linear Regression</strong>: Predicts future values by fitting a line to the historical data, where the line represents the relationship between the dependent variable and one or more independent variables.</li>
<li><strong>XGBoost</strong>: Predicts future values using an ensemble of decision trees, boosting their performance by iteratively correcting errors from previous trees, resulting in a highly accurate and robust prediction model.</li>
<li><strong>Cubist</strong>: Predicts future values by combining decision trees with linear regression models, creating rule-based predictions that incorporate linear relationships within each segment of the data for greater accuracy.</li>
</ul></li>
</ul>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="language" class="level3">
<h3 class="anchored" data-anchor-id="language">What programming language or framework to use</h3>
<p>Should I use python? But what if I learned R in my statistics class? What about stata or good ole javascript? Ask 10 data scientists what programming language to use and you’ll probably get 10 different answers. There is no right answer. It’s kind of like arguing what hammer to use when building a house. Shouldn’t we just be worried about getting the house built? And make sure we don’t screw it up?</p>
<p>Here is my take on the ML language wars. You should use both, python and R. Different languages offer different things, and depending on the task you might want to use one over the other. Often it’ll boil down to specific open source software that might only be available in one language but not the other. So over the course of a long data career it’s probably a good idea to be competent at both.</p>
<p>With that said, if you could only learn one programming language, learn python. That’ll get you the farthest the fastest in terms of useful knowledge to get building. I think in a few years these debates will go away, because large language models (LLM) will come and save the day. Imagine writing code in your favorite language, using the packages you like, and then have a LLM take your code and translate it into blazing fast machine code that runs like a race car. So it won’t matter if you only know one language or the other. That’s where I hope we’re headed.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="llm" class="level3">
<h3 class="anchored" data-anchor-id="llm">Using large language models like ChatGPT to forecast</h3>
<p>With the explosion of large language models (LLM) that can do everything from tell dad jokes to write production grade code, can’t we just offload all forecasting work to them? In essence you could, but I think it’s kind of overkill and leads a lot to be desired. LLMs take in text, and spit out text. They are good with words, but not that good with numbers. They can’t perform on par with a calculator, because that’s not how they were designed. So you can’t just copy a table from excel, give it to ChatGPT, and hope to get next quarters revenue forecast. It might give it to you, but it won’t be a good forecast. It might even make something up.</p>
<p>The more sensible route to take is to have the LLM write code that can create forecast models and have it execute it for you. For example use the code interpreter feature in ChatGPT to have it take your uploaded CSV file and execute a bunch of python code against it to get a final forecast. This kind of workflow might be good for initial exploration, but it shouldn’t be used in a production setting where you need an updated forecast each month. It’s kind of like needing a place to sleep and each night you build a new house from scratch, only sleep there one night, then the next night build another house from scratch. Having LLMs produce code on the fly each time can lead to inconsistent results that may not be reproducible when you ask ChatGPT to do it again. You could take the code from the first forecast iteration, save it, and either run it yourself each time or give it to ChatGPT as a prompt. But even then you are still missing out. Some automated forecasting packages, like the one I own called <a href="https://microsoft.github.io/finnts/index.html">finnts</a> have over 10,000 lines of code. So a LLM will most likely not be writing that much code to answer one prompt, and if they did having you trying to save and manage that code is out of the question.</p>
<p>I think LLMs can still have some part in the forecasting process. I think they are useful before and after the actual model training is done. For example you can have code interpreter analyze your data for things like outliers or help in running correlation analysis to see what variables could help improve your forecast accuracy. Then you will take those learnings and run the forecast outside of the LLM environment, or you could have the LLM call an outside function to kick off a forecast. This is called “function calling”, where a LLM can use an outside tool (most often calling an API via code) that can accomplish the task a LLM cannot (like getting the current weather). LLMs can then be used after the forecast process is ran to then analyze the final forecast outputs. Tools like code interpreter can make charts and analyze historical back testing accuracy.</p>
<p>Maybe in the future the LLM can help explain how the final forecast was created, or better yet answer questions about forecast variance once actuals land in the future. But using it to actually create predictions or train models itself is still a tall order. With that said there are <a href="https://docs.nixtla.io/">new time series specific LLMs</a> that are being released, so this is an exciting area to watch closely.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="accuracy" class="level3">
<h3 class="anchored" data-anchor-id="accuracy">What level of accuracy is good</h3>
<p>There is no right answer. It all depends on the specific data you are using and how it compares to non ML approaches you have done previously.</p>
<p>A common metric in time series forecasting is the MAPE error metric. MAPE stands for mean absolute percentage error. This is very similar to variance to forecast percent metrics you might already use. Think of it as the average percent error (as an absolute value) across every forecasted data point. There are plenty of other metrics out there, but MAPE is a good one since it’s not dependant on scale and percents are easy for anyone to wrap their head around.</p>
<p>A MAPE of 5% means that on average, your forecast is off plus or minus 5%. So the closer to zero the better. If you ask any finance person what kind of MAPE they want for their forecast, almost all of them will say less than 1%. Or more than 99% accuracy. Think of accuracy as the inverse of MAPE. Maybe the ML forecast has a MAPE of 10%, but your previous manual excel model ended up having a 20% MAPE. The ML forecast has a 50% reduction in forecast error, even though it’s still in the double digits. So evaluating ML is always relative to what kind of performance you got with other forecast methods probably done in excel.</p>
<p>With that said, here are some rules of thumb I use when running my own ML forecasts.</p>
<ul>
<li><strong>Daily and Weekly Data</strong>: Less than a 10% MAPE is terrific. But even MAPEs as high as 30% are ok, because often we might sum up a daily forecast to a monthly or quarterly level. And when evaluated at that aggregate level you may start to have drastically improved MAPEs.</li>
<li><strong>Monthly, Quarterly, Yearly Data</strong>: There are a few levels of accuracy that I think are good at this level. Again, it’s all relative to what kind of performance you had before using ML.
<ul>
<li>Less than a 5% MAPE is good</li>
<li>Less than a 3% MAPE is great</li>
<li>Less than a 1% MAPE is amazing</li>
</ul></li>
</ul>
<p>Even going from a 3% MAPE to a 2% MAPE is a big achievement. Because it’s a lot harder to do that than to go from a 15% MAPE to a 10% MAPE. It’s still the same level of improvement but once you get closer to zero the MAPE improvements seem to happen on a log scale. Where each percentage point you reduce continues to get harder as you get closer to zero.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
</section>
<section id="humans" class="level2">
<h2 class="anchored" data-anchor-id="humans">Humans</h2>
<section id="accountability" class="level3">
<h3 class="anchored" data-anchor-id="accountability">How to make forecast owners accountable for the ML number</h3>
<p>Having a ML model automate your forecast process is great, until you have to tell your CFO why your quarterly forecast is off by xyz%. “It was ML’s fault” is not the right answer. But it’s hard for a human to be on the hook for work that a machine did for them. Maybe the ML forecast came from another engineering team, so the final owner of the forecast maybe had no part in creating the forecast. This can make accountability hard.</p>
<p>In order to get people on board with transitioning more of their work to ML, you need senior leadership buy in. People at the top need to be invested in the promise of ML and the tradeoffs it might provide. Since you cannot audit a ML forecast like you can with an excel model (tracing cell by cell) there is an essential leap of faith that has to happen.</p>
<p>In addition to having senior leadership buy in to improve accountability, being able to adjust the output from ML can also help. Financial analysts can impart their domain expertise about their business by making small manual adjustments to the ML forecast. That way ML can get you 80% of the way to a completed forecast, and a human might make adjustments on that final 20% to finalize the forecast. Having the forecast owners be “humans in the loop” of a ML process adds a sense of ownership, which can then improve accountability.</p>
<p>A final way to improve accountability is through the <a href="https://insidebe.com/articles/the-ikea-effect/">Ikea effect</a>. Which states that we value things more if we are involved in making them. The best way for this to work is if the final forecast owners create their own ML forecast through self-serve tools that abstract away the complex of ML and allows analysts to upload data and get back forecasts with a few clicks of their mouse. This is exactly <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">what we did in Microsoft finance</a> and it has worked out well so far.</p>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="trust" class="level3">
<h3 class="anchored" data-anchor-id="trust">Building Trust in the ML forecast</h3>
<p>Building trust in the ML forecast is the hardest part of using ML. There are three ways that have worked well in helping non-technical financial forecast owners warm up to and fully transition to using ML to forecast.</p>
<ul>
<li><strong>Historical Accuracy</strong>: The best way to get someone on board with a forecast into the future is to show them how well a similar forecast has performed in the past. It’s not a perfect proxy for future performance but gives the end user a good idea of how well a ML model is performing. Common performance metrics to use are <a href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error">MAPE</a> (mean absolute percentage error) and <a href="https://en.wikipedia.org/wiki/Root_mean_square_deviation">RMSE</a> (root mean squared error). MAPE is similar to existing variance to forecast calcs already done by financial analysts so it’s a good error metric to convey past performance. When calculating historical performance, aka back testing, it’s a good idea to create hypothetical forecasts for the most recent periods of your data. Making sure you cover enough historical time to ensure your ML model is robust. For example with a monthly forecast. You might want to just forecast the next 3 months into the future. If you have 5+ years of historical data you could have 4 historical back tests where you train a model and produce a 3 month forecast for each of the last 4 quarters in your historical data.</li>
<li><strong>Prediction Intervals</strong>: Understanding the uncertainty of the future forecast can also help build trust. Think of prediction intervals as upper and lower bounds of the future forecast that convey a certain percent of probability that the future value will land in between these bounds. Common prediction intervals are 80% and 95%. For example, you might have a future forecast of $100 for next month, with a 80% prediction interval of $80 and $120. This means there is an 80% chance that the actual value of next month will be between $80 and $120. So the tighter the prediction interval, the better. Having an prediction interval that’s +-5% of the forecasted value gives more comfort to the end user than one that’s +-30%. Just make sure that the end user of the forecast knows that those upper and lower bounds are not neccesarally a “bull case” and “bear case” of what could happen in the future, like they might be used to in other financial modelling. But instead just a way to capture the uncertainty of the future prediction.</li>
<li><strong>Interpretability</strong>: Finally another good way to build trust is being able to explain how a future ML forecast was created. You will not be able to perfectly explain it like you can an excel model (by tracing through it cell by cell). But you can use <a href="#black-box">methods</a> to poke and prod a model to see what might be going on under the hood.</li>
</ul>
<p><a href="#toc">Back to Table of Contents</a></p>
</section>
<section id="ownership" class="level3">
<h3 class="anchored" data-anchor-id="ownership">Who owns the ML creation process</h3>
</section>
<section id="starting" class="level3">
<h3 class="anchored" data-anchor-id="starting">How to get started with ML</h3>
</section>
<section id="migrating" class="level3">
<h3 class="anchored" data-anchor-id="migrating">Going from ML as a triangulation point to replacing manual human forecasts</h3>
</section>
<section id="talent" class="level3">
<h3 class="anchored" data-anchor-id="talent">Building data science talent in finance</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mftokic\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>