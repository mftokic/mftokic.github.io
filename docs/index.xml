<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Thoughts on Things</title>
<link>https://mftokic.github.io/</link>
<atom:link href="https://mftokic.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>A collection of thoughts on things from the mind of Mike Tokic</description>
<generator>quarto-1.5.57</generator>
<lastBuildDate>Sun, 01 Dec 2024 08:00:00 GMT</lastBuildDate>
<item>
  <title>November Learnings</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-12-01-november-learnings/</link>
  <description><![CDATA[ 





<p>I love reading books, watching YouTube videos, listening to podcasts, you name it. Anything learning related is my jam. But I recently realized that if I don’t take notes on what I’m learning, I will probably forget everything. Now when I hear something interesting, I write it down in an Apple note for that month. Below are some of the learnings I jotted down in November, summarized by ChatGPT. I hope you find them as interesting as I did.</p>
<section id="personal-growth-and-mindset" class="level3">
<h3 class="anchored" data-anchor-id="personal-growth-and-mindset">Personal Growth and Mindset</h3>
<ul>
<li><strong>Happiness and Presence</strong>: True happiness comes from being present and avoiding overthinking. Expectations play a big role in happiness: reality minus expectations equals happiness.</li>
<li><strong>Action and Results</strong>: Be impatient with actions but patient with results. Start quickly, but allow time for outcomes. Enthusiasm and belief are competitive advantages. Avoid the vicious cycle of inaction fueled by doubt.</li>
<li><strong>Overthinking</strong>: Rumination is the #1 symptom of depression. Action is a better way to change your thoughts than overthinking.</li>
<li><strong>Quotes on Mindset</strong>:
<ul>
<li>“Knowledge is knowing what to do; wisdom is doing it.”</li>
<li>“Cynics get to be right, optimists get to be rich.”</li>
<li>“Ask a better question, get a better answer.”</li>
<li>“At the end of the day you’re going to feel some type of way. So why not feel unbeatable. Why not feel untouchable. Why not feel like the best to ever do it.”</li>
</ul></li>
</ul>
</section>
<section id="productivity-and-decision-making" class="level3">
<h3 class="anchored" data-anchor-id="productivity-and-decision-making">Productivity and Decision-Making</h3>
<ul>
<li><strong>Action Frameworks</strong>:
<ul>
<li>Time between deciding and acting defines success.</li>
<li>Be clear on priorities: what you choose to work on is more important than how hard you work.</li>
<li>Use tools like the Dickens Method to evaluate how today’s actions affect your future.</li>
</ul></li>
<li><strong>Worry Management</strong>: Schedule a time to worry instead of letting it linger. Outside of that window, maintain a zero-worry mindset.</li>
<li><strong>Teams and Companies</strong>: Companies should be viewed as sports teams, not families—performance matters. Be clear about whether a role requires a commando (startup mindset), soldier (scaling), or policeman (stability).</li>
</ul>
</section>
<section id="business-and-sales" class="level3">
<h3 class="anchored" data-anchor-id="business-and-sales">Business and Sales</h3>
<ul>
<li><strong>Product-Market Fit</strong>:
<ul>
<li>Before product-market fit: founders must engage directly with customers in unscalable ways.</li>
<li>After product-market fit: scale with sales staff and established processes.</li>
</ul></li>
<li><strong>Sales Approach</strong>:
<ul>
<li>Use the problem-solution-specifics framework. If the customer disagrees about the problem, drop them.</li>
<li>“Reality vs.&nbsp;narrative” moments are key opportunities for emerging tech.</li>
</ul></li>
<li><strong>Wealth and Risk</strong>:
<ul>
<li>Wealth is a byproduct of knowledge.</li>
<li>Risk is what remains after considering every possible variable.</li>
<li>“Survive” is the golden rule for emerging technologies.</li>
</ul></li>
</ul>
</section>
<section id="society-and-systems" class="level3">
<h3 class="anchored" data-anchor-id="society-and-systems">Society and Systems</h3>
<ul>
<li><strong>Social Observations</strong>:
<ul>
<li>Older industries prioritize regulation capture and splitting spoils over innovation.</li>
<li>Traditions can empower tyranny when unquestioned.</li>
</ul></li>
<li><strong>Homelessness and Addiction</strong>:
<ul>
<li>Addiction and trauma are major causes of death for homeless individuals. Programs like Haven for Hope in San Antonio show promise in recovery-based justice systems.</li>
<li>Fentanyl is a growing public health crisis, being 50x more addictive than heroin.</li>
</ul></li>
<li><strong>Economic Realities</strong>:
<ul>
<li>78% of Americans live paycheck to paycheck.</li>
<li>The first 15 years of mortgage payments largely benefit banks, not homeowners.</li>
</ul></li>
</ul>
</section>
<section id="storytelling-and-communication" class="level3">
<h3 class="anchored" data-anchor-id="storytelling-and-communication">Storytelling and Communication</h3>
<ul>
<li><strong>Power of Stories</strong>:
<ul>
<li>Stories connect human brains like APIs. They involve intention, obstacle, and stakes.</li>
<li>The best podcasters are “vibe architects,” creating environments that feel like casual, engaging conversations.</li>
<li>Great tweets follow principles of truth, novelty, and conciseness while being opinionated.</li>
</ul></li>
<li><strong>Music and Stories</strong>: Both resonate emotionally and inspire action.</li>
</ul>
</section>
<section id="practical-knowledge-and-insights" class="level3">
<h3 class="anchored" data-anchor-id="practical-knowledge-and-insights">Practical Knowledge and Insights</h3>
<ul>
<li><strong>General Insights</strong>:
<ul>
<li>Hanlon’s Razor: Never attribute to malice what can be explained by incompetence.</li>
<li>Recruiting agencies charge ~25% of the first-year salary for hires.</li>
<li>Warren Buffet owns more treasury bills than the U.S. government.</li>
<li>Success is a window (external factors), and failure is a mirror (personal responsibility).</li>
</ul></li>
<li><strong>Teaching and Learning</strong>: Computer literacy has untapped potential. Teaching AI-based math instead of manual long division could redefine education.</li>
</ul>
</section>
<section id="miscellaneous-wisdom" class="level3">
<h3 class="anchored" data-anchor-id="miscellaneous-wisdom">Miscellaneous Wisdom</h3>
<ul>
<li>“Tradition is the crown of the tyrant.”</li>
<li>“The larger the group, the worse the conversation.”</li>
<li>“Trying to think your way out of overthinking is like sniffing your way out of a cocaine addiction.”</li>
<li>“Life without love is the worst prison of all.”</li>
<li>“Make your life your hobbies, but don’t make your hobbies your job.”</li>
</ul>


</section>

 ]]></description>
  <category>life</category>
  <category>learning</category>
  <guid>https://mftokic.github.io/posts/2024-12-01-november-learnings/</guid>
  <pubDate>Sun, 01 Dec 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-12-01-november-learnings/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>DIY Ozempic For 90% Less Cost</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-11-27-diy-ozempic/</link>
  <description><![CDATA[ 





<p><em>I’m not a doctor, I don’t play one on TV. This is not health advice. Make your own damn decisions.</em></p>
<p>It’s the day before Thanksgiving. Or as I like to think of it, the day before the month+ holiday eating binge. While it truly is the most wonderful time of the year to eat, it’s not the most healthy. I think everything should be moderation, including moderation. So I like to go nuts myself during this time of year and eat whatever. For most American’s though, going nuts on food for a month straight is not a good idea. Most are obese, and have been that way for decades.</p>
<p>Thankfully new weight loss medicines like Ozempic have risen in popularity over the last few years. These drugs contain a hormone called GLP-1. Which is something your body produces naturally. It’s what makes you feel full after eating a meal. If your body consumes this hormone from Ozempic, it will naturally make you feel full quicker. Which makes you less hungry. Which makes you eat less. Causing you to lose weight. Seems like a miracle drug right! Unfortunately <a href="https://tim.blog/2024/02/02/no-biological-free-lunches/">there are no free lunches</a> in the world of biology. It always comes with a catch. For drugs like Ozempic the catch has to do with it’s price ($1,000 a month) and <a href="https://www.healthline.com/health/drugs/ozempic-side-effects#long-term-side-effects">potential impact on major organs</a> like your thyroid, pancreas, and heart. But if you’re 100 pounds overweight, your organs are already suffering, so taking the drug knowing the tradeoffs is probably worth the risk. Being overweight is bad, mmmk?</p>
<p>The rise in these drugs has definitely caught my attention, so I’ve been studying them closer. They have the potential to not just make people more healthy, but their downstream impacts can be enormous. Planes may not need as much fuel on flights, because people onboard will weigh less. McDonald’s stock might drop 50% because people aren’t impulsively buying milkshakes after work each day. Even gyms could close down, because people can now look good while only taking a pill/shot versus doing 45 min on the stairmaster every day. There will be countless effects. Both good and bad.</p>
<p>What if you could get all of the good effects from Ozempic without having to pay an arm and a leg while also avoiding the harmful side effects? I think I’ve come across a combination that will naturally produce more GLP-1 in your body, while also being 1/10th the price of Ozempic. Here is the stack.</p>
<ol type="1">
<li><a href="https://www.amazon.com/Supergut-Prebiotic-Replacement-Strawberry-servings/dp/B0C645Q2CT/ref=sr_1_4_pp?crid=23XDI3ALKQLWE&amp;dib=eyJ2IjoiMSJ9.ftkuxSBzIaWukfVtnXPvZqBYlET7P_DPpqUuEN5VnUiOlBxfOMzcgkMiL86iJAQ0GeA0vssfvxntIN3Y-jpq2Jr_foimcrO1orPTmc26vPj0zWYqPcTnejj0MwKQICLXWiwlEJSfJtTbo5Q2ENGCwCDK4rtNaAjM9UFz9e_ZJNsryI19XvCxIOYsn05ghGOoAHhr4dXeYIZOebY6ufrQyjSfcTU86deki-ovxQBnhDJTQFcD9aEjuI9cMrhEkIUFg-tKC7DY1nrwm6puUBFgl8nXXy17KZ_zWO8J3keUr8A.RYEHioYWLX2J2QAdYpL0AlnSLvNF7ys-Tw_dT4tW3QA&amp;dib_tag=se&amp;keywords=supergut&amp;qid=1732722580&amp;s=hpc&amp;sprefix=supergut%2Chpc%2C177&amp;sr=1-4">Prebiotic Shakes by Supergut</a></li>
<li><a href="https://www.amazon.com/dp/B0CY3VZDYP?ref=nb_sb_ss_w_as-reorder_k0_1_8&amp;amp=&amp;crid=2T0LC4RNRX9EX&amp;amp=&amp;sprefix=pendulum">GLP-1 Probiotic by Pendulum</a></li>
</ol>
<p>I’ve written about Supergut in a <a href="https://mftokic.github.io/posts/2024-11-15-hacking-blood-sugar/">previous post</a>. It’s a fiber supplement that contains prebiotic fiber that has been proven to stimulate the release of GLP-1 in your gut. Pendulum is a company specializing in supplements for your gut microbiome. Their GLP-1 probiotic contains living bacteria that creates the precursors to GLP-1. I first learned about Pendulum from <a href="https://www.kevinrose.com/p/a-natural-alternative-to-glp-1-drugs">Kevin Rose</a>, and the science behind it looks legit.</p>
<p>I think the combination of both could be a game changer. The prebiotic fiber from Supergut will help give your microbiome the food it needs to thrive. And the probiotics from Pendulum will help develop the right strains of bacteria in your gut that help produce more GLP-1. This one two punch could be very powerful. I don’t think they’ve been studied in combination before, so this could definitely be some bro science, but my research so far tells me it’s a good combination.</p>
<p>These two products combined cost around $100 a month, compared to $1,000 for Ozempic. So you don’t have much to lose by trying these products. At a minumum your bathroom visits will become 10x more productive and your microbiome will be better off. Why not try it and see how it might help you fight the good fight during this upcoming season of countless food temptations?</p>



 ]]></description>
  <category>life</category>
  <category>health</category>
  <guid>https://mftokic.github.io/posts/2024-11-27-diy-ozempic/</guid>
  <pubDate>Wed, 27 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-11-27-diy-ozempic/image.png" medium="image" type="image/png" height="145" width="144"/>
</item>
<item>
  <title>Exploratory Data Analysis: Missing Data and Outliers</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/">exploratory data analysis chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2024-11-26-ts-fundamentals-missing-outliers.ipynb">python code used in this post here.</a></em></p>
<section id="garbage-in-garbage-out" class="level3">
<h3 class="anchored" data-anchor-id="garbage-in-garbage-out">Garbage In, Garbage Out</h3>
<p>Having quality data helps produce quality forecasts. There’s an old saying in the data universe, <a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">garbage in, garbage out</a>. When your data is bad, you will get bad outcomes. The presence of missing data and outliers can reduce forecast accuracy. Which is a shame because they are so easy to fix.</p>
</section>
<section id="missing-data" class="level3">
<h3 class="anchored" data-anchor-id="missing-data">Missing Data</h3>
<p>Time series are unique from other types of data because they have a built in order, based on time. For this to work it’s important that each period of time is represented in the data. For example with a monthly data set spanning five years, we want there to be no missing value for any of the month’s during those five years. Having missing values creates challenges when trying to analyze and model the data, since most statistical and machine learning techniques assume all available time periods are present in the data. This leads to reduced forecast accuracy.</p>
<p>There are a few ways data can be missing in a time series.</p>
<ol type="1">
<li><strong>Missing Completely at Random (MCAR)</strong>
<ul>
<li>Meaning: Data is missing for no specific reason, it’s just random. The missing data doesn’t depend on any pattern or the actual value that’s missing.</li>
<li>Example: A sensor that records the temperature randomly fails to record a value now and then.</li>
</ul></li>
<li><strong>Missing at Random (MAR)</strong>
<ul>
<li>Meaning: Data is missing for a reason that depends on other information you already have, but not on the missing values themselves. You can explain the missing data using the rest of the data.</li>
<li>Example: A temperature sensor is more likely to fail during hot weather, but the failure doesn’t depend on the exact temperature value it would have recorded.</li>
</ul></li>
<li><strong>Not Missing at Random (NMAR)</strong>
<ul>
<li>Meaning: Data is missing because of the value itself, it’s missing for a reason related to what’s not recorded. The missing data is biased, and you need to understand why it’s missing to deal with it.</li>
<li>Example: A temperature sensor doesn’t record very high temperatures because it shuts down when it overheats.</li>
</ul></li>
<li><strong>Mixed Mechanisms</strong>
<ul>
<li>Meaning: Missing data can be a mix of random, explainable, and biased causes.</li>
<li>Example: Some values are randomly missed due to glitches (MCAR), some during maintenance periods (MAR), and others during extreme weather (NMAR).</li>
</ul></li>
</ol>
<p>Most data I deal with is some combination of missing completely at random or not missing at random. For example there might be a months worth of revenue data missing in a system due to issues with the company’s enterprise resource planning (ERP) system. So that data is missing completely at random. A system error created the missing data. Another example is having monthly revenue for three products, where two of the products have five full years of revenue data and the other only has the last three years of data. This is due to that third product being newer and only being sold in the last three years. So that data is not missing at random but is due to a specific reason.</p>
<p>For the first two types of missing data (#1 and #2 in the list), it’s a good idea to use some sort of simple statistical model to interpolate what the missing value should be based on actual values on either side of the data. Below is a monthly time series from our example data. I removed a few months at random. We can use a statistical model that breaks down the time series by trend, seasonality, and residual. Then predict what the missing value should be based on the existing trend and seasonal components.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/chart1.png" class="img-fluid"></p>
<p><img src="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/chart2.png" class="img-fluid"></p>
<p>For the third type of missing data, it’s usually a good idea to go talk to the owner of that data. Maybe missing data in a system is simply due to that observation having a value of 0, so to save memory they just don’t record that value in the system. The easy fix there is to go in and replace those values with zero. You might have some time series in your dataset that are shorter than others. For example, most of your time series could have five years of monthly data, but one may have only the recent three years of monthly data. To deal with this, you could also replace those missing values with 0. That way each time series is the same length. This becomes important later on when we want to start back testing different models to analyze forecast accuracy.</p>
<p>After you replace the missing data, it’s also a good idea to flag where missing values were originally. This can be done with a simple binary variable added to your dataset. Showing a value of 1 when the original data point was missing, and 0 when it wasn’t. This allows us to give this information to a model, and have it adapt to the changes we made in the data.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Date</th>
<th>Value</th>
<th>Missing</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2023-01-01</td>
<td>10</td>
<td>0</td>
</tr>
<tr class="even">
<td>2023-02-01</td>
<td>15</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2023-03-01</td>
<td>20</td>
<td>0</td>
</tr>
<tr class="even">
<td>2023-04-01</td>
<td>25</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2023-05-01</td>
<td>30</td>
<td>1</td>
</tr>
<tr class="even">
<td>2023-06-01</td>
<td>35</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2023-07-01</td>
<td>40</td>
<td>0</td>
</tr>
<tr class="even">
<td>2023-08-01</td>
<td>45</td>
<td>1</td>
</tr>
<tr class="odd">
<td>2023-09-01</td>
<td>50</td>
<td>0</td>
</tr>
<tr class="even">
<td>2023-10-01</td>
<td>55</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2023-11-01</td>
<td>60</td>
<td>0</td>
</tr>
<tr class="even">
<td>2023-12-01</td>
<td>65</td>
<td>1</td>
</tr>
</tbody>
</table>
</section>
<section id="outliers" class="level3">
<h3 class="anchored" data-anchor-id="outliers">Outliers</h3>
<p>Outliers are values in a time series that depart from the norm. They can be extremely high or low values. Having outliers in your time series can worsen forecast accuracy. A model may try to learn the new changes in trend/seasonality caused by an outlier and carry them forward into the future forecast. We don’t want that. Instead we should identify when outliers occur and do our best at dealing with them.</p>
<p>There are a few ways we can spot outliers.</p>
<ol type="1">
<li><strong>Smell Test</strong>
<ul>
<li>Use our domain knowledge to point out values that don’t make sense after inspecting the time series on a chart. For example, a temperature of 150°F in Seattle may not be physically possible. It doesn’t pass our smell test, and so we can flag it manually as an outlier.</li>
</ul></li>
<li><strong>Statistical Methods</strong>
<ul>
<li>Calculate statistical measures like Z-scores and interquartile ranges (IQR) to spot data points that are outside of standard ranges.</li>
<li>The <strong>Z-score method</strong> identifies outliers by measuring how far a data point is from the mean, in terms of standard deviations, with values typically beyond 3 considered outliers.</li>
<li>The <strong>Interquartile Range (IQR)</strong> is a measure of statistical dispersion and represents the middle 50% of the data. It is calculated as the difference between the third quartile (Q3), which is the value below which 75% of the data lies, and the first quartile (Q1), which is the value below which 25% of the data lies. The IQR method identifies outliers as data points that fall outside Q1−1.5×IQR (too low) or Q3+1.5×IQR (too high). This method works well for skewed or non-normal data because it uses the quartiles, which are less affected by extreme values than the mean or standard deviation.</li>
</ul></li>
<li><strong>Residual Methods</strong>
<ul>
<li>Residual methods, such as those used in <strong>STL decomposition</strong> (Seasonal-Trend decomposition using LOESS), identify outliers by isolating the residuals after removing trend and seasonality from a time series. STL splits a time series into three components:
<ol type="a">
<li>Trend: The long-term movement or pattern in the data.</li>
<li>Seasonal: Repeating patterns or cycles at fixed frequencies.</li>
<li>Residual: The remaining random noise or deviations after subtracting the trend and seasonal components.</li>
</ol></li>
<li>Outliers are detected in the residuals, which represent the part of the data that cannot be explained by the trend or seasonal patterns. Typically, residuals that fall outside a certain threshold, such as ±3 standard deviations or another robust range, are flagged as outliers. This method is particularly effective for time series data as it accounts for both trend and seasonality, ensuring that outliers are not mistaken for normal patterns.</li>
</ul></li>
<li><strong>Machine Learning Methods</strong>
<ul>
<li>Machine learning methods identify outliers by training models to learn the normal patterns in the data and then flagging deviations from these patterns. These methods include:
<ol type="a">
<li><strong>Isolation Forest</strong>: This tree-based algorithm isolates data points by creating random partitions. Outliers are points that require fewer splits to isolate, as they differ significantly from the rest of the data.</li>
<li><strong>Autoencoders</strong>: Neural networks are trained to reconstruct the time series. Data points with high reconstruction errors (i.e., the model struggles to recreate them) are flagged as outliers.</li>
<li><strong>Clustering</strong>: Algorithms like K-Means or DBSCAN group similar data points into clusters. Outliers are points that either belong to sparse or distant clusters or are classified as noise by the algorithm.</li>
<li><strong>Probabilistic Models</strong>: Techniques like Gaussian Mixture Models (GMM) assign probabilities to data points based on how well they fit the learned distribution, flagging low-probability points as outliers.</li>
</ol></li>
<li>Machine learning methods are powerful because they can handle non-linear, multi-dimensional, and non-Gaussian patterns, making them highly effective for complex time series. However, they require careful tuning and may need more data than simpler statistical approaches.</li>
</ul></li>
</ol>
<p>Let’s use the residual method and see if we can spot a few outliers in our time series. First we will <a href="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/">decompose our time series</a>, then see what residuals are 3 or more standard deviations away from the average.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/chart3.png" class="img-fluid"></p>
<p><img src="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/chart4.png" class="img-fluid"></p>
<p>There seems to be on major outlier in mid 2020, shown as outside of the dotted upper and lower range. Which is not surprising since our smell test could have told us the same thing. COVID-19 in 2020 was most likely the cause for the sudden change in trend and seasonality for those periods around 2020. We can now confirm it with the residual method for spotting outliers. How cool is that!</p>
<p>Once we know the outliers in our data, there is a few things we can do to handle them.</p>
<ol type="1">
<li><strong>Do Nothing</strong>: Leave it alone, and let its presence impact our future forecast. This is a good approach if there is a structural change in the time series that you expect to carry onward in the future. For example COVID might have caused a permanent work from home revolution, which could impact your business that relies on growth in office space. So leaving it alone would give the model insight into a change that is expected to continue in the future.</li>
<li><strong>Flag It</strong>: Similar to flagging missing values, we can add a binary variable to our dataset. A value of 1 to indicate an outlier occurred, and a 0 when it did not. This will allow our model to understand true one time events that are not expected to happen again in the future. Making it less likely for a model to learn the change in pattern. COVID-19 was truly a one off thing, so flagging the outliers could be helpful for our time series.</li>
<li><strong>Remove It</strong>: Remove the outlier, and treat it like a missing value. You can then use the methods discussed earlier to fill in the missing value with something that is more in line with future trends and seasonality. Combining this method with adding an outlier flag from #2 is a solid approach.</li>
</ol>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Handling the presence of missing values and outliers can sometimes be more art than science, so always make sure to be adaptable in using the right approach for your use case. When done correctly, cleaning your data of missing values and outliers can help you understand your data while improving forecast accuracy.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/</guid>
  <pubDate>Tue, 26 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Hacking My Blood Sugar With Fiber</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-11-15-hacking-blood-sugar/</link>
  <description><![CDATA[ 





<p>For years, I’d heard about continuous glucose monitors (CGMs) , mostly from health enthusiasts on podcasts. These small devices, which attach to your upper arm, measure blood glucose (blood sugar) every five minutes and send the data to your phone via Bluetooth. Originally developed for diabetics who need to monitor their blood glucose throughout the day, CGMs are now becoming popular among non-diabetics as a tool to track metabolic health.</p>
<p>Metabolic health refers to how well your body processes and manages energy from food. Good metabolic health means your body efficiently converts food into energy without putting too much strain on organs like the heart, pancreas, liver, and muscles. People with optimal metabolic health typically have stable blood sugar, good insulin sensitivity, healthy cholesterol levels, and normal blood pressure. Poor metabolic health can increase the risk of conditions like diabetes, heart disease, stroke, and obesity.</p>
<p>Key indicators of metabolic health often include:</p>
<ul>
<li>Blood sugar levels - Balanced glucose levels without spikes or drops.</li>
<li>Blood pressure - Normal range without requiring medication.</li>
<li>Cholesterol and triglycerides - Healthy levels that reduce risk of cardiovascular issues.</li>
<li>Waist circumference - Indicates abdominal fat, linked to higher risk of metabolic disorders.</li>
<li>Insulin sensitivity - Ability to regulate blood sugar without excessive insulin release.</li>
</ul>
<p>Using a CGM to track blood glucose (BG) is a great way to gauge metabolic health. When your BG stays within a healthy range (70-140 mg/dl), your body functions optimally. Repeatedly leaving that range can lead to serious consequences. <a href="https://www.cdc.gov/diabetes/communication-resources/diabetes-statistics.html#:~:text=Diabetes%201%20Diabetes%20About%2038%20million%20people%20have,health%20complications%3A%20...%205%20Common%20Types%20of%20Diabetes">Over 1/3 of Americans</a> have either diabetes or prediabetes, with many unaware of their condition. Heart disease is the <a href="https://www.healthline.com/health/leading-causes-of-death">leading cause of death</a>, accounting for 20% of all deaths in America. These illnesses, with the exception of type 1 diabetes, can be mitigated with good metabolic health, which involves maintaining stable BG throughout the day.</p>
<p>A few months back I purchased a CGM device, <a href="https://www.stelo.com/en-us">made by Dexcom</a>, to start tracking my BG. I did it for a few reasons. A family member of mine has type 1 diabetes, so I wanted to see how my own BG levels look throughout the day. While also test driving to device before recommending it to them. I also wanted to understand how certain foods impact my blood sugar. I’ve heard on podcasts that you’d be surprised what kinds of foods impact your BG. Which is different for everyone. Some foods people thought as healthy, like bananas, might send their BG spiking. Finally, if I could get a better handle on my BG, I could also get better control of my energy throughout the day. When your BG spikes above the normal range, it will eventually come crashing down. Going far lower than the normal range. This spike and fall of BG leads many people to have energy crashes throughout the day. This saps their energy, while also giving them cravings to eat more food. This is a vicious cycle. And one that I wanted to break.</p>
<p>I purchased the CGM from Dexcom and slapped it on my arm. It didn’t hurt to apply and after a few minutes I forgot it was even there. One device lasts for about 15 days so every couple of weeks you have to switch it out for a new one. I now got a stream of data every five minutes alerting me to my BG level. For a data nerd like me it was awesome. I quickly become some sort of mad scientist. Eating things at random and seeing how my BG changed in the next 60 minutes. The findings for my body were very straight forward. If I ate processed junk, my BG would spike. If I ate unprocessed whole food, my BG would stay stable. As long as I didn’t eat processed food, my BG would stay in the healthy range. There is just one problem though, I love junk food.</p>
<p>Everything in moderation, including moderation. Right? I usually try to eat clean +90% of the week. But I am human, and love to pig out every once in a while. I have been known to subscribe to the practice known as “Faturday”. Where for one day of the week I go absolutely nuts and eat everything in site. This kind of <a href="https://www.investopedia.com/articles/investing/013114/barbell-investment-strategy.asp">barbell strategy</a>, either eating 100% clean or 100% junk, has kept me in balance over the years. It keeps me on track of my health goals without being too much of a stickler. The only downside of this approach is the massive hits my BG takes on the days I let loose. Once I got the CGM I could see the roller coaster ride my BG would take on these cheat days, and I could match my mood and energy level with where my BG was at the time. This made me think more about ways I could control my BG when I wanted to treat myself, without putting myself at risk of the consequences of poor BG management.</p>
<p>There are a few tried and true ways to control your BG. The first, and most boring, is to just eat healthy unprocessed foods. A second way is to incorporate movement into your day after eating. Simply <a href="https://www.thehealthy.com/exercise/walking/blood-sugar-walking/">going on a walk after eating</a> can have a profound impact on stabilizing your blood glucose. The same goes for more intense movement like lifting weights or cardio. These two strategies are strong, but they didn’t help me when I wanted to treat myself. I quickly learned that it’s hard to outrun a donut you just ate. That’s when I came across a third way to control BG.</p>
<p>A favorite podcast of mine is called <a href="https://allin.com/">All In</a>. It features four men who are titans in Silicon Valley. From founders of Paypal to early Facebook and Google employees, these guys know their stuff. During one episode I learned about a supplement company one of the members of the podcast invested in, called <a href="https://supergut.com/">Super Gut</a>. The company is all about fiber, which sounds like the worlds most boring supplement, but in reality has countless benefits. It turns out that 95% of Americans do not consume enough fiber, which is around 30 grams a day. So we all need to look for more ways to consume more fiber.</p>
<p>Super Gut uses prebiotic fiber found in foods like green bananas, oats, and potatoes. This preobiotic fiber is the best kind of food to provide your gut microbiome, since it can’t be converted into fuel for your body like other macronutrients. Fiber is bulky, so it easily expands to fill your stomach, causing a feeling of being full. It also slows your digestion, which can prolong the feeling of being full, and has the additional benefit of regulating your BG. Finally, there have been recent findings that show consuming the right types of fiber makes your body <a href="https://supergut.com/blog/natural-glp-1-how-to-produce-satiety-hormones-without-ozempic">release hormones like GLP-1</a>. This is the main ingredient behind booming drugs like Ozempic, used for weight loss. Why pay thousands for synthetic GLP-1 when you get get more of it naturally with fiber?</p>
<p>Each serving of the Super Gut shake contains 15 grams of fiber, which is around 50% of the fiber we need each day. That’s a crap ton of fiber. To put that into perspective, you would have to eat about 5 medium sized potatoes (with skin on) to get the same amount of fiber. 10 seconds of consuming a fiber supplement compared to 20+ minutes of force feeding potatoes. The choice is easy.</p>
<p>How do I use it? First and foremost I use Super Gut to get the daily recommendation of fiber. Usually consuming a serving at the start of each day. Going from maybe 10 grams of daily fiber to 30+ is life changing in more ways then one. Bathroom trips get a lot more interesting. Any previous problems in that department gets solved immediately. What has surprised me the most is its impact on my blood sugar when I eat junk. When I treat myself on a Faturday, I first consume fiber, then eat whatever crap comes my way. Ice cream went from spiking my BG over 200 mg/dl to now only going up slightly to 130-140 mg/dl. Which is within the healthy range. That small spike is short lived, compared to previous Faturday’s where my BG would spike for hours at a time. Now when I eat pizza, my responds like I’m eating chicken and rice. I usually have a 2-3 window after consuming fiber where I can eat junk without spiking my BG. It’s truly mind blowing.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-15-hacking-blood-sugar/chart1.png" class="img-fluid"></p>
<p><img src="https://mftokic.github.io/posts/2024-11-15-hacking-blood-sugar/chart2.png" class="img-fluid"></p>
<p>Now this doesn’t mean you should go out and eat whatever you want, as long as you consume some fiber beforehand. Don’t do that. But when you do want to treat yourself on occasion, you can do so knowing that it won’t wreck your metabolic health. Try it for yourself! I’m sure there are other supplements besides Super Gut out there that can do the same thing. Regardless of whether you’re trying to pig out or not, getting more fiber into your life will improve your life in more ways than one.</p>



 ]]></description>
  <category>life</category>
  <category>health</category>
  <guid>https://mftokic.github.io/posts/2024-11-15-hacking-blood-sugar/</guid>
  <pubDate>Fri, 15 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-11-15-hacking-blood-sugar/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Exploratory Data Analysis: Autocorrelation</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/">exploratory data analysis chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2024-11-12-ts-fundamentals-autocorrelation.ipynb">python code used in this post here.</a></em></p>
<section id="time-series-data-has-memory" class="level3">
<h3 class="anchored" data-anchor-id="time-series-data-has-memory">Time Series Data Has Memory</h3>
<p>The biggest factor that differentiates a time series from another form of data is order. Each observation in a time series is ordered by well, you guessed it, time. Because of this order, there are unique relationships that develop in the data. Let’s take temperature for example. If today’s temperature is 70°F, and the temperature in the previous seven days was around 65-80, what do you think the temperature tomorrow will be? Probably not below freezing. It’ll most likely be similar to the temperature today. This memory about the past is one of the most powerful concepts in time series forecasting. It’s the concept of autocorrelation.</p>
<p>Autocorrelation is when a value in a time series is related to previous values in that series. In simple terms, it measures how much the current value depends on past values. For example, if high temperatures today make it likely to have high temperatures tomorrow, the temperature series has a positive autocorrelation.</p>
</section>
<section id="calculating-autocorrelation" class="level3">
<h3 class="anchored" data-anchor-id="calculating-autocorrelation">Calculating Autocorrelation</h3>
<p>Getting the autocorrelation is as simple as computing the correlation of the existing time series with a lagged time series. For example let’s take a time series from our example data set, shown below.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/chart1.png" class="img-fluid"></p>
<p>We can create lags of one month, two months, and onwards. Then calculate the correlation between the original time series (with a lag of 0) and these new lagged time series. The results of that process are shown below, with a lag up to 24 months.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/chart2.png" class="img-fluid"></p>
<p>Correlation is shown on the y-axis and the lag amount is shown on the x-axis. The chart shows high autocorrelation for a lag of 0, 1, 12, and 24 months. A lag of 0 has a perfect correlation because it’s the exact same as the original time series. These lag correlations are shown as positive values, meaning that there is a positive correlation with the original time series. There are also above the shaded blue region of the chart. This shaded region is a confidence interval. This confidence interval helps us filter out lags that are not statistically significant, meaning they don’t have a correlation due to random chance. Any lag outside of the shaded region is significant and should have a real relationship with our original time series.</p>
</section>
<section id="partial-autocorrelation" class="level3">
<h3 class="anchored" data-anchor-id="partial-autocorrelation">Partial Autocorrelation</h3>
<p>Autocorrelation has one fatal flaw though. It can provide misleading correlations since it doesn’t account for correlations between lags. For example, there might be a very strong correlation with the original time series and lag 1 of the time series. Because of this correlation, there is a good chance that a lag 2 also shows a strong correlation. The lag 2 correlation might only be due to lag 2 having similar information to lag 1. So the end results could be misleading.</p>
<p>To account for this, partial autocorrelation was created. This process takes into account the correlations between lags. Making sure that the end correlations are only connected to the original time series. It is the preferred method of analyzing autocorrelation. So make sure it’s part of your time series tool kit. Here is the partial autocorrelation of our example time series.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/chart3.png" class="img-fluid"></p>
</section>
<section id="reading-the-tea-leaves" class="level3">
<h3 class="anchored" data-anchor-id="reading-the-tea-leaves">Reading the Tea Leaves</h3>
<p>Let’s take a deeper look at the partial autocorrelation and see what insights it might provide. When looking at the partial autocorrelation chart, the biggest correlation is at lag 0. This makes sense since a lag of 0 is just the original time series, so there will be a perfect correlation of 1. Lag 1 shows a strong correlation, which makes sense, since it’s contains values closest to the original series. There are also strong correlations at lag 11, 12, and 13. This confirms our data has strong seasonality. The highest correlation is at lag 12, which means values today are highly correlated to values at the same time in the previous year (12 months ago). This information will be invaluable when we start to build models in the future.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Having strong partial autocorrelation in your time series will always lead to more accurate future forecasts. Especially if you expect <a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">the future to be similar to the past</a>. If your data has little or no correlation with historical lags, then it will be more difficult to train accurate models to forecast the future. Calculating partial autocorrelation should always be one of the first things you do when working with time series. It’s quickest way to start building intuition about your data.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/</guid>
  <pubDate>Tue, 12 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/chart3.png" medium="image" type="image/png" height="110" width="144"/>
</item>
<item>
  <title>Why I Cancelled All My Streaming Apps</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-11-08-cancelled-streaming/</link>
  <description><![CDATA[ 





<p>Last weekend I was in Dallas for a close friend who was getting married. It was the Friday before the wedding and I had some time to kill. So I walked around Dallas for a few hours. That’s my favorite way to explore the city. I eventually got hungry and settled on a restaurant in uptown. After ordering I sat outside to enjoy the nice Texas weather. Which funny enough looked the exact same as a winter in Seattle (clouds, dark, rainy).</p>
<p>A waitress slowly walked up behind me, looking concerned. She asked what I was doing, making sure I was ok. I wasn’t doing anything crazy, just looking out across the city and thinking. It took me a while to realize that she was concerned because I wasn’t engrossed in my phone. Checking X, Instagram, or TicTok. After realizing this I told her that I was trying to stare at my phone less and was enjoying the new city. Maybe she thought I just got dumped and was looking grimly out on this cruel world. Or that I just got fired and was re-evaluating my life choices. Overall she was concerned because I was not looking at my phone to pass the time. Now that definitely concerned me.</p>
<p>Weeks before this incident I made conscious decision to unsubscribe and delete all TV/Movie streaming apps. Things like Hulu with live TV, Netflix, MAX, Paramount+. I had them all. And they all had to go. Why would I do something so crazy! The explanation is simple my dear Watson. I wanted to create more opportunities to be bored in my life. Call me crazy, but it’s working out better than I’d imagined.</p>
<p>When I was a college freshman at Kansas, circa 2012, I was part of a fraternity. As a rule, all pledges of the fraternity were not allowed to have any form of TV or video game console in their room. I like to think it was to give parents peace of mind that they would be studying more than goofing off. But the real goal was something entirely different. When 40 pledges can’t pass time by watching TV they have to do other things. Together. Instead of binge watching a show alone in your room you now have to be a real human being and get together with other pledges to pass the time. My older brother, who was two years older and in the fraternity, knew this when he bought me a dart board as a present before school started. He said I would use this more than anything else in my room. You know what? He was absolutely right. That dart board become a sort of water cooler that allowed other pledges to come to my room and pass the time by playing darts. In addition to darts, we did all sorts of crazy things to pass the time in between classes. One week it was playing cards. Another it was creating playlists on Spotify. We even created a sacred coffee ritual before we all went off to study each night. This included a special coffee blend, singing an old Folgers jingle from the 90s, and maybe a little dance if we were feeling up to it. My mom even knew what to expect when I bought a desk chair before school started. She said I needed to get the cheapest one because she knew with absolute certainty that it was going to get destroyed through activities like chair racing and playing a form of floor hockey while riding a chair. That was a common activity when my older brother was a pledge. Safe to say, that chair did not make it through my freshman year unscathed. All of those activities may sound dumb, but that’s how each pledge got to know each other. Going from strangers to brothers in a short six months.</p>
<p>Cutting out all streaming apps from my life allowed me to help recreate the kind of boredom I felt in college to do things that were actually good for me. Instead of watching a show for four hours like a zombie. There are simply too many good shows and movies out right now. All at our fingertips waiting to be watched. This creates an opportunity to always be entertained, always have something to occupy your mind. That kind of stimulation cannot be good for us, and that’s why I’m trying to remove it from my life.</p>
<p>Here are a few other reasons why I wanted to remove TV from my daily equation:</p>
<ol type="1">
<li>Time suck: You can easily watch TV for eight hours straight on a Saturday. That is time you just never get back. Robert Green has an idea called “alive time vs dead time”. Alive time is doing things that are creative and beneficial to your life. Things like reading, writing, painting. Dead time is essentially a waste and time you never get back. Things like watching TV or scrolling social media. Alive time gives you life, while dead time takes it away from you.</li>
<li>News is bad for you: Most news out there is about terrible things happening in the world. That’s what creates the most viewers, which bring in ad revenue to stay on air. Humans are not designed to know everything bad going on in the world at once. It’s a form of sensory overload that leaves us more anxious and pessimistic about societies future. It’s a form of entertainment junk food.</li>
<li>TV meeting your social needs: I think an unnoticed impact from TV is that it fills a lot of the socialization needs us humans crave every day. A feeling of being with friends or loved ones. Instead of going out to hang with a friend, you might just stay in and hang out with your friends that live inside a TV show. An introvert like me can only have so much social stimulation in a day, and watching too much TV leaves less opportunities to socialize with real people.</li>
<li>TV to forget problems: Ever had a bad day at the office and come home to watch a funny sitcom to relax? We’ve all done it. And in moderation it’s probably an ok thing to do. But if you’re doing that every day after work, then you are just numbing bigger problems in your life. TV won’t fix that, it just delays the problem for another time. Which can eventually blow up in your face. Taking that salve away gives us no choice but to face problems in our lives. Giving us the time to actually do something about versus just get by another day.</li>
</ol>
<p>Now my dear reader, you might still think I’m insane. What do you do with all of this newfound boredom? Aren’t people who say they don’t own a TV just pretentious do****s? Here’s how I now spend my time:</p>
<ol type="1">
<li>Books: When TV is out of the question, you can easily crush 2+ books a week. Books become your constant companion. I’ve recently fallen back in love with fiction books. For over a decade I’ve been strictly reading non-fiction at a clip of 1-2 books per month. Now I read multiple non-fiction and fiction books at once. And it’s amazing. You know how people say the book was better than the movie? They are usually right. What was a 2.5 hour movie is actually a 300+ page book that takes over 10 hours to read. Talk about bang for your buck.</li>
<li>Music: Sitting down to solely listen to music has been lost on me the last decade. As a teenager a good song could change my life, but in recent years I haven’t ventured out of my old favorites. Now I sit down and explore new artists, albums, and deep cuts from my top bands. This is now the most relaxing thing I do. Nothing fixes a rough day like a good playlist.</li>
<li>Sports: The biggest drawback of no TV is no live sports. I love everything soccer and Kansas City sports. So whenever I want to go watch a game I now have to get off my butt and go watch it somewhere. This now forces me to be in the company of others, most often close friends. This leads me to my next point.</li>
<li>Get out of the house: TV is the ultimate ball and chain tying you to your house. Without it I now have pressure to get out into the world and explore what’s going on in my community. Art shows. Farmers markets. Anything and everything going on in the world is now at my disposal since I literally have nothing better to do. I now can’t say no to things because if I did I would just be bored at home. This creates more serendipity in my life.</li>
<li>TV in the wild: Coming across a movie or show when I’m out and about is now a treat. I enjoy it 100x more because it doesn’t happen that often. Last weekend my Alaska Airlines flight had free movies I could watch. I chose a new Guy Ritchie movie about WW2 and it blew my mind. I wouldn’t have appreciated it in the same way if it was the third movie I watched on a lazy Sunday afternoon.</li>
</ol>
<p>Who knows, maybe in a months time I will relapse and sign back up for all of the streaming apps I quit. But so far it’s been a good experience. Maybe try it out yourself for a few weeks and see how it might improve your life. I think we all need to engineer more opportunities to be bored. Because when we’re bored, that’s when good ideas come to us and when serendipity can change your life forever.</p>



 ]]></description>
  <category>life</category>
  <guid>https://mftokic.github.io/posts/2024-11-08-cancelled-streaming/</guid>
  <pubDate>Fri, 08 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-11-08-cancelled-streaming/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Exploratory Data Analysis: Time Series Decomposition</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/">exploratory data analysis chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2024-11-06-ts-fundamentals-decomposition.ipynb">python code used in this post here.</a></em></p>
<section id="your-data-is-so-trendy" class="level3">
<h3 class="anchored" data-anchor-id="your-data-is-so-trendy">Your Data is so Trendy</h3>
<p>Every single time series you have ever seen has a trend and seasonality. If they don’t, then they are random white noise. A trend is just values steadily rising or falling over time. You could have a rising trend in some years, then a falling trend in others. Below is a chart with a strong trend but weak seasonality.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart1.png" class="img-fluid"></p>
<p>Seasonality just means that your data has a recurring seasonal pattern. For example your data could spike during the holiday season from Oct-Dec, then fall drastically from Jan-Jun.&nbsp;Your seasonality could also change over time. Below is a chart with strong seasonality but weak trend.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart2.png" class="img-fluid"></p>
<p>In order to better understand the trend and seasonal patterns in your data, you need to isolate them into separate components. This is done through a process called time series decomposition. This process breaks out a time series into three separate parts: trend, seasonality, and remainder. The remainder component is just parts of your time series that can’t be explained by the trend and seasonal component. Let’s try decomposing a time series from our example data set.</p>
</section>
<section id="breaking-out-trend-and-seasonality-with-additive-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="breaking-out-trend-and-seasonality-with-additive-decomposition">Breaking Out Trend and Seasonality with Additive Decomposition</h3>
<p>We can isolate the trend component of a time series using simple methods like moving averages (MA). These are just simple averages over a span of time. Let’s take a time series from our example revenue data and create a moving average. In the first chart below we used a <a href="https://otexts.com/fpp3/moving-averages.html#estimating-the-trend-cycle-with-seasonal-data">2x12-MA</a>. This moving average now isolates the trend of the time series. We can see a dip in trend around 2020 then a strong rebound going forward. The moving average doesn’t start and end at the same time as our time series, since we need a burn in period to start creating the averages. If we wanted to detrend the time series we can subtract the new trend series from our original revenue, shown in the second chart below.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart3.png" class="img-fluid"></p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart4.png" class="img-fluid"></p>
<p>Next we can get the seasonal component of our data. This is very straightforward. All we have to do is take our detrended series and calculate the average revenue for each month of the year. After getting the average value per month, we can divide by the total average across all months. This ensures that the seasonal values of each month add to zero. Then we repeat the final values per month across all years. The final result is shown below. Now we can see there is very strong seasonal patterns at certain times of the year. Some quarters have high sales, while others do not. This kind of repeatable pattern will be very important for us when it comes to training models.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart5.png" class="img-fluid"></p>
<p>Finally we can get the final piece of our decomposition, the remainder (aka residual) series. This is everything that couldn’t be explained by the trend and seasonal components. Simply take the original revenue time series, subtract the trend and seasonal components, and bam you have the remainder series.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart6.png" class="img-fluid"></p>
</section>
<section id="stl-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="stl-decomposition">STL Decomposition</h3>
<p>The additive decomposition approach can work very well if your data has a linear trend and stable seasonality. But if the series is growing exponentially, or has changing seasonality, then more advanced methods are needed. This is where STL decomposition comes in. STL is an acronym for “Seasonal and Trend decomposition using Loess”, while loess is a smoothing method for estimating nonlinear relationships. This smoothing process allows for changing seasonality, a more complex understanding of the trend component, and more resistance to outliers. Here is the STL process broken down step by step.</p>
<ol type="1">
<li>Extract Initial Seasonal Component
<ul>
<li>First, STL identifies the seasonal pattern in the data. It does this by looking at the regular repeating cycles (e.g., monthly or weekly patterns).</li>
<li>Using Loess smoothing, it calculates a rough seasonal pattern that captures these cycles.</li>
<li>This step gives an initial estimate of what the seasonal pattern looks like.</li>
</ul></li>
<li>Remove Seasonality to Estimate the Trend
<ul>
<li>After finding the initial seasonal component, STL subtracts it from the data to get a rough idea of the trend (the overall up or down direction).</li>
<li>Loess smoothing is applied again to the deseasonalized data (data without seasonal patterns) to create a smooth trend line.</li>
</ul></li>
<li>Refine the Seasonal and Trend Components
<ul>
<li>STL repeats the process in cycles, fine-tuning both the trend and seasonal estimates.</li>
<li>Each cycle alternates between smoothing the seasonal component and the trend component, adjusting them with each pass to better fit the data.</li>
<li>By repeating this process, STL allows the seasonal component to change over time if necessary and captures any evolving trends.</li>
</ul></li>
<li>Calculate the Remainder
<ul>
<li>Once the trend and seasonal components are finalized, STL subtracts both from the original data. What’s left is the remainder component, representing the random, unpredictable part of the data.</li>
<li>This remainder is what can’t be explained by the regular trend or seasonal patterns, capturing any noise or outliers.</li>
</ul></li>
</ol>
<p>Here is the output of a STL decomposition. Each component can be added together to get the original time series, just like additive decomposition.</p>
<p><img src="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart7.png" class="img-fluid"></p>
</section>
<section id="reading-the-tea-leaves" class="level3">
<h3 class="anchored" data-anchor-id="reading-the-tea-leaves">Reading the Tea Leaves</h3>
<p>Understanding the outputs of time series decomposition can be more of an art than science. The more you do it, the more your data intuition grows about what’s happening. Looking at the results of STL decomposition tells us a few things for our time series.</p>
<ol type="1">
<li>There has been mostly a stable trend over the years, except for a strange dip in 2020.</li>
<li>Seasonality is strong with repeating peaks and valleys across the years. But it does seem to be growing with each passing year.</li>
<li>Most of the residual points hover around zero, which is ideal. Having the residual component have an average of zero and a constant standard deviation over time means the data is just white noise, or things that can’t be explained. We do see a large drop in 2020 though…</li>
</ol>
<p>This analysis shows us that there is most likely an outlier in 2020 that seriously impacted our data. If you don’t have a guess as to what this might be than you might have been living under a rock the last decade. The impact is from COVID-19. Thankfully this impact can be taken care of later in our modeling process. But for now it’s good that we identify it and get the domain knowledge to know what could have caused it.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Decomposing a time series is often one of the first things an accomplished data scientist does before training any kind of machine learning model. Breaking the time series into its components allows us to understand the potential forces that is impacting the trend of the data and if there are any outliers in the data. Knowing this allows us to change our approach when training models. Ultimately leading to more accurate forecasts down the road.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/</guid>
  <pubDate>Wed, 06 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/chart7.png" medium="image" type="image/png" height="115" width="144"/>
</item>
<item>
  <title>Newsletters Stink</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-10-30-newsletters-stink/</link>
  <description><![CDATA[ 





<section id="too-many-too-fast" class="level3">
<h3 class="anchored" data-anchor-id="too-many-too-fast">Too Many, Too Fast</h3>
<p>When I open my email, I cringe. I have hundreds of unread emails. Not from coworkers about important work. But instead from the many newsletters that every influential person on the internet now has. When I signed up for these newsletters, I was excited. Insights delivered right to my mailbox! What was initially 3-4 newsletter emails a week quickly turned into over two dozen. For someone who likes the practice of inbox zero this caused unneeded stress.</p>
<p>In order to offload these emails into another place for reading, I signed up for services like ReadWise. Which has a great reading app you can have newsletters automatically get sent to. This was helpful at first, but eventually turned back into email. When I look at my “feed” on the Reader app, I have 121 unseen newsletter emails. That’s insane. I cannot read all of these, nor do I want to. Something needs to change.</p>
</section>
<section id="why-newsletters-stink" class="level3">
<h3 class="anchored" data-anchor-id="why-newsletters-stink">Why Newsletters Stink</h3>
<p>Newsletters serve a good purpose. They are a way to push out content and build audiences. Which can lead lead to $ for their creators. These good intentions come with some drawbacks. Let’s call them out.</p>
<ol type="1">
<li><p><strong>Push, no Pull</strong>: Newsletters get thrusted upon us once we sign up. Some get sent every single day. This kind of push process creates build ups of unread articles in our mailboxes. The bottleneck is us. It’s our time. We don’t have a lot and we want to make the most of it. Ideally we would instead prefer a pull approach where once we read one newsletter, we then get the next one. Instead of having 20 stacked up in our inboxes.</p></li>
<li><p><strong>New is Not Always Better</strong>: The “news” in newsletter is what makes them bad. I think we all know that consuming news is not good for us. It raises our anxiety and is a form of entertainment junk food. Instead of always getting the freshest take on business or technology today, you’d probably get more insight from articles written years ago that are timeless. Reading a Paul Graham essay on building a business written 10 years ago is probably better than getting a newsletter from someone today who has only build one business. Also there is pressure for creators to push these out on a regular cadence, which means quality goes down. Pushing 4 newsletters out a month will most likely lead to less quality then taking the time to write one newsletter over 1-2 months. New and more is not always better. We need more evergreen content.</p></li>
<li><p><strong>Archives Are Graveyards</strong>: Have you ever gone looking through old newsletters from your favorite creator? Probably not. Only the brave of heart dive into the dumpster of a creators website and dig around for little nuggets of gold. There might be a newsletter from five years ago that could change your life, but to find it you might have to dig through dozens of others about the NFT market in 2021 that no one cares about anymore. Again, see my point ini #2. We need a better way of finding the best evergreen content.</p></li>
<li><p><strong>No Personalization</strong>: Once you sign up for a newsletter, you are at the mercy of reading all of them. Regardless of the content in each one. This might be ok if the newsletter author writes about one thing, but a disaster when they are wide ranging. For example, let’s say Joe Rogan had a newsletter (he doesn’t but let’s pretend). You might love all of the content around culture, politics, and comedy but absolutely hate it every time he talks about the UFC. Maybe you don’t like MMA, and could care less who Connor McGregor may fight next. We need a better way of finding the best content relevant to our interests.</p></li>
<li><p><strong>They Replaced Blogs</strong>: People that used to write blogs now write newsletters. What a shame! You could in theory just take the posts you used to publish to your blog and now just send out via newsletter. But people don’t do that anymore. What a bummer. We need more blogs and less newsletters.</p></li>
</ol>
</section>
<section id="who-does-things-right" class="level3">
<h3 class="anchored" data-anchor-id="who-does-things-right">Who Does Things Right</h3>
<p>You know who does things right? YouTube. They have it all figured out. Instead of seeing a list of videos in chronological order, they show you what videos you might be most interested in. Not just from channels you follow but for any channel. You can interact with videos you like by watching them multiple times, liking the video, or subscribing to the channel. This ensures you see more content like it. Or if you hate the video you can give the thumbs down, click on “show me less of this”, or even block the channel entirely. With a few smart features they fixed every thing that is wrong with other forms of content like newsletters and blogs.</p>
<p>When I open up my YouTube homepage on the app, I see a sea of great options. The first video recommended on the page is for a podcast I like that just posted a new video two hours ago. As I scroll I see content from last week, last month, even as far back as two years ago. These are all things that interest me, not just the latest content from channels I follow. I even see content from channels I’ve never heard about, but is chosen based on my interest in other liked videos. This is why YouTube dominates.</p>
<p><img src="https://mftokic.github.io/posts/2024-10-30-newsletters-stink/image2.png" class="img-fluid"></p>
<p><a href="https://variety.com/vip/netflix-vs-youtube-post-streaming-wars-1236143341/">Source - Variety</a></p>
</section>
<section id="make-blogs-great-again" class="level3">
<h3 class="anchored" data-anchor-id="make-blogs-great-again">Make Blogs Great Again</h3>
<p>Ideally there should be a service that is like YouTube but for blogs. Anyone who has a blog can connect their site to the service, and posts are algorithmically provided to the user based on what the user likes. It won’t be what causes the most outrage or reactions, but instead what makes them entertained or more informed. The site would have no news, just evergreen content that’s just as relevant next year as it is now. Sites like Medium try to do this today, but their biggest flaw is that they live behind a walled garden. Meaning a blog owner has to only post their stuff to Medium and not on their own site. This is not ideal. Since you now have to play by Mediums rules and all of your content now lives on a platform you don’t control. You could argue YouTube is the same but YouTube is the only way people consume user submitted video content today. There is no second choice. Compared to blogs where anyone can host their own for free via GitHub (that’s what I do).</p>
<p>There could also be amazing AI features built into this new blog recommendation service. What if all blog posts on the site were indexed and you could ask questions about the blog via GenAI? Imagine having a conversation with Paul Graham, powered by every piece of advice he has ever written about building businesses or technology. It would basically be a mentor on demand. Always ready to bounce ideas off of or think through hard problems.</p>
<p>The world has too many new(s) things. We need to make old things, like blogs, new again.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>learning</category>
  <guid>https://mftokic.github.io/posts/2024-10-30-newsletters-stink/</guid>
  <pubDate>Wed, 30 Oct 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-10-30-newsletters-stink/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Exploratory Data Analysis: Shape of the Data</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/</link>
  <description><![CDATA[ 





<style>
.figure {
    text-align: center;
}

.figure figcaption {
    text-align: center;
}
</style>
<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/">exploratory data analysis chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p>The example data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a></p>
<section id="initial-data-smell-test" class="level3">
<h3 class="anchored" data-anchor-id="initial-data-smell-test">Initial Data Smell Test</h3>
<p>The first step of exploratory data analysis for time series is getting a feel for the data at a high level. This doesn’t involve complex statistical analysis. Just simple charts to see how things look. When analyzing these charts we’ll use the most underrated concept in machine learning. The human smell test. This involves using your eye balls to look at the data and understand what could be going on based on your <a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">domain experience</a>. Let’s chart the time series in a few ways and give it a smell test.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/chart1.png" class="img-fluid figure-img"></p>
<figcaption>Total revenue by month</figcaption>
</figure>
</div>
<p>Looking at the data all up shows a pretty stable upward trend with a few bumps in the data. Right now it’s hard to tell if those bumps in 2019 and 2021 are outliers or not. We would have to dig deeper into the data. The trend seems to be growing exponentially. Meaning it’s not a straight line but instead one that seems to grow faster each year. This kind of hockey stick growth is what all businesses aspire to. Lastly it’s hard to tell if there is any strong seasonality.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/chart2.png" class="img-fluid figure-img"></p>
<figcaption>Total country revenue by month</figcaption>
</figure>
</div>
<p>Breaking out the data by each country gives us a better picture of what’s going on in our monthly sales. Canada is the country with the exponential growth, combined with a few spikes in some months. These spikes could be one off events that are unpredictable, or something happened in those months that can be quantified in data.</p>
<p>Revenue in the United States has more of a linear upward trend with strong seasonality. There is something strange going on in 2020 though. Any guesses on what that could be?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/chart3.png" class="img-fluid figure-img"></p>
<figcaption>Total product revenue by month</figcaption>
</figure>
</div>
<p>Looking at revenue by product tells a similar story as revenue by country. Cookie sales seem to be a lot more bumpier than ice cream, which is more stable and growing fast.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/chart4.png" class="img-fluid figure-img"></p>
<figcaption>Revenue for each individual time series by month</figcaption>
</figure>
</div>
<p>Finally we can view each time series individually. Our initial hunches at higher aggregations are now confirmed. We can see Canada cookie sales have those crazy spikes. After talking to our sales and marketing teams, we learn that the spikes are caused by new cookie product launches. Ice cream sales in Canada is the one series with the exponential growth. Both don’t have much seasonality.</p>
<p>Revenue in the United States is all about seasonality. Cookie sales show an interesting dip in 2020 but seem to rebound in 2021. This could be caused by the impact of COVID. Ice cream sales has both strong trend and seasonality. This will make it easy to forecast going forward. The more stable the trends and seasonality in your time series, the easier it is to create an accurate future forecast. <a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The future should always resemble the past.</a></p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>We have now completed our initial smell test of the historical data. Based on our domain knowledge of the business we can start to understand what happened in the past, and use that information to help us create a better future forecast. The smell test was easy on this dataset since there are only four time series. You might be working with thousands of time series at your company, so higher level smell checks might be the only thing you can do. There are more automated ways at analyzing the data, and will be explored more in future posts.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/</guid>
  <pubDate>Tue, 15 Oct 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Exploratory Data Analysis For Time Series</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/</link>
  <description><![CDATA[ 





<p><em>This post is part of a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the learning path</a> to see other posts in the series.</em></p>
<section id="exploratory-data-analysis-overview" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis-overview">Exploratory Data Analysis Overview</h3>
<p>Exploratory data analysis, or EDA, is the process of understanding the patterns in your data before you train any machine learning model. It’s the first step in the data science lifecycle. Blindly throwing your data into a model before understanding it yourself is a recipe for disaster. If your data is garbage, you will create a garbage forecast. <a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Gargbage in, garbage out.</a></p>
</section>
<section id="eda-for-time-series" class="level3">
<h3 class="anchored" data-anchor-id="eda-for-time-series">EDA for Time Series</h3>
<p>Applying EDA to time series data is a unique process, different from every other kind of data used in machine learning. Here are the building blocks of good time series EDA. Click on each to explore further.</p>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/">Shape of the Data</a></li>
<li><a href="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/">Time Series Decomposition</a></li>
<li><a href="https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/">Autocorrelation</a></li>
<li><a href="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/">Missing Values, Outliers</a></li>
<li>External Regressors (in progress)</li>
</ul>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/</guid>
  <pubDate>Thu, 03 Oct 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>What’s A Time Series?</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/</link>
  <description><![CDATA[ 





<p><em>This post is part of a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the learning path</a> to see other posts in the series.</em></p>
<section id="ais-are-like-onions-we-both-have-layers" class="level3">
<h3 class="anchored" data-anchor-id="ais-are-like-onions-we-both-have-layers">AI’s Are Like Onions, We Both Have Layers</h3>
<p>There’s a lot of terminology in the world of artificial intelligence. With a lot of layers to it. The practice of time series forecasting is many layers down. How deep? Let’s start peeling back the layers.</p>
<p><img src="https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/image2.png" class="img-fluid"></p>
<section id="artificial-intelligence" class="level4">
<h4 class="anchored" data-anchor-id="artificial-intelligence">Artificial Intelligence</h4>
<p>Artificial Intelligence, or AI, can be described as the ability for machines to learn and think like humans. It’s as simple as that. While that’s an easy thing to say, it’s a hard thing to do. AI has been around since the mid 20th century, with a lot of ups and downs. There are multiple subdisciplines of AI. Things like robotics and expert systems. But the biggest and most important is machine learning.</p>
</section>
<section id="machine-learning" class="level4">
<h4 class="anchored" data-anchor-id="machine-learning">Machine Learning</h4>
<p>Machine Learning, or ML, is all about creating algorithms learn on their own from data. ML turns the idea of traditional programming on its head. Traditional programming is all about writing out explicit instructions or rules, in the form of code, that tell a computer what to do. ML on the other hand is code in the form of an algorithm where the rules are learned from training data. It’s a unique paradigm shift that has unlocked countless advancements in computing. Self-driving cars, human genome sequencing, and yes even forecasting has all been driven by these algorithms that can learn. Similar to AI, the world of ML has multiple disciplines. The one we’re interested in is supervised learning.</p>
<div class="text-center">
<p><img src="https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/image3.png" class="img-fluid"></p>
</div>
<p><a href="https://contenteratechspace.com/how-different-are-conventional-programming-and-machine-learning/">image source</a></p>
</section>
<section id="supervised-learning" class="level4">
<h4 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h4>
<p>Supervised learning is a type of machine learning where you teach a computer to make predictions or decisions using examples. It’s like teaching a child to identify animals by showing them pictures of different animals and telling them what each one is. In supervised learning, you give the computer a bunch of “input” data (like pictures of animals) and the correct “output” (the names of the animals). The computer learns from these examples, and over time it gets better at predicting the outputs based on new inputs it hasn’t seen before. There are a few different flavors of supervised learning, but in this learning series we care about regression.</p>
</section>
<section id="regression" class="level4">
<h4 class="anchored" data-anchor-id="regression">Regression</h4>
<p>Regression is a type of supervised learning method that helps predict a numerical value based on past data. Imagine you want to predict the price of a house based on its size, location, and number of rooms. Regression analyzes the historical data of house prices and their characteristics to find a relationship. Once this relationship is understood, you can input the characteristics of any house and the regression model will predict its price.</p>
<p>Traditional regression modeling usually doesn’t have a time component, but when you need to predict a number over time, that’s when we enter the crazy world of time series.</p>
</section>
<section id="time-series" class="level4">
<h4 class="anchored" data-anchor-id="time-series">Time Series</h4>
<p>A time series is a series of numerical data points recorded at regular intervals. For example the highest temperature each day over the last 10 years can be thought of as one time series. If we have that temperature data for 50 cities, then we have 50 time series in our dataset. A time series can be at any kind of time interval. Yearly, quarterly, monthly, daily, hourly, etc. You get the idea.</p>
<p>The art of forecasting is just taking historical time series data, and feeding it into a model that can learn from historical trends and seasonality patterns. Ultimately creating a future prediction for the next few periods of time.</p>
<p>Most regression models in machine learning can be turned into a time series forecast model by the process of incorporating time dependant data as features through a process called feature engineering. A feature is just a variable in your dataset that can be used to help predict your target variable. The process of creating features before you train a model is called feature engineering. The target variable is what you want to predict going forward. These machine learning regression models can be thought of as multivariate models, since they can incorporate many different variables or features into a model.</p>
<p>Let’s apply this to a quick example. For a monthly revenue time series forecast, our target variable will be the revenue variable in our dataset. And we can create features like month of the year, how much money we made in the same month last year, etc. to help predict revenue.</p>
<p>There are also models that only exist in the world of time series forecasting. These are more statistical models and less machine learning models. Meaning they operate like equations that can applied to your data compared to a machine learning model that tries to learn the patterns underlying the data. These models are often univariate, which means that you only need the historical target variable values accompanied by a timestamp (list of dates) to train these models. While they might be simple in nature, they are still very useful even today. Often beating more complex models like deep learning.</p>
</section>
</section>
<section id="time-series-example" class="level3">
<h3 class="anchored" data-anchor-id="time-series-example">Time Series Example</h3>
<p>Now that we’ve peeled back all of the layers on time series forecasting, let’s take a look at some data. In this learning series I will be using the most common time series that applies to every company in the world, historical revenue. The data we’ll use is completely made up, but created in a way to illustrate a lot of the learning concepts throughout the series. The sales data is recoded at a monthly level, broken out by countries our hypothetical company operates in and what products it sells. Let’s take a quick look at the data.</p>
<p><a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">You can find the raw data here.</a></p>
<p><img src="https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/chart1.png" class="img-fluid"></p>
<p>In the data there are sales for two countries across two products. This means we have four unique time series we can forecast. One for each unique combination of country and product. Throughout this learning series we will use this data as an example as we work through different time series concepts.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Time series is a very niche corner in the AI universe. It may seem small but in reality every company in the world deals with time series. They make up most financial data like sales and are top of mind for every leader in the C-suite. You should now know what a time series is and understand more of the common terms you will hear around machine learning. Now that we have a good foundation of terminology, lets explore the data even more in the next post.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/</guid>
  <pubDate>Wed, 02 Oct 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Thoughts On Time Series Forecasting Fundamentals</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/</link>
  <description><![CDATA[ 





<p>The ability to create forecasts about the future is a superpower. Machine learning (ML) models take this to another level by increasing forecast accuracy while reducing the time spent creating the forecast. Using ML might seem a little scary at first. You may not know where to start. Type “intro ML course” into Bing and you’ll probably get millions of links. Which ones are good? Why do they cost $5,000? That’s why I wanted to create a gentle introduction to time series forecasting with ML. Where I start from first principles and work our way up to shipping forecasts in production. The intent is to cover the core theory of ML forecasting, and less on the code itself. The code can come later, but anyone who consumes the outputs from ML or helps train ML models needs a strong understanding of how this process works.</p>
<p>The sequence of what you learn is just as important as what content you learn. I have developed a learning path that takes you from absolute beginner and slowly adds new concepts until you’re a forecasting master! Please click on each link in order to get up to speed, or skip around to any topic you want to dive into again. Don’t try to read this all in a day, take your time, take notes, and maybe even paste some of the posts into your favorite AI tool to quiz yourself on the topics. Happy learning!</p>
<section id="our-learning-journey" class="level3">
<h3 class="anchored" data-anchor-id="our-learning-journey">Our Learning Journey</h3>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-10-02-ts-fundamentals-whats-a-time-series/">What’s a time series?</a></li>
<li><a href="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/">Exploratory Data Analysis</a>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-10-15-ts-fundamentals-eda-data-shape/">Shape of the Data</a></li>
<li><a href="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/">Time Series Decomposition</a></li>
<li><a href="https://mftokic.github.io/posts/2024-11-12-ts-fundamentals-autocorrelation/">Autocorrelation</a></li>
<li><a href="https://mftokic.github.io/posts/2024-11-26-ts-fundamentals-missing-outliers/">Missing Values, Outliers</a></li>
<li>External Regressors (in progress)</li>
</ul></li>
<li>Data Cleaning
<ul>
<li>Missing Values</li>
<li>Outliers</li>
<li>Box Cox Transformation</li>
<li>Stationary</li>
</ul></li>
<li>Univariate Models
<ul>
<li>ARIMA</li>
<li>Exponential Smoothing</li>
<li>Simple Benchmark Models</li>
</ul></li>
<li>Evaluation Metrics</li>
<li>Feature Engineering
<ul>
<li>Date</li>
<li>Target Variable</li>
<li>External Regressors</li>
</ul></li>
<li>Multivariate Models
<ul>
<li>Local Models</li>
<li>Global Models</li>
<li>Hyperparameter Tuning</li>
<li>Linear Regression</li>
<li>Decision Trees</li>
<li>Random Forest</li>
<li>Gradient Boosting (XGBoost, LightGBM)</li>
<li>Feature Selection</li>
<li>Mutlistep Horizon, Autoregressive</li>
</ul></li>
<li>Model Training Lifecycle
<ul>
<li>Train/Test Splits</li>
<li>Time Series Cross Validation</li>
<li>Evaluation Metrics</li>
</ul></li>
<li>Hierarchical Forecasting
<ul>
<li>Standard Hierarchy</li>
<li>Grouped Hierarchy</li>
<li>Clustering</li>
</ul></li>
<li>Combining Models
<ul>
<li>Simple Averages</li>
<li>Weighted Averaged</li>
<li>Ensemble Models</li>
</ul></li>
<li>Prediction Intervals</li>
<li>Model Interpretability
<ul>
<li>Model Specific</li>
<li>Model Agnostic
<ul>
<li>Global Methods</li>
<li>Local Methods</li>
</ul></li>
</ul></li>
<li>Forecasts in Production
<ul>
<li>Parallel Computing</li>
<li>Model Training and Serving</li>
</ul></li>
<li>Appendix
<ul>
<li>ML Term Glossary</li>
</ul></li>
</ol>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/</guid>
  <pubDate>Wed, 25 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>My Path from Finance Intern to Senior Software Engineer at Microsoft</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-09-04-sde-career-path/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-09-04-sde-career-path/image.png" class="img-fluid"></p>
<p>I write code every day as a senior software engineer at Microsoft. But I didn’t use to. When I came to Microsoft as an intern in summer 2015, I was just your ordinary finance intern. The only code I knew was excel formulas. During the summer I realized the power of data+code and made it my mission to figure it out.</p>
<p>I have previously written about my journey in <a href="https://mftokic.github.io/posts/2024-02-19-frp-journey/">Microsoft’s Finance Rotation Program (FRP)</a>. That details the first half of my career and how I got my first engineering job, but not what I do today as a senior software engineer. Most of my time is spent on building and operating machine learning systems used by others across the finance organization. It’s been a hard journey, but also a fun one. If you’re like me and are interested in making the switch, here are some pieces of advice that might help you. Like all advice, take it with a grain of salt. Advice is like getting last years winning lottery numbers. They might have worked for that person in the past, but it may not work for you. Anyways I hope you find it helpful.</p>
<section id="focus-on-slope-over-intercept" class="level3">
<h3 class="anchored" data-anchor-id="focus-on-slope-over-intercept">Focus on Slope over Intercept</h3>
<p>When I came back as a full time employee after my internship, I kept seeing these new signs everywhere talking about something called a <a href="https://hbr.org/2016/01/what-having-a-growth-mindset-actually-means">“growth mindset”</a>. During my internship these words were never mentioned. Now they are taped to every blank wall on campus. What’s going on? Microsoft’s CEO, Satya Nadella, was in the midst of working on a culture shift at the company. Trying to go from employees that were “know it alls” to a more improved “learn it all”. This new attitude was perfect for me because I knew jack squat about coding, and I wanted to learn.</p>
<p>If you want to pivot your career into software engineering, there are two ways to go about it. The first and most common is to go to school and get a degree. The second is to figure it out on your own, aka the learn it yourself path. Both paths have their pros and cons. Going to school is the more direct path, but self-learning may have a different kind of benefit. If you’ve only ever learned how to code on your own, then you are setting yourself up for lifelong learning. As opposed to someone who went to school, who is used to classroom learning. The learning never stops once you start coding for money, so having the skill to learn proactively and not on a predetermined schedule is a super power.</p>
<p>Having technical knowledge from school puts you ahead of someone else who is just starting to learn on their own. But if that self-taught person is learning at a pace higher than the school smart person, eventually their trajectories will cross and the self-taught coder will surpass them. Think of it like a graph. Where school knowledge gives you a high Y intercept, a good starting point, but the rate of your learning every day after is the slope. The most important thing is to focus on the slope over the intercept.</p>
<p><img src="https://mftokic.github.io/posts/2024-09-04-sde-career-path/image2.png" class="img-fluid"></p>
<p>The learning never stops. In fact it only get’s harder. Not the learning itself (maybe it does), but taking the time to learn. Build the habit now, stay curious. The biggest trap is getting into the mindset of “I’ll start learning new things again once current xyz thing cools down”. That thing might be a new job, getting married, having a kid. As your responsibilities grow in life, your free time shrinks in proportion. Make sure learning stays a priority.</p>
<p>A good way to learn on your own while having an existing job is to make the learning part of your job. If you want to learn more about AI technology, go tell your boss that you want to work on a project with AI that could help the team. I’m 100% positive you’re boss will say yes. Getting free engineering help is usually not turned down by anyone. We all need better software in our lives. Once your boss expects you to deliver on something, with a deadline, then that’s the healthy pressure needed to go out and learn the damn thing. In addition to signing up for project work you can also do the same for traditional learning through books, courses, and certifications. For me back in the day I told my boss I was going to finish a Microsoft sponsored course in data science by xyz date. Each month I would provide her updates on my progress. Finishing that course become one of my deliverables in my job. That allowed me to spend some time each day at work on learning, without feeling guilty because it was actually part of my job to learn. Make it part of your job and things become a lot easier. Compared to squeezing in a few minutes before or after work without telling anyone. If your upcoming performance review is tied to reading a few books and building a new thing for your team, you will have all the motivation you need to get it done.</p>
<p>If you can’t find any good projects on your team, look elsewhere. You could go help another team at your company that might need some coding help, or a local charity or organization you care about. Towards the end of my time in the FRP, I stumbled across a team at Microsoft called the <a href="https://www.microsoft.com/en-us/corporate-responsibility/airband-initiative?msockid=0aa1dafa17d06b740264ce5816656a0b">Airband Initiative</a>. This team is focused on growing internet access to communities all around the world. They needed some help crunching data from policy documents and with zero experience I was able to come join the team as a temporary resource to help them with this analytics project. I was free labor so they didn’t have anything to lose, but I had everything to gain. I got good experience with natural language processing and working with unstructured data. Eventually the project grew. I ended up presenting the whole thing to Microsoft’s chief data scientist and even got to showcase the work at the 2019 Internet Governance Forum in Berlin. Where all my expenses were paid. All because I spoke up and offered to help. The Airband team got help, I learned a ton, and become an international data traveler. Talk about a win-win-win.</p>
<p>Maybe you’re still in school, but want to pick up some coding skills. Go see if any student organizations need help analyzing data or updating their website. Maybe the Football team could use another hand at analyzing what plays work best on third down, or if the basketball team needs to play a smaller lineup to score more points. The coffee shop in your business school might need some help on seeing what kind of sales promotions bring in the most revenue. The opportunities are endless. And because you’re offering your services for free they will not turn you down.</p>
<p>Last thing I’ll say about learning is that I’ve seen too many people get a masters in data analytics, AI, computer science, etc. only to get a job post-school that does none of that. It’s a shame. Don’t settle. Don’t give up. Keep learning.</p>
</section>
<section id="real-coders-ship" class="level3">
<h3 class="anchored" data-anchor-id="real-coders-ship">Real Coders Ship</h3>
<p>Real coders don’t just take classes and read books. They ship, meaning they build stuff and put it out into the universe. My learning only started when I put the books down and started pulling real data and training real machine learning models. Projects that actually helped my team in my current job, even if that job wasn’t software engineering. Shipping 10 projects is more impressive than acing 10 classes.</p>
<p>Some people create a “portfolio” of projects and have it live on their GitHub. I don’t think that’s a good idea. Real work is messy, and is the best indicator of future performance to an employer. Projects in a portfolio allow you to control all the variables, which is not how the real world works.</p>
<p>You can have public GitHub repos that show as samples of your work. But they should not be sample projects. They should either be pieces of work that you applied in your real job made open source and accessible to others. Or side projects where you wanted to build something cool to help you in your personal life or another organization. For example if you built your own website for your wedding, and had the code in a GitHub repo for hiring managers to see your coding chops. Or you built a bot that constantly analyzes your fantasy football league’s waiver wire and automatically picks up the best players for you based on AI powered analysis. There are endless ideas. Get building. Go out and ship.</p>
</section>
<section id="ai-is-your-friend" class="level3">
<h3 class="anchored" data-anchor-id="ai-is-your-friend">AI is Your Friend</h3>
<p>In this post ChatGPT era, all technical work becomes 100x easier to learn. You don’t need school, or even books. You can, for free, start using a large language model (LLM) to learn coding concepts and even have it ask you technical questions to test your learning.</p>
<p>ChatGPT and other tools like GitHub Copilot now become your coding buddy, always there to help you when you get stuck or don’t know how to do something. Any new kid on the coding block can now get up to speed on languages like Python quickly because they have a personal AI tutor available 24/7. Go pay for a few of these AI services, and use them every day.</p>
</section>
<section id="use-your-competitive-advantage" class="level3">
<h3 class="anchored" data-anchor-id="use-your-competitive-advantage">Use Your Competitive Advantage</h3>
<p>Some people feel like coming into software engineering from a nontechnical discipline is a major handicap. I actually think it’s a superpower. If you come from a business background you actually have something other engineers do not. Business domain knowledge combined with technical knowledge is a deadly combination. You now understand both sides of the coin. You know how to make decisions about the business (through the lens of marketing, finance, sales) and can now go and build things that improve how the business serves customers.</p>
<p>For me having a finance background first, then learning coding second was a good combination. It created a lot of skills that are now invaluable. For example the skill of communicating things in simple terms. When I was building machine learning solutions for finance users, no one cared about the sophistication about my model or how much feature engineering I applied to the data. They just wanted to know how the solution ran at a high level and if it actually worked by showing improvements in a certain metric. For example, creating a more accurate revenue forecast for a Microsoft product. I’ve seen traditional data scientists/engineers try to explain their work to regular people and it can sometimes be like nails on a chalkboard. It’s painful to watch because they cannot explain themselves in plain english. And if the end user can’t understand how something works, then they won’t trust it, which means they won’t use it.</p>
<p>Usually being 80% competent at two skills can create more impact than being 99% competent in a single skill. Focus on <a href="https://personalexcellence.co/blog/talent-stack/">combining skills</a>. If you can build and you can sell, you will be unstoppable.</p>
</section>
<section id="baby-steps-not-one-giant-leap" class="level3">
<h3 class="anchored" data-anchor-id="baby-steps-not-one-giant-leap">Baby Steps, Not One Giant Leap</h3>
<p>Don’t go and build the next social networking app on your first coding project. Crawl, walk, then run with new technology. Here is a good workflow for learning progression.</p>
<ol type="1">
<li>Crawl: Get some code working on your computer.</li>
<li>Walk: Move that code up into the cloud and have it run on a different machine that’s not yours.</li>
<li>Run: Build a production ready system with proper CI/CD, unit testing, version control, etc.</li>
</ol>
<p>Those steps can take years, and that’s ok. You might even get a software engineering job with just knowledge of #1. But as you progress you will eventually figure out #2 and #3. The same can be said for the actual job progression.</p>
<ol type="1">
<li>Business Partner: You are the business person who works with the engineers.</li>
<li>Program Manager: Now you are the person in the middle between the business partner and the software engineer. This is an engineering role, and in some companies like Microsoft your compensation will be the same as a software engineer.</li>
<li>Software Engineer: You now build things, in collaboration with the program manager who tells you what the business partner needs.</li>
</ol>
<p>Going from business partner, to program manager, to software engineer is a lot easier than skipping directly to software engineer. When I graduated the FRP my first role title was “IT Solution Manager”. I still don’t know what that means. Overall I was basically a program manager that coded on the side when no one was looking. Eventually that side coding turned into real solutions I pitched to my manager and got into production. Which eventually led me to working solely on building things. Then I finally got the title of software engineer. It didn’t happen overnight, but it was possible.</p>
</section>
<section id="getting-promoted" class="level3">
<h3 class="anchored" data-anchor-id="getting-promoted">Getting Promoted</h3>
<p>Ok so maybe you now have a sweet engineering gig. Now what? How do you grow your career? Let’s talk about getting promoted.</p>
<p>You get promoted when what you build has impact. Not just for building cool or complex things. Most impact with technology can boil down to a few things.</p>
<ol type="1">
<li>Time savings</li>
<li>Money savings</li>
<li>Increasing revenue</li>
</ol>
<p>You work needs to boil down to numbers. Not what you shipped but what happened after you shipped it. Most impact is money and time. Either saving it or getting more of it. <strong>What gets measured gets managed. What gets measured gets promoted.</strong> Training a deep learning model is cool but shipping a simple linear regression in half the time might get you promoted twice as fast. Everyone is in sales. Once you build it, you have to sell it. If you can build and sell, you will be unstoppable. Ask your boss what you need to do this year to get promoted, then do those things. Ruthlessly prioritize and execute. Ignore everything else.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Learning to code is important. Life is all about leverage. The best types of leverage in the world are permissionless leverage. They have no marginal costs of replication. These are things like code and content (podcasts, blog posts, etc.). Why do you think I wrote this? Because this kind of content has leverage, meaning it can scale. It’s easier to write this once then to give the same advice to 100 people who ask for it. Save your keystrokes folks. That’s why this personal blog exists. Hopefully it’s helpful to you my dear reader 😊.</p>
<p>Pretty soon everyone will be a manager, just not managing people. You will manage AI people, or bots/agents, who will do your work for you. Knowing how technology works will help you grow your leverage, whether you’re a software engineer or not. Most things 50 years from now will boil down to AI doing the thinking plus executing digital tasks, and robots executing physical tasks. What do you think those run on? You guessed it, code. Software will eat the entire world, it’s just a matter of time. I’d rather be giving our robot overlords instructions then taking instructions from them. Everyone will have a choice. Take the red pill. Go all the way down the rabbit hole. Learn some code.</p>
<p>Last thing I’ll say is that it takes guts to move to a new field. People who only do what their boss tells them to do will never have the guts to do it. It takes a certain amount of high agency to do it. If you’re considering or are already in the process of doing it, I salute you. The world needs more people like you. Good luck!</p>


</section>

 ]]></description>
  <category>life</category>
  <category>finance</category>
  <category>career</category>
  <guid>https://mftokic.github.io/posts/2024-09-04-sde-career-path/</guid>
  <pubDate>Wed, 04 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-09-04-sde-career-path/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (8/30/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-08-30-weekend-reads/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-08-30-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://www.muskfoundation.org/">Elon Musk’s Foundation Page</a>: money talks, wealth whispers</li>
<li><a href="https://thielfellowship.org/apply">Thiel Fellowship App</a>: should be the application for most jobs</li>
<li><a href="https://eugeneyan.com/writing/prompting/">Prompt Engineering Fundamentals</a></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=WO5m-roVzjg">24 Controversial Truths About Success and Failure on Modern Wisdom</a></li>
<li>One of a Kind Guy on My First Million
<ul>
<li><a href="https://www.youtube.com/watch?v=SVwLEocqK0E">Part 1</a></li>
<li><a href="https://www.youtube.com/watch?v=W_oJJtSvCcA">Part 2</a></li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=TRnoCjPzmV8">Incentive Masterclass on My First Million</a></li>
<li><a href="https://www.youtube.com/watch?v=qDw8zT7pCdQ">WHOOP CEO on Diary of a CEO</a></li>
<li><a href="https://www.youtube.com/watch?v=ROuPd-Cwrbo">New OpenAI Developments on AI for Humans</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/ajassy/status/1826608791741493281">Amazon CEO Automates Tech Debt with AI</a></li>
</ul>
</section>
<section id="products" class="level2">
<h2 class="anchored" data-anchor-id="products">Products</h2>
<ul>
<li><a href="https://elemindtech.com/">Headband That Puts You to Sleep</a></li>
</ul>
</section>
<section id="songs" class="level2">
<h2 class="anchored" data-anchor-id="songs">Songs</h2>
<ul>
<li><a href="https://open.spotify.com/track/0dbTQYW3Ad1FTzIA9t90E8?si=Zky16-6eRf--T-1ZIV82NQ&amp;nd=1&amp;dlsi=16a2bd4780d24517">Mona Lisa by Lil Wayne</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-08-30-weekend-reads/</guid>
  <pubDate>Fri, 30 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-08-30-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (8/23/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-08-23-weekend-reads/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-08-23-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-08-12-ml-fcst-faq/">Simple Answers to Hard ML Forecasting Questions</a></li>
<li><a href="https://info.deeplearning.ai/llm-price-war-black-forests-powerful-open-image-generator-the-high-cost-of-ai-leadership-machine-translation-goes-agentic?ecid=ACsprvurcocB85Yj2tmm-kaWhU7MjIxZkryFxNSQQ4iYRIhIzhvbptMewhYJmzlP30TSYdWmaxLc&amp;utm_campaign=The%20Batch&amp;utm_medium=email&amp;_hsmi=320139015&amp;utm_content=320139015&amp;utm_source=hs_email">LLM Performance vs Price</a></li>
<li><a href="https://fortune.com/2024/08/14/google-eric-schmidt-working-from-home-ai-openai/">Ex Google CEO on Work From Home</a></li>
<li><a href="https://www.wired.com/story/the-english-premier-league-has-a-new-iphone-powered-offside-detection-system/">Fixing Offsides in Soccer for Good</a></li>
<li><a href="https://www.popsci.com/technology/ai-tongue-scanner/">AI Tongue Scans Spot Disease Early</a></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=FyLwVyJ9uXw">Breathing Expert on Diary of a CEO</a></li>
</ul>
</section>
<section id="podcasts" class="level2">
<h2 class="anchored" data-anchor-id="podcasts">Podcasts</h2>
<ul>
<li><a href="https://open.spotify.com/episode/2DFsA7qIdjZZukcCRbBRhI?si=mck3VapCQLilUMkwV1xkhA&amp;nd=1&amp;dlsi=d2c18c0011b14af7#login">Peter Thiel on Joe Rogan</a></li>
<li><a href="https://open.spotify.com/episode/6KBpL2XfR9VdojbKNpE7cX?si=74CSFwnNQXavZTUYX6VpIA&amp;context=spotify%3Acollection%3Apodcasts%3Aepisodes&amp;nd=1&amp;dlsi=fced64e3e9304a60">Pieter Levels on Lex Fridman</a></li>
</ul>
</section>
<section id="movies" class="level2">
<h2 class="anchored" data-anchor-id="movies">Movies</h2>
<ul>
<li><a href="https://truefilms.com/kumare/">Kumare</a></li>
<li><a href="https://truefilms.com/10-mph/">10 mph</a></li>
<li><a href="https://truefilms.com/bill-cunningham/">Bill Cunningham New York</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-08-23-weekend-reads/</guid>
  <pubDate>Fri, 23 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-08-23-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>FAQ on Machine Learning Forecasting</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-08-12-ml-fcst-faq/</link>
  <description><![CDATA[ 





<p>Over the last few years I’ve presented to hundreds of people outside of Microsoft around how we approach machine learning (ML) forecasting within Microsoft finance. A lot of great questions were asked during those conversations. In this post I want to highlight some of the most commonly asked questions and my take on answering them. Hopefully this can be a quick reference for anyone ML curious or want to deepen the ML work being done on their teams. Use the table of contents to skip around to the sections you’re most interested in. If there are any topics missing please reach out to me via <a href="https://www.linkedin.com/in/michaeltokic/">LinkedIn</a> and I will continue to update this post.</p>
<section id="toc" class="level2">
<h2 class="anchored" data-anchor-id="toc">FAQ Table of Contents</h2>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">Data</h3>
<ul>
<li>Getting high quality historical data</li>
<li>Using third party data</li>
<li>New info not found in the training data, one time events</li>
<li>Handling outliers</li>
</ul>
</section>
<section id="technical" class="level3">
<h3 class="anchored" data-anchor-id="technical">Technical</h3>
<ul>
<li>Interpreting the black box</li>
<li>What models to use, should we use deep learning</li>
<li>What programming language or framework to use</li>
<li>Using large language models like ChatGPT to forecast</li>
<li>What level of accuracy is good</li>
</ul>
</section>
<section id="humans" class="level3">
<h3 class="anchored" data-anchor-id="humans">Humans</h3>
<ul>
<li>How to make forecast owners accountable for the ML number</li>
<li>Building trust in the ML forecast</li>
<li>Who owns the ML creation process</li>
<li>How to get started with ML</li>
<li>Going from ML as a triangulation point to replacing manual human forecasts</li>
<li>Building data science talent in finance</li>
</ul>
</section>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<section id="historical-data" class="level3">
<h3 class="anchored" data-anchor-id="historical-data">Getting high quality historical data</h3>
<p><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage in, garbage out</a>. That’s probably the most common saying in the world of ML. If you cannot get high quality historical data, then there is no easy way to produce an accurate ML forecast. You can’t work your way around noisy or incomplete data. If your data is messy, hard to find, and comes from 10 different systems, then ML is not something you should be worried about. A nice bow on top of a pile of crap is still a pile of crap. Fix your data first, then focus on ML after.</p>
<p>Back to Table of Contents</p>
</section>
<section id="third-party-data" class="level3">
<h3 class="anchored" data-anchor-id="third-party-data">Using third party data</h3>
<p>Your company’s business is most likely impacted by greater market forces outside of your control. For example the health of the economy or how much money customers have to spend. Adding data from outside of your company (third party data) as features in your ML models is a good way to improve forecast accuracy, while also being able to describe what outside forces impact your business the most. Some data is freely available, while others have to be paid for. What data you use is up to your domain knowledge of your business.</p>
<p>Free Data</p>
<ul>
<li><a href="https://fred.stlouisfed.org/">FRED</a></li>
<li><a href="https://data.worldbank.org/">World Bank</a></li>
<li><a href="https://data.imf.org/?sk=388dfa60-1d26-4ade-b505-a05a558d9a42">International Monetary Fund</a></li>
<li><a href="https://data.un.org/">United Nations</a></li>
<li><a href="https://trends.google.com/trends/">Google Trends</a></li>
</ul>
<p>Paid Data</p>
<ul>
<li><a href="https://www.idc.com/data-analytics">IDC</a></li>
<li><a href="https://tradingeconomics.com/indicators">Trading Economics</a></li>
</ul>
<p>Back to Table of Contents</p>
</section>
<section id="one-time-events" class="level3">
<h3 class="anchored" data-anchor-id="one-time-events">New info not found in training data and one time events</h3>
<p>If you are changing the price of your product in three months, this is most likely going to impact your future revenue forecast. But if you have never changed the price of your product before, then a ML model cannot learn from that information. For a model to learn from one time events, it needs to be present in the historical data a model is trained on. <a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The future must always learn from the past</a>.</p>
<p>Back to Table of Contents</p>
</section>
<section id="outliers" class="level3">
<h3 class="anchored" data-anchor-id="outliers">Handling Outliers</h3>
<p><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/#outliers">Outliers</a> in your data can have a bad impact on your future forecast. It can hurt accuracy or give false signals of the future. There are many ways to deal with outliers. The easiest way is to use statistical methods to identify and remove them. Treating them as a missing value you can then replace. Sometimes outliers are more subtle, and take a trained eye to spot them. This is where the <a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">domain expertise</a> of a person comes into play.</p>
<p>Back to Table of Contents</p>
</section>
</section>
<section id="technical" class="level2">
<h2 class="anchored" data-anchor-id="technical">Technical</h2>
<section id="black-box" class="level3">
<h3 class="anchored" data-anchor-id="black-box">Interpreting the black box</h3>
<p>This one is a toughie. When a person creates a forecast manually, most often using excel, someone else can come into that financial model and trace cell by cell exactly what’s going on. Going from input data, to assumptions, to the formulas that create the final output. This is the kind of exactitude that allows accountants to sleep peacefully at night. Everything is in order and everything is perfectly understood. But we are not accountants. This is finance. We have to make calls about the future that are uncertain. We can never have 100% certainty that something is going to happen. If that’s the case then your company is doing something illegal. Get out now!</p>
<p>The biggest paradigm shift someone has to make with machine learning is giving up this total control of the forecast. And in essence take a <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/#leap-of-faith">leap of faith</a>. Machine learning models are enigmas. Sometimes akin to magic. The cannot be perfectly understood because the capture non-linear relationships in data that a human never could. That’s why we have them, because they can work better and faster than our human brains in some tasks.</p>
<p>There are ways to understand these models, but they cannot be perfectly audited like a manual forecast done in excel. Instead they have to be interrogated. Not like a criminal wanted for war crimes but more like a therapist talking to their patient. There is no way for a therapist to know exactly what’s going on inside of their patients mind. But they can start to ask questions that can give clues into what’s going on and see why the person has made past decisions in their life.</p>
<p>The best resource I know on explaining ML models is <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a> by Christoph Molnar. Here’s a quick overview of the method’s described in the book.</p>
<ul>
<li><strong>Model Specific:</strong> These are models like linear regression or a single decision tree where we can see exactly what’s going on under the hood. The model structure is more like an excel formula we can trace step by step. But because they are easy to explain, they are simple in nature and may not produce the most accurate forecast. That is the tradeoff between having a forecast that can be easily explained versus having a forecast that is the most accurate. The more accurate the forecast, the more likely you cannot explain it perfectly.</li>
<li><strong>Model Agnostic:</strong> For more advanced models like gradient boosted trees and deep learning, we can use methods that approximate what’s going on under the hood of a complex model. This is when we have to act like a therapist and start asking questions to our model and see what answers it gives back. There are two ways of doing this.
<ul>
<li><strong>Global Interpretability:</strong> This uses methods that can see overall what’s impacting the model the most. For example you can see what input variable (or feature) is the most important in the model overall.<br>
</li>
<li><strong>Local Interpretability:</strong> This uses methods to see what’s going on for each individual forecast data point. For example you can see for a specific future forecast what’s impact that number the most.</li>
</ul></li>
</ul>
<p>The last thought I’d leave you with is this. Have you ever not used ChatGPT because you couldn’t get an explanation of its answer? For example maybe you asked it to help you write some excel formulas to format dates. Do you trust the output it gave you because the excel formula was correct or because it could tell you exactly how it came to that conclusion? What if the explanation it gave was made up or a hallucination? If the excel formula is correct you would still use it right? Even the CEO of OpenAI, Sam Altman, cannot explain how models like GPT-4 think under the hood. But hey, ChatGPT was still the fastest growing product of all time. Sometimes imperfect interpretability is ok. But maybe your CEO is still demanding an explanation of the forecast numbers, so this is <a href="https://mftokic.github.io/posts/2023-02-11-three-levels-of-ml-adoption/">still a hard problem to solve in finance</a>.</p>
<p>Back to Table of Contents</p>
</section>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">What models to use, should we use deep learning</h3>
<p>People are always attracted to the hot new thing, and I can’t blame them. New is exciting. When it comes to ML forecasting, new isn’t always better. The newest trend in ML is all about deep learning. Or models that can mimic the human brain. While they work really well for things like analyzing photos and text, using them on tabular data (aka excel data) hasn’t always worked out well. That’s why I <a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">recommend using deep learning last</a>.</p>
<p>Here are the models to use first, then you can always resort to deep learning if need be.</p>
<ul>
<li><strong>Univariate Models</strong>: These are the simplest forecasting models. Since they only need one variable, hence the name univariate. If you want to forecast revenue, then you only need historical revenue and you’re off and running. They run extremely fast and can scale to millions of data combinations without spending too much on cloud compute. Here are a few popular ones.
<ul>
<li><strong>ARIMA</strong>: An ARIMA (AutoRegressive Integrated Moving Average) model predicts future values in a time series by combining differencing (modeling the difference between periods), autoregression (using past values), and moving averages (using past forecast errors). It’s the most common univariate model in the forecasting game.</li>
<li><strong>Exponential Smoothing</strong>: Forecasts future values in a time series by applying decreasingly weighted averages of past observations, giving more importance to recent data points to capture trends and seasonal patterns.</li>
<li><strong>Seasonal Naive</strong>: Predicts future values by simply repeating the observations from the same season of the previous period, assuming that future patterns will mimic past seasonal cycles. Don’t sleep on this one! You’d be surprised how often it comes in handy as a good benchmarking model to compare with more complicated models.</li>
</ul></li>
<li><strong>Traditional ML Models</strong>: After trying univariate models, it’s time to try more traditional machine learning models. These are models built specifically for tabular data, or data that can live in a SQL table or excel spreadsheet. These models are multivariate, which allow them to incorporate outside variables as features to improve their forecast accuracy. They require more handling than a model like ARIMA, since they need <a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">feature engineering</a> and proper <a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">time series cross-validation</a>. Multivariate models can also learn across multiple time series at the same time, instead of being trained on just a single time series like a univariate model. Here are a few common multivariate models.
<ul>
<li><strong>Linear Regression</strong>: Predicts future values by fitting a line to the historical data, where the line represents the relationship between the dependent variable and one or more independent variables.</li>
<li><strong>XGBoost</strong>: Predicts future values using an ensemble of decision trees, boosting their performance by iteratively correcting errors from previous trees, resulting in a highly accurate and robust prediction model.</li>
<li><strong>Cubist</strong>: Predicts future values by combining decision trees with linear regression models, creating rule-based predictions that incorporate linear relationships within each segment of the data for greater accuracy.</li>
</ul></li>
</ul>
<p>Back to Table of Contents</p>
</section>
<section id="language" class="level3">
<h3 class="anchored" data-anchor-id="language">What programming language or framework to use</h3>
<p>Should I use python? But what if I learned R in my statistics class? What about stata or good ole javascript? Ask 10 data scientists what programming language to use and you’ll probably get 10 different answers. There is no right answer. It’s kind of like arguing what hammer to use when building a house. Shouldn’t we just be worried about getting the house built? And make sure we don’t screw it up?</p>
<p>Here is my take on the ML language wars. You should use both, python and R. Different languages offer different things, and depending on the task you might want to use one over the other. Often it’ll boil down to specific open source software that might only be available in one language but not the other. So over the course of a long data career it’s probably a good idea to be competent at both.</p>
<p>With that said, if you could only learn one programming language, learn python. That’ll get you the farthest the fastest in terms of useful knowledge to get building. I think in a few years these debates will go away, because large language models (LLM) will come and save the day. Imagine writing code in your favorite language, using the packages you like, and then have a LLM take your code and translate it into blazing fast machine code that runs like a race car. So it won’t matter if you only know one language or the other. That’s where I hope we’re headed.</p>
<p>Back to Table of Contents</p>
</section>
<section id="llm" class="level3">
<h3 class="anchored" data-anchor-id="llm">Using large language models like ChatGPT to forecast</h3>
<p>With the explosion of large language models (LLM) that can do everything from tell dad jokes to write production grade code, can’t we just offload all forecasting work to them? In essence you could, but I think it’s kind of overkill and leaves a lot to be desired. LLMs take in text, and spit out text. They are good with words, but not that good with numbers. They can’t perform on par with a calculator, because that’s not how they were designed. So you can’t just copy a table from excel, give it to ChatGPT, and hope to get next quarters revenue forecast. It might give it to you, but it won’t be a good forecast. It might even make something up.</p>
<p>The more sensible route to take is to have the LLM write code that can create forecast models and have it execute it for you. For example use the code interpreter feature in ChatGPT to have it take your uploaded CSV file and execute a bunch of python code against it to get a final forecast. This kind of workflow might be good for initial exploration, but it shouldn’t be used in a production setting where you need an updated forecast each month. It’s kind of like needing a place to sleep and each night you build a new house from scratch, only sleep there one night, then the next night build another house from scratch. Having LLMs produce code on the fly each time can lead to inconsistent results that may not be reproducible when you ask ChatGPT to do it again. You could take the code from the first forecast iteration, save it, and either run it yourself each time or give it to ChatGPT as a prompt. But even then you are still missing out. Some automated forecasting packages, like the one I own called <a href="https://microsoft.github.io/finnts/index.html">finnts</a> have over 10,000 lines of code. So a LLM will most likely not be writing that much code to answer one prompt, and if they did having you trying to save and manage that code is out of the question.</p>
<p>I think LLMs can still have some part in the forecasting process. They are useful before and after the actual model training is done. For example you can have code interpreter analyze your data for things like outliers or help in running correlation analysis to see what variables could help improve your forecast accuracy. Then you will take those learnings and run the forecast outside of the LLM environment, or you could have the LLM call an outside function to kick off a forecast. This is called “function calling”, where a LLM can use an outside tool (most often calling an API via code) that can accomplish the task a LLM cannot (like getting the current weather). LLMs can then be used after the forecast process is ran to then analyze the final forecast outputs. Tools like code interpreter can make charts and analyze historical back testing accuracy.</p>
<p>Maybe in the future the LLM can help explain how the final forecast was created, or better yet answer questions about forecast variance once actuals land in the future. But using it to actually create predictions or train models itself is still a tall order. With that said there are <a href="https://docs.nixtla.io/">new time series specific LLMs</a> that are being released, so this is an exciting area to watch closely.</p>
<p>Back to Table of Contents</p>
</section>
<section id="accuracy" class="level3">
<h3 class="anchored" data-anchor-id="accuracy">What level of accuracy is good</h3>
<p>There is no right answer. It all depends on the specific data you are using and how it compares to non-ML approaches you have done previously.</p>
<p>A common metric in time series forecasting is the MAPE error metric. MAPE stands for mean absolute percentage error. This is very similar to variance to forecast percent metrics you might already use. Think of it as the average percent error (as an absolute value) across every forecasted data point. There are plenty of other metrics out there, but MAPE is a good one since it’s not dependant on scale and percents are easy for anyone to wrap their head around.</p>
<p>A MAPE of 5% means that on average, your forecast is off plus or minus 5%. So the closer to zero the better. If you ask any finance person what kind of MAPE they want for their forecast, almost all of them will say less than 1%. Or more than 99% accuracy. Think of accuracy as the inverse of MAPE. Maybe the ML forecast has a MAPE of 10%, but your previous manual excel model ended up having a 20% MAPE. The ML forecast has a 50% reduction in forecast error, even though it’s still in the double digits. So evaluating ML is always relative to what kind of performance you got with other forecast methods probably done in excel.</p>
<p>With that said, here are some rules of thumb I use when running my own ML forecasts.</p>
<ul>
<li><strong>Daily and Weekly Data</strong>: Less than a 10% MAPE is terrific. But even MAPEs as high as 30% are ok, because often we might sum up a daily forecast to a monthly or quarterly level. And when evaluated at that aggregate level you may start to have drastically improved MAPEs.</li>
<li><strong>Monthly, Quarterly, Yearly Data</strong>: There are a few levels of accuracy that I think are good at this level. Again, it’s all relative to what kind of performance you had before using ML.
<ul>
<li>Less than a 5% MAPE is good</li>
<li>Less than a 3% MAPE is great</li>
<li>Less than a 1% MAPE is amazing</li>
</ul></li>
</ul>
<p>Even going from a 3% MAPE to a 2% MAPE is a big achievement. Because it’s a lot harder to do that than to go from a 15% MAPE to a 10% MAPE. It’s still the same level of improvement but once you get closer to zero the MAPE improvements seem to happen on a log scale. Where each percentage point you reduce continues to get harder as you get closer to zero.</p>
<p>Back to Table of Contents</p>
</section>
</section>
<section id="humans" class="level2">
<h2 class="anchored" data-anchor-id="humans">Humans</h2>
<section id="accountability" class="level3">
<h3 class="anchored" data-anchor-id="accountability">How to make forecast owners accountable for the ML number</h3>
<p>Having a ML model automate your forecast process is great, until you have to tell your CFO why your quarterly forecast is off by xyz%. “It was ML’s fault” is not the right answer. But it’s hard for a human to be on the hook for work that a machine did for them. Maybe the ML forecast came from another engineering team, so the final owner of the forecast maybe had no part in creating the forecast. This can make accountability hard.</p>
<p>In order to get people on board with transitioning more of their work to ML, you need senior leadership buy in. People at the top need to be invested in the promise of ML and the tradeoffs it might provide. Since you cannot audit a ML forecast like you can with an excel model (tracing cell by cell) there is an essential leap of faith that has to happen.</p>
<p>In addition to having senior leadership buy in to improve accountability, being able to adjust the output from ML can also help. Financial analysts can impart their domain expertise about their business by making small manual adjustments to the ML forecast. That way ML can get you 80% of the way to a completed forecast, and a human might make adjustments on that final 20% to finalize the forecast. Having the forecast owners be “humans in the loop” of a ML process adds a sense of ownership, which can then improve accountability.</p>
<p>A final way to improve accountability is through the <a href="https://insidebe.com/articles/the-ikea-effect/">Ikea effect</a>. Which states that we value things more if we are involved in making them. The best way for this to work is if the final forecast owners create their own ML forecast through self-serve tools that abstract away the complex of ML and allows analysts to upload data and get back forecasts with a few clicks of their mouse. This is exactly <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">what we did in Microsoft finance</a> and it has worked out well so far.</p>
<p>Back to Table of Contents</p>
</section>
<section id="trust" class="level3">
<h3 class="anchored" data-anchor-id="trust">Building Trust in the ML forecast</h3>
<p>Building trust in the ML forecast is the hardest part of using ML. There are three ways that have worked well in helping non-technical financial forecast owners warm up to and fully transition to using ML to forecast.</p>
<ul>
<li><strong>Historical Accuracy</strong>: The best way to get someone on board with a forecast into the future is to show them how well a similar forecast has performed in the past. It’s not a perfect proxy for future performance but gives the end user a good idea of how well a ML model is performing. Common performance metrics to use are <a href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error">MAPE</a> (mean absolute percentage error) and <a href="https://en.wikipedia.org/wiki/Root_mean_square_deviation">RMSE</a> (root mean squared error). MAPE is similar to existing variance to forecast calcs already done by financial analysts so it’s a good error metric to convey past performance. When calculating historical performance, aka back testing, it’s a good idea to create hypothetical forecasts for the most recent periods of your data. Making sure you cover enough historical time to ensure your ML model is robust. For example with a monthly forecast. You might want to just forecast the next 3 months into the future. If you have 5+ years of historical data you could have 4 historical back tests where you train a model and produce a 3 month forecast for each of the last 4 quarters in your historical data.</li>
<li><strong>Prediction Intervals</strong>: Understanding the uncertainty of the future forecast can also help build trust. Think of prediction intervals as upper and lower bounds of the future forecast that convey a certain percent of probability that the future value will land in between these bounds. Common prediction intervals are 80% and 95%. For example, you might have a future forecast of $100 for next month, with a 80% prediction interval of $80 and $120. This means there is an 80% chance that the actual value of next month will be between $80 and $120. So the tighter the prediction interval, the better. Having an prediction interval that’s +-5% of the forecasted value gives more comfort to the end user than one that’s +-30%. Just make sure that the end user of the forecast knows that those upper and lower bounds are not a “bull case” and “bear case” of what could happen in the future, like they might be used to in other financial modelling. But instead just a way to capture the uncertainty of the future prediction.</li>
<li><strong>Interpretability</strong>: Finally another good way to build trust is being able to explain how a future ML forecast was created. You will not be able to perfectly explain it like you can an excel model (by tracing through it cell by cell). But you can use methods to poke and prod a model to see what might be going on under the hood.</li>
</ul>
<p>Back to Table of Contents</p>
</section>
<section id="ownership" class="level3">
<h3 class="anchored" data-anchor-id="ownership">Who owns the ML creation process</h3>
<p>Being at Microsoft we are lucky to have engineering teams (sometimes called IT in other companies) that sit inside of finance and report to the CFO. This allows us to have software engineers who are solely focused on improving the lived experience of each of the 5,000+ employees under the CFO.</p>
<p>On those engineering teams there are people like myself who work on ML. Most of my time is spent helping produce and evangelize ML forecasting. My team has built two unique ways of how ML gets created and consumed by financial analysts.</p>
<ul>
<li><strong>Standard API</strong>: This allows other engineering teams to call upon ML on demand to get a forecast. Without needing to set up the infrastructure to train and serve models. This process works hand in hand with <a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">other forecast centralization efforts we’ve done</a>.</li>
<li><strong>Self-Serve UI</strong>: On the other end of the spectrum is to have tools that allow any financial analyst to produce their own forecast with a few clicks of their mouse. This allows us to scale ML to every single person in finance, without needing to rely on an engineering team to help produce a forecast. The tool we built for this is called Finn, and you can <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">learn more about it here</a>.</li>
</ul>
<p>Back to Table of Contents</p>
</section>
<section id="starting" class="level3">
<h3 class="anchored" data-anchor-id="starting">How to get started with ML</h3>
<p>Getting the ball rolling can seem like an insurmountable task. Thankfully it’s been easier than ever to get started with ML. <a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/">Check out how we got started</a> back in 2015.</p>
<p>Another way to make quick wins is to use something pre-built off the shelf that’s ready to go. Thankfully you can use it for free! We have open-sourced our ML forecasting code into a standard package called <a href="https://microsoft.github.io/finnts/index.html">finnts</a>. You can have your engineers take this code and quickly get up and running with ML forecasts within a week. It condenses almost 10 years of trial and error in Microsoft finance down to code that works at scale in production. Try it!</p>
<p>Back to Table of Contents</p>
</section>
<section id="migrating" class="level3">
<h3 class="anchored" data-anchor-id="migrating">Going from ML as a triangulation point to replacing manual human forecasts</h3>
<p>There’s a saying that 80% of ML projects <a href="https://venturebeat.com/ai/why-do-87-of-data-science-projects-never-make-it-into-production/">never make it into production</a>. This definitely applies to ML forecasting, but in a different way. Better put, 80% of ML forecast projects never make it past the triangulation point phase.</p>
<p>There are three distinct phases of adopting a ML forecast.</p>
<ol type="1">
<li><strong>Initial Development</strong>: Going from initial idea to a first prototype. Trying to see what a ML forecast would look like and if accuracy is good or not.</li>
<li><strong>Triangulation Point</strong>: Using a ML forecast every month or quarter alongside your existing manual forecast process. ML is another data point you “triangulate” with the actual forecast you will be using. So ML is nice to have but not required.</li>
<li><strong>Baseline Forecast</strong>: Using a ML forecast to replace your manual process. Where now the first step in your forecast cycle is to produce the ML forecast and build on top of it. Using the ML forecast as the initial “baseline” foundation. You have now “burned the ships” of your manual process never to look back. You are in it to win it with ML.</li>
</ol>
<p>It’s easy to go from phase 1 to phase 2. With tools like <a href="https://microsoft.github.io/finnts/index.html">finnts</a> you can get a new forecast up and running in less than a day. But most ML forecasts go to the triangulation point stage and die. It’s kind of a bummer but a fact of life. Here are some tips to break through the resistance and get all the way to phase 3.</p>
<ul>
<li>Have a timeline. Finance teams are busy. There is always more to do in the time allotted to do it. So having deadlines helps move work along. Instead of a “one day we will switch to ML” attitude you need a deadline like “we will switch to ML within the next two quarters”. This instills a sense of urgency and gets things moving. I’ve seen ML projects stall for 2+ years because there wasn’t a timeline set in place. An answer like “we’ll move to ML sometime this fiscal year” is not good enough. Keep pushing until a deadline is agreed upon, and do all you can to stick to it.</li>
<li>Get leadership buy in. The quickest way to change a financial analysts behavior is to have them hear it from their boss. Getting senior leadership buy in helps with the ongoing issue of prioritization. If the leaders make it a priority then every person on their team has no choice but to make it a priority. Things start to move a lot faster once that happens.</li>
<li>If accuracy is a concern, establish a benchmark to beat. If you ask any forecast owner what kind of forecast error do they want, they will probably say something like “less than 1% error”. Meaning 99% accuracy. This is all well and good, but if the previous manual forecast process had a forecast error of 10% then having ML be 9% or less is already a win. Make sure you compare the approaches and agree beforehand on switching once a certain benchmark is beat.</li>
<li>Squeaky wheel gets the grease. Constant contact with the end ML forecast user helps speed things up. I can’t tell you how many times I’ve seen finance teams come to me, over the moon excited about using ML to revolutionize their team. Only to have that same team fizzle out their ML usage over the next 2 months. ML projects take time, and momentum with business partners can be lost quickly. Something I’ve realized is simply staying in contact with them, even as little as 1-2 times a month, helps move people from ML curious to ML power users rather quickly. It may seem like you might be bugging them too much but keeping ML at the top of their mind will help in prioritization.</li>
</ul>
<p>Back to Table of Contents</p>
</section>
<section id="talent" class="level3">
<h3 class="anchored" data-anchor-id="talent">Building data science talent in finance</h3>
<p>Hiring technical talent into the finance org is no easy feat. Here are a few challenges you have to overcome.</p>
<ul>
<li>Lack of defined career path. A data scientist working in finance will most likely not work for a data scientist manager. If they are lucky they might work for a software engineering manager, but I haven’t seen that happen too many times in Microsoft finance. This makes it hard to attract strong data science talent and get them to stick around for many years. If they keep getting promoted there are not many other jobs they can rise up to and take. The more successful they get, the more likely they will have to move on outside of finance to grow their career. And that’s ok. So make sure you cultivate the career path of your data scientists, even if that means leaving your team.</li>
<li>Lack of mentors. Because there aren’t a lot of data scientists in finance, there is often no one they can go to for help. For example, I’ve never had a boss review my code. Not even once. So to know if what I built is any good I needed to go consult the opinions of others. Sometimes these can be other data scientists in the finance org, but often I’ve had to go outside of finance to other mature data science teams to get advice and feedback on my work. So for your data scientists, make sure they are connected to a larger data and AI community at your company. And if there isn’t one, ensure they are finding community outside of the company at conferences and online spaces.</li>
<li>Lack of data engineering. <a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage in, garbage out</a>. If there isn’t good data, no amount of data scientists can create value for you. Even worse, don’t rely on a data scientist to fix your data problems first before they start training models. Building robust data infrastructure in finance should be the job of data engineers, not data scientists. Those two jobs cannot often be combined into one, because they require different skill sets and even different mindsets. So make sure you get your data house in order first before even thinking of getting data scientists.<br>
</li>
<li>Lack of complexity. Sometimes data scientists can get lost in building the coolest thing possible, instead of building something that helps the business. For example, a data scientist might use the latest hot thing from the world of deep learning to create a solution for the business problem, when in reality a simple linear regression could have taken 1/10th the time and give you the same results. Also when explaining their work to the end user in finance, they might dive right into the technical aspects of the project, and all of the cool statistics they performed to save the day and create something awesome. This kind of explanation works well with other data scientists, but it will scare off every finance person I know. One of the main jobs of a data scientist in finance is to abstract away all of the complexity of the craft and make their work simple to understand for the average finance person. It may feel like the data scientist is “dumbing down” all of their hard work, but this part is crucial. If the end finance user cannot understand what they are being given from the data scientist, then they will not trust it, which means they will not use it. So gone are the fun technical presentations showing off all of the bells and whistles of their work. Now all they need to do is explain in simple terms if what they built worked, maybe how it worked under the hood (simplest explanation possible), and how the finance end user can leverage the work to do their job better.</li>
</ul>
<p>Ok, now that we know the challenges we must overcome to grow strong data scientist talent, here are some more tips around making data scientists successful in finance.</p>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1">Borrow, rent, then buy</a>. If you are starting from zero. Then I recommend trying to borrow a data scientist from elsewhere in your company. Then once you’ve gotten a few projects off the ground rent some outside vendors/contractors to keep the work going. Then once you’re really kicking butt either hire those vendors as full time employees or go out and hire other data scientists in full time positions.</li>
<li>Start small. If your team has the budget to hire 5 data scientists, maybe just hire two for now and see how it goes. Then ramp up over time. When new technology is booming, like the current generative AI wave, people have the tendency to overinvest. So start small and grow over time. Having too much work for your 1-2 data scientists to do is way better than having to lay off 1 of your 5 data scientists because of budget cuts that always seem to happen every few years.</li>
<li>Connect with mentors outside of finance. Make sure your data scientists have a community of like minded people whom they can share their work with and get feedback. This will most likely be with data scientists in other departments like marketing, sales, and product teams.</li>
<li>Always answer the “so what” question. Once you hear this concept you cannot unhear it. A boss of mine recently started asking me one simple question after I told him about a project I recently worked on, “so what”? I recently moved our model training infrastructure to a new Azure resource, so what? I’m working on improving the model ensembling techniques used in our ML forecasting models, so what? I’ve been asked to present to some outside customers about the work we do in Microsoft finance, so what? It’s a simple question but also a powerful one. If you cannot answer the so what question, you probably should go work on something else. Often the answer to the so what question boils down to a metric or number to measure impact of the work. If you cannot convey that to your manager, then you might be in trouble of making yourself busy instead of productive. Always be able to answer the so what question with data or customer testimonials.</li>
<li>Hire for more applied ML, not research ML. It’s better to hire someone who has spent their time putting ML solutions into production than someone who just got their PHD in deep learning. There is a difference between applied ML and research ML. If you do hire a PHD to work on ML stuff, they most likely will not be happy, this goes back to the lack of complexity I called out earlier. We’re not building rockets in finance, often times we <a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">don’t even need deep learning</a> to get the job done. So this kind of work may not entice the PHD to stick around long. Instead hire someone who can bring data science to business expertise, which brings me to my next point.</li>
<li>Convert financial analysts into data scientists. The perfect scenario is to take existing financial analysts, who are already experts in the business, and either give them tools that turn them into data scientists without the code. Or actually have them take the red pill and go all the way down the ML rabbit hole, becoming a true data scientists. This fixes most problems. Your data scientist already has strong domain expertise in the business, they can already speak like a normal person to business partners without all of the technical jargon, and they’ve only ever known applied ML so they won’t waste time trying to build custom models from scratch. In my opinion it’s a no brainer and something that should become the standard going forward.</li>
</ul>
<p>Back to Table of Contents</p>


</section>
</section>

 ]]></description>
  <category>finance</category>
  <category>machine-learning</category>
  <category>forecasting</category>
  <guid>https://mftokic.github.io/posts/2024-08-12-ml-fcst-faq/</guid>
  <pubDate>Mon, 12 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-08-12-ml-fcst-faq/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Microsoft Finance ML Forecasting Journey: Part Three</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/image.png" class="img-fluid"></p>
<p>This is a multipart series:</p>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/">Part One</a></li>
<li><a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">Part Two</a><br>
</li>
<li><a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">Part Three</a></li>
</ul>
<p>By now you should know how we started our machine learning (ML) forecast journey and how we applied it to Microsoft’s largest forecast process. But the fun doesn’t stop there. We were able to transform the biggest forecast process, but not every forecast process. There are hundreds more forecast processes in finance that are still in the dark ages. Essentially people with paper and pen creating these forecasts (written down inside excel models). Not knowing the potential ML can have on their job. All of these forecasts are important, but cannot scale in centralized tools like we discussed in <a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">part two</a>. Something else had to be done. Centralizing processes can help solve many problems but not all problems. Sometimes you have to build democratized tools that give the power back to the people. That’s exactly what we did with ML forecasting. Keep reading to find out how.</p>
<section id="total-addressable-market" class="level3">
<h3 class="anchored" data-anchor-id="total-addressable-market">Total Addressable Market</h3>
<p>There are around 5,000 full time employees who work for Amy Hood, the CFO of Microsoft. They do a lot of different jobs. Some are considered finance roles while others are not. About 40% of these employees do some sort of predicting the future. This is the “planning” in “financial planning and analysis” roles in corporate finance. These predictions are often around future financial metrics. Like how much revenue a product will make next month or how much headcount we will have on a specific engineering team. Let’s run the numbers to see how much time, and in essence money, is spent doing this one simple job of forecasting.</p>
<ul>
<li>5,000 finance employees</li>
<li>40% create forecasts</li>
<li>Spend ~4 days a quarter creating forecasts (very conservative number)</li>
</ul>
<p>Doing the math this equals around 24,000 days of human effort spent every year forecasting (24,000 = 5,000 x .40 x 12). If the average finance headcount costs Microsoft $250,000 year (salary, benefits, office space, etc) then the total cost of forecasting is around $24,000,000 ($1,000 per day x 24,000 days). Yep, that’s 24 million a year just crunching numbers in excel. This is also a pretty conservative estimate. I know some teams who spend weeks every quarter just forecasting, so it could easily be higher.</p>
<p>Think of this 24 million as the total addressable market (TAM) for forecasting in Microsoft finance.</p>
<p>The largest forecast process we discussed in part two only saves 10% of this 24 million. So we have a long ways to go in making a dent in this TAM. Unfortunately we cannot create 9 more centralized forecast solutions to cover the TAM. There is a long tail effect here, where the last 50-60% of forecasting might be done by 100+ forecast processes. We simply cannot create ML forecasts for everyone. There are not enough data scientists and data engineers needed to do that.</p>
<p>But hang on a second, what if we flip the script on that idea? Instead of having a dozen data scientists and data engineers maintain 100 ML forecast solutions. What if we have 100 regular finance people maintain their own single ML forecast? This is how a tool called “Finn” was born.</p>
</section>
<section id="self-serve-ice-cream-prototype" class="level3">
<h3 class="anchored" data-anchor-id="self-serve-ice-cream-prototype">Self Serve Ice Cream Prototype</h3>
<p>I graduated <a href="https://mftokic.github.io/posts/2024-02-19-frp-journey/">Microsoft’s Finance Rotation Program</a> (FRP) in the fall of 2018. My full time post program role was on the same business intelligence team as my fourth rotation. Basically I stuck around until they gave me a job. In that job I supported the Bing finance team. I helped them build ML forecasts for things like search volume and revenue on the Bing platform. It was my first true ML job where I wrote code and had legit business partners. It was awesome. Writing code to train models each day was a dream come true.</p>
<p>Initially I wrote code to create models to forecast search volume. Pretty soon that spread to trying to calculate search rates, or how much money we could make off “x” amount of search volume. This PxQ approach would be used to get to search revenue. I created monthly forecasts, then weekly, then daily. Each time I had to rewrite the code to purpose fit it for the specific task at hand.</p>
<p>Pretty soon I started to turn the custom code written for each forecast task into reusable components that could be used across all forecast projects. Just take the code and plug ’n play with new historical data. It was fun to build and I was learning a lot. This meant that I was always on the hook for producing new forecasts though. Each time the Bing finance team needed an updated forecast, I had to be there to run it, create a report, and send it to them. I was now the data scientist training the ML models, the ML engineer serving the final outputs, and also the PM creating the final report and working with the business partner. I quickly learned that this was impossible to scale.</p>
<p>What really cemented the scale issue was when another team, called Device Market Intelligence (DMI), heard about the work in Bing and wanted it applied to their market analytics of the Windows PC ecosystem. I was able to take the reusable code and apply it to DMI PC shipment forecasts, but I was still the human in the loop. Always on call to update forecasts and make tweaks as I got business partner feedback. I needed to scale myself.</p>
<p>It was around this time that I was at my desk having just come back from lunch. I was thinking about ice cream, and how awesome those self serve ice cream machines are. Where you can make the worlds largest ice cream cone or a huge sundae in a bowl. As a random thought I wrote down “self serve machine learning” on a sticky note and stuck it on my computer monitor. I didn’t give much thought to it, but thought it was cool enough to write down to make sure I didn’t forget it.</p>
<p>Months rolled by. I continued to run ML forecasts for both the Bing and DMI finance teams. Each time manually pulling the data and kicking off ML runs. Then sending them the outputs via excel report. It was at this time that I spoke with a coworker about an automation project that blew my mind. They were able to create an API that could kick off a large forecast process on demand. Without having to manually run code. Basically you press a button and the rest of the process takes care of itself. This started to turn the wheels in my head. What if I could take my reusable ML forecasting code and put it behind this kind of automated process?</p>
<p>I couldn’t stop thinking about it. How could I create a way to let someone kick off a ML forecast run without needing to come talk to me? Could they pull their own historical data, upload it inside of some tool, then an hour later get back a forecast they could use? I had no clue how to do this but wanted to figure how.</p>
<p>Over a few months I was able to put together a god awful prototype. One that allowed a user to fill out an excel template that had tabs to add their historical data and tabs to control certain inputs like forecast horizon. They could then upload that file into a Microsoft Power Automate flow. This flow would take their file, copy it to a shared server, then kick off an API that would run the ML forecast process. After it finished running the user would get an email with a link to where they could download the ML output results. It was all built with chewing gum and duct tape, but it worked. It actually worked. I felt like a super hero.</p>
<p>All great tools need a name. Most things at Microsoft are acronyms, which everyone hates. There is literally an internal company acronym lookup tool because there are so many. So I wanted to create a name that wasn’t an acronym, but also kind of described what it did. In essence it was a tool for financial forecasting. I settled on a one syllable word that kind of had finance in the name. I called it “Finn”. When I told this to my manager, they said “are you sure”? And “ok we can always update the name later”. The name stuck and is still around today. Sadly people still think it’s an acronym.</p>
<p>I rolled out an early beta of Finn at Microsoft’s company wide hackathon in July 2019. Finance employees bravely signed up to be my guienne pigs for three days. They would stop by, bring some historical data they want forecasted, and attempt to use the tool. They got confused at times. And even more times the tool broke on a corner case with their data. It was glorious. Fixing bugs on the fly and seeing people use something I’ve built, even be a little excited about it, was like nothing I’ve ever experienced. I knew this was it for me, I had to make this work.</p>
<p>The hackathon was a medium success. Less than 10 people showed up, but those who did gave amazing feedback that I used to make the tool better. I was now ready to officially launch it to the masses. Before the big launch, I demoed it to my BI team, and people laughed. Yep, laughed. People said it was too complex and no one in finance would follow the steps needed to submit a forecast run. It was hard to hear but good feedback. I continued to iterate.</p>
<p>By the fall of 2019 Finn was ready for launch. We held training sessions, presented at CVP level all hands meetings, and basically told everyone I knew that they could start using Finn. Machine learning was still so new to people, so there were always people willing to try it out. With each passing month I would gather feedback, making improvements, and slowly usage grew.</p>
</section>
<section id="scaling-up" class="level3">
<h3 class="anchored" data-anchor-id="scaling-up">Scaling Up</h3>
<p>Finn was an interesting tool with a terrible UI. The UI was an excel template uploaded through a Power Automate flow. It wasn’t pretty but it worked. The tool needed a facelift, something to take it to the next level. Thankfully at this time my BI team was working on another tool called “Replay”. It was touted as an internal portal for custom built apps specific to Microsoft Finance. The first big feature was going to be centralized reporting. They were also interested in adding other apps into the mix. We pitched them Finn and thankfully they agreed to add a Finn app.</p>
<p>The newest Finn app launched alongside the new Replay site in March 2021. People could now go to a legit website, upload an excel or csv file, click through a UI to adjust various inputs, then click submit. The ML magic would happen behind the scenes. Then they could come back to the site and see when their ML run finished. Even download the output files. A user could submit a ML forecast run in 10 clicks of their mouse. It was magnificent.</p>
<p>In order to make this happen we had to completely rebuild the ML backend of Finn. Moving away from on-prem servers and into the cloud on Azure. This involved things like data lakes and Azure Machine Learning. We were able to migrate the Finn API to an Azure ML pipeline. Allowing for better scale and monitoring. The core modeling code also got an upgrade. We partnered with the Chief Economist team within Microsoft Research to make the ML brain of Finn more robust. The data scientists on the Chief Economist team were amazing mentors to me. I learned years worth of knowledge within months. It goes to show how a good mentor can make all the difference.</p>
<p>After giving the core ML code a makeover, we realized that we could package it up and make it open-source. Allowing other finance teams at other companies to use the exact same forecast process we use at Microsoft. This was released as an R packaged called <a href="https://microsoft.github.io/finnts/index.html">finnts</a>. Anyone can now take the code off the shelf and use it, free of charge.</p>
<p>We also realized that not everyone wants to use the self-serve UI to get a forecast. Sometimes people still want to use code, so we built a more general purpose API that allows anyone to call Finn on demand via API and give them a forecast on their specific data lake. Various engineering teams in Treasury, FinOps, etc now call Finn via API to produce forecasts on demand and at scale. This is how the Fusion tool mentioned in <a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">Part Two</a> uses Finn today.</p>
</section>
<section id="future-state" class="level3">
<h3 class="anchored" data-anchor-id="future-state">Future State</h3>
<p>Finn continues to change almost on a monthly basis. There are hundreds of things we want to add or improve in the tool. Here are a few that come to mind.</p>
<ol type="1">
<li><strong>Forecast Accuracy</strong>: Always a top priority. No one will use a ML forecast if it’s less accurate than the previous manual forecast. There are countless ways we can make Finn more accurate. Thankfully all of them will be made available in the open-source <a href="https://microsoft.github.io/finnts/index.html">finnts</a> package.</li>
<li><strong>Model Interpretability</strong>: Once finance users get the level of accuracy needed, their next question is always around knowing how these models created the forecast. This is our next top priority that we are now starting to work on.</li>
<li><strong>Forecast Adjustments</strong>: ML forecasts may not capture everything about the future. There might be changes in business strategy, new product launches, or tax changes that could affect the forecast. This is where human domain knowledge comes in the form of manual adjustments. We want to create a way for ML to do the initial 80% of the work, and allow humans to come in for the last 20% and easily make and track manual forecast adjustments when needed.</li>
</ol>
</section>
<section id="lessons-learned" class="level3">
<h3 class="anchored" data-anchor-id="lessons-learned">Lessons Learned</h3>
<section id="paradigm-shift" class="level4">
<h4 class="anchored" data-anchor-id="paradigm-shift">Paradigm Shift</h4>
<p>Going from a manual forecast done in excel to a ML forecast requires a large paradigm shift in the brain of a finance person. You’re going from a deterministic process, where you know all the inputs and formulas used to create the forecast. To a probabilistic one, where there is this black box that takes in data and spits out a forecast. There are ways to explain what’s going on in the black box, but they are not perfect. You will not be able to trace through a ML forecast step by step like you can with a good excel model. So finance people need to change their mindset and know the potential tradeoffs of using ML. It boils down to a change in control. From letting a human control the entire forecast to now letting a machine control most of the process. As AI technology gets better, we will all turn into a form of a manager. Instead of managing people, we will manage little AI employees (or agents) to do our work for us. The sooner you embrace this, the bigger the impact you will have going forward into this AI future.</p>
</section>
<section id="duplication-of-work" class="level4">
<h4 class="anchored" data-anchor-id="duplication-of-work">Duplication of Work</h4>
<p>Most of the time people do not stop their manual forecast process and immediately switch to a 100% ML powered forecast. Often there needs to be overlap between the old process and the new process. This can be a few months (or even years) where ML is ran alongside the manual forecast process. With ML serving as a triangulation point until the team is ready to make the switch. This creates a duplicate of effort. Finance people barely have enough time to do their current job to sometimes learn a new way of doing it. That’s when senior leadership needs to kick in to help their teams prioritize using ML. Not just as a nice to have but to eventually change how their jobs get done. To do that brings us to the next lesson, taking the leap of faith.</p>
</section>
<section id="leap-of-faith" class="level4">
<h4 class="anchored" data-anchor-id="leap-of-faith">Leap of Faith</h4>
<p>You know that <a href="https://youtu.be/DjffIi2Pl7M?si=UWMjRJphxhIKnY-u">scene in the Dark Knight Rises</a> where Batman escapes the third world prison? The reason he escaped was because he literally took a leap of faith, without the rope. Using ML as a triangulation point is like jumping with the rope attached to you. You will never truly have ML help you because you can always fall back on the manual forecast. I’ve seen some teams use Finn for years but only ever as a triangulation point. In order to truly get the benefits of ML, you need to take the leap of faith. Jump without a rope. Ditch the manual forecast. It seems scary at first, but soon you’ll be laughing at how much time you spent forecasting each month.</p>
<p>The best way to take a leap of faith is having senior leaders give you the kick in the butt to make the jump to full ML. If senior leaders aren’t expecting to see ML usage grow on their team, adoption will slow to only those employees brave enough to jump by themselves. That’s a small number. Get higher ups to buy in and lead the way.</p>
</section>
<section id="invest-in-youth" class="level4">
<h4 class="anchored" data-anchor-id="invest-in-youth">Invest in Youth</h4>
<p>It’s a lot easier to teach someone fresh out of school to use ML compared to a senior employee who has built excel models for 20 years. Younger people are more open to technology. They have no bad habits to unlearn. They don’t know any other way of doing things. These are the people you want to equip with ML tools. If they use ML in their initial jobs, once they become a senior executive they will make sure ML use becomes standard on their teams. This is kind of like planting trees. It takes time to see results, but one day you will have an entire forest of ML experts leading the charge.</p>
</section>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>This wraps up our three part series on ML forecasting in Microsoft finance. I started at the beginning with our first ever solution in <a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/">Part One</a>, then discussed how we built tools to centralize the forecasting process in <a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">Part Two</a>, and finally I wrapped up with telling you how we decentralized ML to everyone in Finance in <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">Part Three</a>. If you’d like to use the same forecasting techniques as we do at Microsoft, check out our free forecasting package called <a href="https://microsoft.github.io/finnts/index.html">finnts</a>.</p>
<p>May the MAPE ever be in your favor. Happy forecasting!</p>


</section>

 ]]></description>
  <category>finance</category>
  <category>machine-learning</category>
  <category>forecasting</category>
  <guid>https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/</guid>
  <pubDate>Mon, 15 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/image.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>Inner Circles of Life</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-06-28-life-circles/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-06-28-life-circles/image.png" class="img-fluid"></p>
<p>One of my siblings recently got married and had a baby. As they were living this new life, myself and other family members realized something. They now had less time for us. Instead of coming around to the standard family events like they used to, they now had to “squeeze us in” between other things going on with their life. This become the most apparent around Christmas time. My sibling and their family now only stopped by for a few hours around the Christmas holiday, and on Christmas day this meant only seeing them for 2-3 hours. In previous years we would have been together nonstop. This broke my Mom’s heart. She could no longer be with all of her kids 24/7 during holidays and major life events.</p>
<p>It was during this Christmas that I realized something. My sibling had to deprioritize us for their spouse and eventually their new child. And that’s perfectly ok. They now had a new top priority in life, and myself and other family and friends are now lower down on the list. A new inner circle of priorities formed for them, and myself and others were no longer in it. We had to make due with this new reality and understand it could get worse in the future. This kind of deprioritization also happens with friends too. It just gets hard to prioritize people in your life as new people come into it.</p>
<p>The list of life priorities is something I like the call the “inner circles of life”. Sounds fancy but it’s just a list of what you truly prioritize and make time for in life. Your inner most circle is your top priority. Then circles form around and outward. With each new circle, your priorities of things in that circle drops. Let’s see how that changes as we get older.</p>
<p><img src="https://mftokic.github.io/posts/2024-06-28-life-circles/image2.png" class="img-fluid"></p>
<section id="age-0-1" class="level3">
<h3 class="anchored" data-anchor-id="age-0-1">Age 0-1</h3>
<ol type="1">
<li><strong>Mom</strong></li>
</ol>
<p>When you’re born, the only person that exists is your mother. Dad, who’s Dad? What’s a Dad? You have no idea. The only person you recognize and bond with is your Mom. No one else comes close.</p>
</section>
<section id="age-1-6" class="level3">
<h3 class="anchored" data-anchor-id="age-1-6">Age 1-6</h3>
<ol type="1">
<li>Mom</li>
<li><strong>Dad</strong></li>
<li><strong>Grandparents, Aunt/Uncle</strong></li>
</ol>
<p>Ok, now Dad comes into the picture as the second circle of your life, but Mom still holds the inner most circle. You also now get to know there are other people who love you unconditionally. These people are called Grandparents and they’re awesome. All they do is give you hugs and tasty food, life is great when they are around. Aunts and Uncles come into the picture to. They kind of look like Mom and Dad but smell different and always seem to get out of having to change your diaper. Lucky them.</p>
</section>
<section id="age-7-12" class="level3">
<h3 class="anchored" data-anchor-id="age-7-12">Age 7-12</h3>
<ol type="1">
<li>Parents</li>
<li><strong>Friends</strong></li>
<li><strong>Siblings</strong></li>
<li>Relatives</li>
</ol>
<p>Your parents still keep the top spot, but now they are more like a combined unit. Not just separate people but a singular force. Now they are telling you to do chores and keep an eye on your brothers and sisters. Who the heck are they? These people look like me but have different interests and personalities. And hey, they’re mean! We don’t get along that well. We always fight. So they are definitely farther down on the list. Same goes with Grandparents and other relatives. We still enjoy seeing them, but we’d rather hang out more with these people who go to school with you. People your own age who have the same interests as you. Who you see every day at school. People who give you their pudding cup just because you looked hungry. These people are your friends, and they are the best. They now take a higher spot on the list. Life starts to revolve more around your friends and less around your other family members.</p>
</section>
<section id="age-13-25" class="level3">
<h3 class="anchored" data-anchor-id="age-13-25">Age 13-25</h3>
<ol type="1">
<li>Friends</li>
<li><strong>Romantic Partners</strong></li>
<li>Siblings</li>
<li>Parents</li>
<li>Relatives</li>
</ol>
<p>This is what I have come to call the “dark decade”. A time where you kinda suck as a person. You might hate your parents. You might hate school. You might just hate the world. Don’t worry that’s just your emo phase, it’ll pass. Friends become your top priority in life. School might be on that list too but it most likely won’t come until your college years, so I’ve left it off the list for now. There are now others who might have initially looked like friends. But who you now see in a different light. They smell nice. They have shiny hair. They seem cool. You’d like to get to know them more. Maybe even kiss them right on the mouth. Yes, these are people I call romantic partners. Hopefully they do not occupy the top spot on the list. You know the saying, bros before ____ right? Wrong. At times a girlfriend, boyfriend, or someone you admire (who might not know you even exist) could take the top spot. You might even go to a specific college on the other side of the country for them. This dark decade is where mistakes happen. Where you fail a lot. Do dumb things. Thankfully all of this dumb stuff happens when you’re at a school of some sort, so the mistakes are temporary. These mistakes are things you learn from and grow into a better person (hopefully).</p>
</section>
<section id="age-22-26" class="level3">
<h3 class="anchored" data-anchor-id="age-22-26">Age 22-26</h3>
<ol type="1">
<li><strong>Job</strong></li>
<li>Romantic Partners</li>
<li>Friends</li>
<li>Parents</li>
<li>Siblings</li>
<li>Relatives</li>
</ol>
<p>Now you’re in the real world. And you need money to live. Work has now become your top priority. Don’t believe me? How many of your friends took jobs in different cities after college graduation? Did you break up with your romantic partner because you both were headed to different cities to start your careers? Yup, it happens. It’s ok to have your job be the top priority. You need to establish yourself at this stage in life. Build a career that’s going somewhere. You also might be in a serious relationship with someone who smells nice and has shiny hair. Lucky you. This person might even move in with you. Your roommate used to be your best friend. Now you’ve kicked them out for a different kind of best friend, one you may want to spend every day of the rest of your life with. Friends are still high up on the list, but they might live in a different city now. You take trips to visit them, but you only have so many vacation days off work. You also need to balance that with time to see your parents and other family members. Now you have too many life balls in the air to juggle, so some might get dropped. When was the last time you called your Grandparents? Call them now.</p>
</section>
<section id="age-25-35" class="level3">
<h3 class="anchored" data-anchor-id="age-25-35">Age 25-35</h3>
<ol type="1">
<li><strong>Spouse</strong></li>
<li>Job</li>
<li>Parents</li>
<li>Siblings</li>
<li>Friends</li>
<li>Relatives</li>
</ol>
<p>By now you might have married your roommate who smells nice. Where you live and sometimes changing jobs are based on this other person. They are now the center of your world. Having a job and good friends are still high up on the list, but those fall by the wayside compared to your new spouse. You are now out of the “dark decade”, so naturally your parents and siblings become fun again. You genuinely enjoy hanging out with them. And miss them when they’re not around. Now that you’re starting to see your family more, and your job responsibilities are heating up, all of a sudden you can’t see your friends +3x a week. Some of your friends might move away, back to their or their spouse’s hometown. It happens, and it kinda sucks. But that’s life. They’re also dealing with their own priorities just like you.</p>
</section>
<section id="age-28-38" class="level3">
<h3 class="anchored" data-anchor-id="age-28-38">Age 28-38</h3>
<ol type="1">
<li><strong>Kids</strong></li>
<li>Spouse</li>
<li>Job</li>
<li>Parents</li>
<li>Siblings</li>
<li>Friends</li>
<li>Relatives</li>
</ol>
<p>The most beautiful thing in the world happens. A baby comes into your life. Everything else is meaningless. The only the thing that matters is making sure this child is happy and healthy. Your kids become your inner most circle. Everything else gets bumped down the list of priorities. You now realize you need baby sitters, because eventually you might have to return to work. This is where parents and siblings come in. Now you’re closer than ever with them. Friends visit you, but that weekly poker game or all night weekend party is now out of the question. You have someone to feed and someone to love. Life is beautiful. Work falls on the list too. Late night and weekend working sessions become harder. Now you have to tradeoff time at work with time with your child. This becomes a hard choice that has been argued thousands of times by smart people. The answer is hard. Thankfully by now you have built up some career capital. Meaning you can use your seniority and expertise at your company to guard your time more. Only work on the biggest impact items instead of the grunt work you did at the start of your career. They say you can have everything in life, just not all at once. Choices have to be made. Just know the tradeoffs of each one. Make sure you define your own definition of success in life. Which can be truly anything. No one has the right answer. No one has it all figured out.</p>
</section>
<section id="age-35" class="level3">
<h3 class="anchored" data-anchor-id="age-35">Age 35+</h3>
<ol type="1">
<li>Kids</li>
<li>Spouse</li>
<li>Parents</li>
<li>Siblings</li>
<li>Friends</li>
<li><strong>Job</strong></li>
<li>Relatives</li>
</ol>
<p>Hopefully by your mid to late thirties you are able to find a nice smelling person. Maybe even raise some rugrats. By this time you have also built up a lot of career capital. Maybe this means you can now do your job how and when you’d like. Maybe your job is still demanding most of your time. Good news, things will only get worse. More people will ask for your time. Pull you in a thousand directions. Ask you to do more. Then more. Then once you get all of that work done, your reward is more work. Congrats! Maybe you tell yourself you’ll retire early. That way you can then have more time to spend with your family. Like I said before, I don’t know the right answer. I don’t think anyone does. So again I’ll say that life is all about priorities and tradeoffs. How you define success in life could be different than someone else. And that’s ok. I think in a perfect world your family and friends are still high on the list as you get older. You can spend more time with them, and maybe less time on that job. Or maybe your job fulfills you immensely. You know the work contributes to making the world better. So working more is a worthwhile tradeoff. Do Presidents of nations feel bad that they cannot spend time with their family every day? Maybe they do, maybe not. For me I don’t think retiring to a beach for the rest of my life is any fun. I’d like to be like Charlie Munger, working into his 90s. I assume he wasn’t working nights and weekends in his 90s. Instead he still worked, but also made time for other relationships in his life. Again, there’s no right answer.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>When we’re on our deathbed. I don’t think any of us will say “I wish I worked harder”. The quality of our life boils down to the quality of our relationships. The quality of your relationship with your kids, parents, siblings, friends, and extended family. Relationships at work can serve a purpose too, but it’s hard for a job to replace these other types of relationships. You can have everything in life, just not all at once. Everything comes with a tradeoff. In the end, define what success looks like to you and have zero f#### for anyone else who tells you how to live your life. Prioritize accordingly.</p>


</section>

 ]]></description>
  <category>life</category>
  <guid>https://mftokic.github.io/posts/2024-06-28-life-circles/</guid>
  <pubDate>Fri, 28 Jun 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-06-28-life-circles/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Microsoft Finance ML Forecasting Journey: Part Two</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/image.png" class="img-fluid"></p>
<p>This is a multipart series:</p>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/">Part One</a></li>
<li><a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">Part Two</a><br>
</li>
<li><a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">Part Three</a></li>
</ul>
<p>The success of Microsoft finance’s first machine learning (ML) forecast spread like wildfire throughout finance. The ML forecast was shared with all finance leaders. So naturally knowledge of ML’s potential trickled down to more people across the organization. Eventually the news came to a team in central finance (CFT). Think of this team as Microsoft’s core FP&amp;A team across the entire company. After seeing the accuracy at a worldwide level, this team knew it could help in the biggest forecast process at Microsoft. Something called the commercial field forecast. This forecast is created by finance members who sit in the “field”. The field is just a cool way to say regional offices all around the world. These field finance teams support the sales teams who also sit in the field. How could they take a worldwide forecast by product and break it down into specific countries all across the world? Well buckle up gang, it’s time to find out! This is how a tool called “Commercial Predict” was born in 2017.</p>
<section id="how-things-used-to-work" class="level3">
<h3 class="anchored" data-anchor-id="how-things-used-to-work">How Things Used to Work</h3>
<p>Before we dive into all the ML goodness, we have to understand how the old way used to work. I know, it’s kind of like eating your vegetables. But we just have to do it real fast then we can get to the fun parts.</p>
<p>In the past, each finance team in the field was responsible for their own forecast each quarter. These forecasts would happen in “CFO forecast cycles”. With cycles happening in October, January, and April. Microsoft’s fiscal year runs from July - June so these forecast cycles happen at the start of Q2, Q3, and Q4. The forecast at the start of Q1 is budget (that’s a story for a different day). Each cycle, a forecast would be created for the remainder of the fiscal year.</p>
<p>Microsoft sells products in over 100 countries. Most of those countries have a sales team that tries to sell products to companies in that geographical region. If there’s a sales team, then there is a finance team who supports them. This means there are dozens of sales finance teams creating quarterly forecasts for the rest of the fiscal year each CFO forecast cycle. Each team had their own secret recipe of how the forecasting was done. Often a custom excel model that would create the forecast. This model needed to be handled with care. Since each quarter it would have to be rolled over and prepared for the next forecast cycle. Anyone who has ever created and owned a financial model in excel knows the anxiety faced with trying to build and maintain one. These models were complex, and you said a little prayer every time you opened the file. Hoping it wouldn’t crash your machine because it was so large.</p>
<p>Once each team in the field had their forecast for their geography, it would get sent up the food chain. Forecasts from each country would be combined to form higher level aggregations in Microsoft’s sales territories. Each aggregation added more countries and continents together. This continued until you got the total worldwide number for the entire commercial business. Each time the forecasts got combined together at a higher level, senior finance leaders had the opportunity to make adjustments to that forecast. Based on their domain knowledge of the business. Eventually the final forecast the CFO, Amy Hood, saw was something completely different than what was initially created by each sales finance team for their specific geography.</p>
<p>Layers upon layers of bias were added to the forecast. Some was good bias that could improve forecast accuracy, but often it was too many cooks in the forecast kitchen. Too many people touching a forecast that didn’t need to be touched. Resulting in worse accuracy and more confusion once the books were closed at quarter end. This process would take upwards of a month every quarter. From the initial forecast created by field team all the way up the food chain to the CFO. In the spirit of every good infomercial, “there just has to be a better way!”.</p>
<p>Now you know why finance had to do something different. Drastically different.</p>
</section>
<section id="excel-prototype-built-in-a-redmond-garage" class="level3">
<h3 class="anchored" data-anchor-id="excel-prototype-built-in-a-redmond-garage">Excel Prototype Built in a Redmond Garage</h3>
<p>All good things start from humble beginnings. The team in CFT wanted to centralize the field forecast process for the commercial business. Create a single way that everyone in the field would follow to create a forecast. To make this a reality, they started with the swiss army knife of every finance professional. That’s right. You guessed it. They started with excel. Like any innovative project, it quickly became their baby. And all babies need a name. The named it Commercial Predict.</p>
<p>The team created an excel prototype of a single model that every field finance team could use. It was a combination of the old and the new. First was old but reliable PxQ forecasts. Where you take what’s in the sales pipeline for a quarter and multiply it by how many deals on average have closed in similar historical quarters. Second was classic CAGR and year over year percentage growths, which actually still work quite well. These traditional methods were combined with more statistical rigor. Something more along the lines of machine learning. They built by hand, formula by formula, exponential smoothing statistical models. Which is a common model in time series forecasting. It’s more stats than machine learning, but still performed really well. Today exponential smoothing is a simple function call in excel, but this team built it from scratch. I tip my cap to them, because that was hard to do.</p>
<p>Now there were multiple forecasting methods in this mega excel model. The beauty of the idea is that someone could come into the model and choose what methods they wanted to use to forecast a specific geography, customer segments, and products. Users could even combine multiple methods together to get a more accurate forecast. This was powerful because someone could use the PxQ sales pipeline method for products that depended on big customer deals landing, and use the other methods for things that had more stable trends and seasonality.</p>
<p>It was genius prototype. The team was able to take this to their leadership team and show how one single approach to do forecasting in the field could save thousands of days of combined human effort across the field every year. One mega model to rule them all. It had the promise to cut forecasting down by 50%. Would it work though? To test it out, the team ran this excel model alongside the traditional bottoms up forecast process from each field team. They could then compare the results and even track accuracy across the old and new ways. The results were good. The new prototype was the same or even better than the existing process, but was 50% faster.</p>
<p>The new approach was fast, and it was accurate. The final roadblock before adopting the new approach was to get everyone in the field to agree on what level they should forecast at. This historically was a difficult subject to discuss, with everyone having differing opinions. Thankfully this was solved by getting the buy in from the top senior finance leaders in central finance and the field. Once that happened everyone was able to get on board.</p>
<p>Ok, so the team had a cool prototype that knew worked well. But if they just used that excel model, then they are still maintaining a model that is messy and requires constant upkeep. It would be hard to scale. They needed something more robust. A real tool that was built by engineers. Thankfully there was a team who could do just that.</p>
</section>
<section id="building-the-tool" class="level3">
<h3 class="anchored" data-anchor-id="building-the-tool">Building the Tool</h3>
<p>The vendor team who was created to take over the <a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/">initial ML forecasts</a> was the up to the task. They had the data science knowledge, but the data engineering and software engineering needed to build a software tool to scale out the excel prototype was missing. So the team got other vendors to fill in those gaps. Now there was a team of engineers all capable of making the tool a reality.</p>
<p>The first version of the production level Commercial Predict tool had to be built fast, before an upcoming CFO forecast cycle. V1 was built into excel within six months as an add-in field users could download and connect to. It needed to combine new machine learning methods with traditional PxQ and CAGR/YoY run rate methods.</p>
<p>Here’s how it worked.</p>
<ol type="1">
<li>Data engineers would pull historical revenue and sales pipeline data. All the forecasts methods were precomputed and saved in a database that was turned into a cube. This would be the starting point for all field members. Instead of calculating these forecasts by hand in their old excel models, it would be precomputed for them. At scale.</li>
<li>The forecasts in the cube were then served to users in a custom excel file. Each field team could come into the tool and select the geography, products, and segments they were responsible for forecasting. After making these selections, all the forecast methods would populate in the excel.</li>
<li>Users could then see each forecast method and see which ones pass their smell test of what they expect to happen in the business based on their domain knowledge. They could choose a specific forecast method to use, or combine multiple methods together to get a more robust forecast. Finally there might be things these forecast methods don’t know about. Like upcoming tax changes or product strategy changes. Field users could ultimately make manually adjustments to get a final forecast.</li>
<li>Once the final forecast was created, they could save it back to the cube. This allowed finance leaders to see the forecast creation in real time. Also it would prevent the classic “excel crash without saving” headache we’ve all been through in the past.</li>
<li>Once the forecast was complete for each field team, a static output file was created at the touch of the button. Teams could take this output and load it into the final planning system.</li>
</ol>
<p>Before official launch, training sessions were held to make sure everyone knew how to use it. It was also a good opportunity to fix any bugs in the tool. This resulted in some late nights and even weekend shifts, but the job got done. The tool was launched on time and the rest is history.</p>
<p>We were able to go from a forecast process of 21 business days each quarter, down to just 10. It was a revolution. This saved Microsoft millions of dollars each year of human capital. Finance teams in the field could now forecast faster, with less headaches, and prevent the layering of bias that was a staple of the previous way.</p>
</section>
<section id="evolutions" class="level3">
<h3 class="anchored" data-anchor-id="evolutions">Evolutions</h3>
<p>After this officially launched in 2018, the Commercial Predict tool has gone through a lot of iterations. What started in excel then moved into a web based tool. Then back to excel. With each iteration, we got better at the machine learning methods. Better at adding more features to give users more control over the final forecast.</p>
<p>Eventually Commercial Predict evolved into a much broader solution called “Fusion” in 2022. Think of it as a tool that could still do the commercial field forecast process but now also take on other forecasts within Microsoft finance. A true one stop shop for all things planning. Fusion is an excel add-in with a built in UI on the side of excel. Kind of like how excel copilot opens on the side of your excel tab, Fusion does the same. A user could select what forecast they want to do, select the parts they’re responsible for forecasting, and Fusion would populate the blank excel file with all the information they need to finalize their forecast. Methods like PxQ and machine learning are still ran ahead of time. The UI was truly dynamic. You could take any excel file and open the Fusion app inside to get going on the forecast. Fusion allowed finance to scale the learnings of Commercial Predict to so many other forecast processes. Improving the impact ML and centralization can have on forecasting.</p>
<p>Planning tools like Fusion will most definitely change in the future. As the business evolves, so should our way of forecasting it. What doesn’t change is how ML has become a central part of the forecast process.</p>
</section>
<section id="lessons-learned" class="level3">
<h3 class="anchored" data-anchor-id="lessons-learned">Lessons Learned</h3>
<section id="iterate-iterate-iterate" class="level4">
<h4 class="anchored" data-anchor-id="iterate-iterate-iterate">Iterate Iterate Iterate</h4>
<p>Rome wasn’t built in a day. Instead of building this complex centralized forecasting tool from the start, we started small. Built a prototype. Got senior leadership buy in. And continued to make it better every 6-12 months. Even as I write this we are in the process of improving the ML accuracy of the commercial field forecast. If you’re coasting, you’re going downhill. You need to continue to iterate.</p>
</section>
<section id="combine-the-old-with-the-new" class="level4">
<h4 class="anchored" data-anchor-id="combine-the-old-with-the-new">Combine the Old with the New</h4>
<p>ML didn’t outright replace every part of the commercial field forecast. Instead we combined ML techniques with older methods like PxQ sales pipeline methods. This allowed us to use the strengths of each approach based on what product was being forecasted. Some products are sensitive to large customer deals closing, so PxQ works best. Others have stable trends and seasonality, that’s where ML shines. Using both gives us the best of both worlds.</p>
</section>
<section id="senior-leadership-buy-in" class="level4">
<h4 class="anchored" data-anchor-id="senior-leadership-buy-in">Senior Leadership Buy In</h4>
<p>A forecast process is like a ship. The bigger the ship, the harder it is to change course. So the bigger the forecast process, the higher the buy in needed from a senior leader. Getting a GM or CVP level support allowed us to supercharge the change management. It’s easy to get bogged down in arguing with senior finance managers about how a forecast process should be done. Once a CVP (someone who reports to the CFO) comes in and says this is how we’re going to do it. Then everyone gets on board and starts turning the wheel of the ship together to change direction. The commercial field forecast had to get support from GM and CVP level leaders or else it would have taken years to change it instead of months.</p>
</section>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>The hardest part of any ML project comes down to people. Training models is easy, convincing people to use them is hard. It takes time. It takes senior leader buy in. It takes an open mind to rethink how your job can be done. It might be hard, but in the end it’s worth it.</p>
<p>Often we get asked by finance teams outside the company if they can take our “Commercial Predict” or “Fusion” tool off the shelf and start using it at their own company for forecasting. Sadly you cannot. We build a lot of these custom tools because we don’t have a choice. Microsoft’s business is complex. Often we need custom solutions that are hard to standardize in external products. Thankfully the machine learning methods we use are available for free as an <a href="https://microsoft.github.io/finnts/index.html">open-source R package</a>. Check it out if you’d like to learn more.</p>


</section>

 ]]></description>
  <category>finance</category>
  <category>machine-learning</category>
  <category>forecasting</category>
  <guid>https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/</guid>
  <pubDate>Wed, 26 Jun 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Microsoft Finance ML Forecasting Journey: Part One</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/</link>
  <description><![CDATA[ 





<p><img src="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/image.png" class="img-fluid"></p>
<p>This is a multipart series:</p>
<ul>
<li><a href="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/">Part One</a></li>
<li><a href="https://mftokic.github.io/posts/2024-06-26-msft-ml-fcst-journey-2/">Part Two</a><br>
</li>
<li><a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">Part Three</a></li>
</ul>
<p>Ever wonder how Microsoft Finance got started with machine learning? It didn’t just happen overnight. It started small and grew from calculated steps. In this post and a few others I want to tell the journey of how we got started. Gather round children! It’s story time.</p>
<section id="paradigm-shift" class="level3">
<h3 class="anchored" data-anchor-id="paradigm-shift">Paradigm Shift</h3>
<p>In the summer of 2015 AI and machine learning (ML) weren’t terms you’d hear every day. Maybe you’d hear the word “big data” being thrown around business circles but no one had a clue what it meant. There was a lot of data being captured about our world. Somehow we could “mine” the data to get some value out of it. No one really knew.</p>
<p>Earlier that year, something interesting happened at Microsoft. A new product called <a href="https://techcrunch.com/2015/02/18/microsoft-officially-launches-azure-machine-learning-big-data-platform/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuYmluZy5jb20v&amp;guce_referrer_sig=AQAAAE95NY6ZC1q7S3u9eB-VRujlcx7hEFnu35ya9daztiyij3JgOLZWH9VqOfmNl6FuEi2KTbr67hu2aoyrIMUYcUGPoDhzEDsXRJ01LUAF0c-VUU_lHdUhGzLcW5FQYKZwXQJ93c3qzwocA3_WIi-5Z4VXcKJGnaD-1E40xMI6LRnB">Azure Machine Learning</a> was officially released. The service allowed anyone to start mining their data up in the cloud. You could train models and serve them through APIs. It was basically magic. Unfortunately in finance, those words meant nothing. To a Microsoft finance worker the term “train a model” meant training the new employee on building excel models. Everything was done by hand and with care. Especially forecasting our financial statements. The CFO of Microsoft, Amy Hood, thought differently. What if we could use the new product to improve some of the manual work we did in finance? Could we have these models be trained to forecast our business? It was a tough question. No one in finance at the time was really qualified to answer it. She had to go ask the expert.</p>
</section>
<section id="getting-the-ball-rolling" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-ball-rolling">Getting The Ball Rolling</h3>
<p>Amy went to the legend himself. The head of Microsoft’s cloud, Scott Guthrie. King of the cloud and wearing red polo shirts. She wanted to see if Scott’s engineering team could help finance build machine learning models. Allowing finance to forecast the business. Thankfully Scott said yes and lent a few data scientists to help the finance org get off the ground with ML.</p>
<p>The big ticket item was forecasting revenue. Instead of starting small with one specific area we started very high level. Amy wanted a quarterly global revenue forecast by each of Microsoft’s major products. This forecast could be used internally to compare against the manual forecasts. Which are created by sales finance and product finance teams. The ML forecast could either confirm or contradict these bottoms up forecasts made by humans. Allowing finance to either adjust their forecasts. Or make sure they know why they are different than ML.</p>
<p>The results were strong. The ML forecast was around 1%-2% off on average, compared to the manual human forecast error of 2%-4%.</p>
</section>
<section id="keeping-the-ball-rolling" class="level3">
<h3 class="anchored" data-anchor-id="keeping-the-ball-rolling">Keeping The Ball Rolling</h3>
<p>The game officially changed. The finance team could now just rely 100% on ML going forward right? Not so fast! Who would keep training these models? What if we wanted to forecast at a more granular level? Scott’s data scientists couldn’t help forever. To fix this Amy had to hire some data science talent. People who knew what they were doing. Like the engineers on Scott’s team.</p>
<p>Hiring your first data scientist is a hard thing to do. Creating a career path for them in a non-technical team like finance makes it harder. As a first step, a team of vendor data scientists were hired. This was enough help to take the work done by Scott’s team and keep it going. Even expand it to other areas. The hope was to eventually turn a vendor data scientist team into a team of full time employees.</p>
</section>
<section id="lessons-learned" class="level3">
<h3 class="anchored" data-anchor-id="lessons-learned">Lessons Learned</h3>
<p>Going from zero ML work to your first forecast solution takes hard work and perseverance. Here are a few lessons Microsoft finance learned when starting out.</p>
<section id="borrow---rent---buy" class="level4">
<h4 class="anchored" data-anchor-id="borrow---rent---buy">Borrow -&gt; Rent -&gt; Buy</h4>
<p>Initially data scientists were borrowed from other teams at the company. Then they were rented from outside companies as vendors. Then finally once a strong data science practice was established after a few years, full time employees were hired. Many were vendors who turned into full time employees. This process was slow, but allowed finance the time to make sure a data science practice and career path could be built.</p>
</section>
<section id="whats-the-biggest-opportunity" class="level4">
<h4 class="anchored" data-anchor-id="whats-the-biggest-opportunity">What’s the biggest opportunity?</h4>
<p>The biggest opportunity to forecast with ML was revenue. We could have spread ourselves thin and tried to do the entire income statement. But we knew revenue was the hardest to forecast. So that’s where we started first.</p>
</section>
<section id="start-at-the-top-work-your-way-down" class="level4">
<h4 class="anchored" data-anchor-id="start-at-the-top-work-your-way-down">Start at the top, work your way down</h4>
<p>Starting first with worldwide revenue allowed finance to get good results without getting too deep into the weeds first. If we wanted to get an accurate daily forecast down to the sku level, that would have taken forever. Instead we started big and then eventually worked our way down. This process may not initially replace the manual forecast work being done. But it starts to get others in finance comfortable using ML in the decision making process. After finance leaders got used to seeing these ML forecasts, we could then start working on more granular forecasts that could replace more manual work.</p>
</section>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Ok now you know how the ML ball got rolling in Microsoft finance. Before reading this article you might have thought we had this amazing ML kick-off with millions invested in the space. We definitely did not. Instead we started small in areas that had the highest ROI and worked our way from there. If your company is just starting out on your ML journey, I suggest you do the same. Small, incremental change can compound into enormous impact over the long run. That’s the kind of change that lasts.</p>


</section>

 ]]></description>
  <category>finance</category>
  <category>machine-learning</category>
  <category>forecasting</category>
  <guid>https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/</guid>
  <pubDate>Wed, 12 Jun 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-06-12-msft-ml-fcst-journey-1/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
