<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Thoughts on Things</title>
<link>https://mftokic.github.io/index.html</link>
<atom:link href="https://mftokic.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>A collection of thoughts on things from the mind of Mike Tokic</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Tue, 28 May 2024 07:00:00 GMT</lastBuildDate>
<item>
  <title>Time Series First Principles: Model Combinations Are King</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the ninth principle of a good time series forecast, model combinations are king. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/"><strong>Model Combinations Are King</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="wisdom-of-the-crowds" class="level3">
<h3 class="anchored" data-anchor-id="wisdom-of-the-crowds">Wisdom of the Crowds</h3>
<p>In 1906, famed statistician Francis Galton went to a county fair for some fun. While there he came upon a competition to guess the weight of an ox. Eight hundred people entered the competition but the guesses were all over the place, some too high, some too low. Francis was a big numbers guy, so he took all of the guesses home with him and crunched the data. He found out that the average of all the guesses was only one pound away from the actual weight of the ox, which weighed 1,198 pounds. That’s an error of less than 0.08%. What he stumbled upon that day is now know as the wisdom of the crowds.</p>
<p>The concept of wisdom of the crowds states that the collective wisdom of a group of individuals is usually more accurate than that of a single expert. When guessing the weight of the ox, the overestimates and underestimates of regular people cancelled each other out. Creating an average prediction that was more accurate and any single person’s estimate.</p>
<p>This principle is important in machine learning forecasting. Usually it’s not one single model that performs the best, but instead a combination of multiple models. Let’s take a look at how we can combine models into more accurate forecasts.</p>
</section>
<section id="types-of-model-combinations" class="level3">
<h3 class="anchored" data-anchor-id="types-of-model-combinations">Types of Model Combinations</h3>
<p>There are many different ways individual model forecasts can be combined to create more accurate forecasts. For today we’ll cover the most common approaches. If you’d like to dive deeper I recommend this <a href="https://robjhyndman.com/publications/combinations/index.html">amazing paper</a> by our forecasting Godfather Rob Hyndman.</p>
<ol type="1">
<li><strong>Simple Average</strong>: As simple as it sounds. Just take the forecasts from individual models and average them together.</li>
<li><strong>Ensemble Models</strong>: Feed the individual model forecasts as features into a machine learning model, and have the model come up with the correct weighted combination. This is also known as “model stacking”.</li>
<li><strong>Hierarchical Reconciliation</strong>: This involves forecasting at different aggregations of the data set based on its inherent hierarchies, then reconciling the down to the lowest level (bottoms up) using a statistical process. For example forecasting by city, country, continent, and global level then reconciling each forecast down to the city level. This reconciliation can be thought as combining different forecasts together to create something more accurate. This approach has more nuances, and will be covered in another post.</li>
</ol>
</section>
<section id="model-combination-example" class="level3">
<h3 class="anchored" data-anchor-id="model-combination-example">Model Combination Example</h3>
<p>Let’s walk through a simple example around how combining the predictions of more than one model can outperform any single model. Below is an example monthly time series. We will try to back test the last 12 months of the historical data.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/chart1.png" class="img-fluid"></p>
<p>To keep things simple we can just run a few models to get the back testing results for the last year of the data. We’ll use various univariate time series models. Ignore the types of models used. Instead, let’s just see how each model did on it’s own. Learn more about accuracy metrics in a <a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">previous post</a>.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/chart2.png" class="img-fluid"></p>
<table class="table">
<caption>Accuracy by Single Model</caption>
<thead>
<tr class="header">
<th>Model</th>
<th>MAPE</th>
<th>MAE</th>
<th>RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>arima</td>
<td>1.97</td>
<td>3.76</td>
<td>4.68</td>
</tr>
<tr class="even">
<td>croston</td>
<td>10.18</td>
<td>19.54</td>
<td>20.01</td>
</tr>
<tr class="odd">
<td>nnetar</td>
<td>9.77</td>
<td>18.37</td>
<td>26.00</td>
</tr>
<tr class="even">
<td>stlm-ets</td>
<td>1.92</td>
<td>3.68</td>
<td>4.59</td>
</tr>
<tr class="odd">
<td>tbats</td>
<td>1.86</td>
<td>3.51</td>
<td>4.05</td>
</tr>
<tr class="even">
<td>theta</td>
<td>2.46</td>
<td>4.71</td>
<td>5.52</td>
</tr>
</tbody>
</table>
<p>It looks like the tbats model performs the best across the board with stlm-ets and arima not far behind. What if we averaged the three of them together? Let’s see how the results change.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/chart3.png" class="img-fluid"></p>
<table class="table">
<caption>Accuracy for Average Model</caption>
<thead>
<tr class="header">
<th>Model</th>
<th>MAPE</th>
<th>MAE</th>
<th>RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>arima_stlm-ets_tbats</td>
<td>1.84</td>
<td>3.51</td>
<td>3.99</td>
</tr>
</tbody>
</table>
<p>Even better results! See how creating simple model averages can improve the results? Averaging the results can help smooth out any under or over forecasts, creating more accurate models.</p>
<p>Simple model averages are often the quickest way to improved forecast accuracy. Another way is to create an ensemble model that can create the weights on its own. Let’s feed the predictions from each model into a linear regression model and have it determine the optimal weights.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/chart4.png" class="img-fluid"></p>
<table class="table">
<caption>Accuracy for Ensemble Model</caption>
<thead>
<tr class="header">
<th>Model</th>
<th>MAPE</th>
<th>MAE</th>
<th>RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ensemble</td>
<td>1.81</td>
<td>3.40</td>
<td>3.65</td>
</tr>
</tbody>
</table>
<p>Alight more accurate results! By feeding each individual model forecast into a final ensemble model, we were able to get a more accurate forecast.</p>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>When trying to combine models, there is always a risk of overfitting. Meaning the combination approach (like simple average or ensemble) could have great accuracy on the back test data but not generalize well to new unseen data in our future forecast. To prevent that we can make sure to back test on enough historical data to prove our combination approach works well for more than just a period or two. We can also have separate validation and test splits in the back testing to see how combinations made on one data set can generalize well when tested on the other.</p>
<p><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/#future-uncertainty">Prediction intervals</a> are harder to create. Simply combining the 80% and 95% prediction intervals of multiple models together is not going to fully capture the uncertainty of forecasts created by the new model combination. So we would need to re-create the intervals based on the results of the new combined model.</p>
<p>Similar to prediction intervals, combining models can also make it harder to interpret them. Instead of just understanding one model and its predictions, we now have to understand how multiple models work and are combined to get the final forecast.</p>
</section>
<section id="finnts" class="level3">
<h3 class="anchored" data-anchor-id="finnts">finnts</h3>
<p>Model combinations can be hard to do effectively. Thankfully my forecasting package, <a href="https://microsoft.github.io/finnts/index.html">finnts</a>, is here to help! It automatically handles every kind of model combination method listed in this post. Check out the package and see just how easy forecasting can be.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Just like the county fair crowd nailed the ox’s weight, combining multiple models in time series forecasting yields more accurate predictions by balancing out individual errors. When you’re forecasting, remember to embrace the collective wisdom of models for better results!</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/index.html</guid>
  <pubDate>Tue, 28 May 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Multistep Horizon Forecasting With finnts</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-05-13-finnts-multistep-horizon/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-05-13-finnts-multistep-horizon/image.png" class="img-fluid"></p>
<section id="tldr" class="level3">
<h3 class="anchored" data-anchor-id="tldr">TL;DR</h3>
<p>I’m excited to announce that we just released a new feature in our machine learning forecast package, <a href="https://microsoft.github.io/finnts">finnts</a>, centered around multistep horizon forecasting. It’s a mouthful to say but at a high level it helps improve forecast accuracy by optimizing models to be accurate at each period of a forecast horizon. For example, a 3 month forecast would then be optimized for the forecast in each month (period) of the future forecast.</p>
<p>Let’s dive in to how multivariate modeling used to work in the package and how multistep horizon forecasting can help.</p>
</section>
<section id="how-it-used-to-work" class="level3">
<h3 class="anchored" data-anchor-id="how-it-used-to-work">How It Used to Work</h3>
<p>Let’s use an example of a monthly revenue forecast for our business’s main product. In practice we would want more than a year of data but let’s just keep it simple today.</p>
<table class="table">
<thead>
<tr class="header">
<th>Date</th>
<th>Revenue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2023-01-01</td>
<td>120</td>
</tr>
<tr class="even">
<td>2023-02-01</td>
<td>135</td>
</tr>
<tr class="odd">
<td>2023-03-01</td>
<td>140</td>
</tr>
<tr class="even">
<td>2023-04-01</td>
<td>145</td>
</tr>
<tr class="odd">
<td>2023-05-01</td>
<td>150</td>
</tr>
<tr class="even">
<td>2023-06-01</td>
<td>155</td>
</tr>
<tr class="odd">
<td>2023-07-01</td>
<td>160</td>
</tr>
<tr class="even">
<td>2023-08-01</td>
<td>165</td>
</tr>
<tr class="odd">
<td>2023-09-01</td>
<td>170</td>
</tr>
<tr class="even">
<td>2023-10-01</td>
<td>175</td>
</tr>
<tr class="odd">
<td>2023-11-01</td>
<td>180</td>
</tr>
<tr class="even">
<td>2023-12-01</td>
<td>185</td>
</tr>
</tbody>
</table>
<p>If we wanted to forecast the next 3 months of revenue using multivariate machine learning models we would have to do some <a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">feature engineering</a> to get our data in good shape. This involves creating lags on our <span style="text-decoration: underline; cursor: help;" title="What we want to forecast, in this case Revenue.">target variable</span>. Let’s try create some lags on this data.</p>
<table class="table">
<thead>
<tr class="header">
<th>Date</th>
<th>Revenue</th>
<th>Revenue_Lag1</th>
<th>Revenue_Lag2</th>
<th>Revenue_Lag3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2023-01-01</td>
<td>120</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>2023-02-01</td>
<td>135</td>
<td>120</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>2023-03-01</td>
<td>140</td>
<td>135</td>
<td>120</td>
<td></td>
</tr>
<tr class="even">
<td>2023-04-01</td>
<td>145</td>
<td>140</td>
<td>135</td>
<td>120</td>
</tr>
<tr class="odd">
<td>2023-05-01</td>
<td>150</td>
<td>145</td>
<td>140</td>
<td>135</td>
</tr>
<tr class="even">
<td>2023-06-01</td>
<td>155</td>
<td>150</td>
<td>145</td>
<td>140</td>
</tr>
<tr class="odd">
<td>2023-07-01</td>
<td>160</td>
<td>155</td>
<td>150</td>
<td>145</td>
</tr>
<tr class="even">
<td>2023-08-01</td>
<td>165</td>
<td>160</td>
<td>155</td>
<td>150</td>
</tr>
<tr class="odd">
<td>2023-09-01</td>
<td>170</td>
<td>165</td>
<td>160</td>
<td>155</td>
</tr>
<tr class="even">
<td>2023-10-01</td>
<td>175</td>
<td>170</td>
<td>165</td>
<td>160</td>
</tr>
<tr class="odd">
<td>2023-11-01</td>
<td>180</td>
<td>175</td>
<td>170</td>
<td>165</td>
</tr>
<tr class="even">
<td>2023-12-01</td>
<td>185</td>
<td>180</td>
<td>175</td>
<td>170</td>
</tr>
<tr class="odd">
<td>2024-01-01</td>
<td>???</td>
<td>185</td>
<td>180</td>
<td>175</td>
</tr>
<tr class="even">
<td>2024-02-01</td>
<td>???</td>
<td>???</td>
<td>185</td>
<td>180</td>
</tr>
<tr class="odd">
<td>2024-03-01</td>
<td>???</td>
<td>???</td>
<td>???</td>
<td>185</td>
</tr>
</tbody>
</table>
<p>We added some rows onto the bottom of the data, to allow us to forecast out the next 3 months after our historical data ends. That’s what we have question marks “???” for those values. We also added lags for a 1 month, 2 month, and 3 month lag. But hey, looks like we have a problem. We have more question marks for a few future months for lag 1 and lag 2. If we wanted to forecast the next three months we wouldn’t be able to use those lags, since once we get out further in the <span style="text-decoration: underline; cursor: help;" title="How far out we want to forecast, in this case we have a forecast horizon of 3.">forecast horizon</span> we start to have missing lag data.</p>
<p>This means that the smallest lag we could use would always be equal to or greater than the forecast horizon. Since our forecast horizon is 3 than the smallest lag we could use to train a model on would be lag 3. This approach can yield good results, but it removes a lot of potential signal in the data. Revenue next month is most likely impacted by how revenue grew in the current month, but if our forecast horizon is long a lot of this insight has to get thrown away before we can train models. Imagine a forecast horizon of 12. For a monthly forecast this limits our lags to 12 months or more, which is a really bummer since our business can drastically change within 3-6 months, and not using that information in our model can hurt forecast accuracy.</p>
</section>
<section id="how-multistep-horizon-forecasting-works" class="level3">
<h3 class="anchored" data-anchor-id="how-multistep-horizon-forecasting-works">How Multistep Horizon Forecasting Works</h3>
<p>Multistep horizon helps fix this issue that allows us to use smaller lags while still being able to have long forecast horizons. In our 3 month forecast horizon example, we can keep the lag 1 and lag 2 features, but how the model gets trained will be different.</p>
<p>In the non-multistep horizon approach, a specific model is trained once on the data using lags that are equal or greater than the forecast horizon. When we run a multistep horizon approach, we can actually train multiple sub models under the hood of a specific model. In our 3 month forecast horizon, here’s how one model like linear regression will be trained.</p>
<ul>
<li>For the first month in the forecast horizon, we can use all available lags. Lag 1, lag 2, and lag 3 of revenue will all be used to predict the first month.</li>
<li>In the second month of the forecast horizon, we will use lag 2 and 3 to predict the second month.</li>
<li>In the third month of the forecast horizon, we will use lag 3 to predict the third month.</li>
</ul>
<p>Are you starting to get the hang of it? With multistep horizon forecasting we can still have one model that under the hood has multiple sub models that are each optimized on forecasting out a specific part of our forecast horizon. This allows us to have greater accuracy in the first few periods of our forecast horizon. In a non-mulitstep horizon approach, we are always optimizing for the last period in a forecast horizon. If the forecast horizon is 12 months, the way we do the feature engineering and train models is optimized for forecasting out the 12th month. When running a multistep horizon approach, we instead optimize for every period of the forecast horizon.</p>
<p>This kind of approach is so crucial to forecasters in the corporate finance space. Often these financial analysts are tasked with always forecasting out the rest of the entire fiscal year, even though they might only care about the next 3 months, since they are most likely going to be re-creating a new forecast in the following quarter. Multistep horizon forecasting allows these analysts to still forecast out long forecast horizons like 9 or 12 months, while still being able to optimize for the next 1-3 months. How cool is that!</p>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>If each specific model can have 2-5 sub models under the hood, the amount of time needed to train these models can multiply by the same amount. Make sure to keep that in mind if run time is a big factor in your forecasting process.</p>
<p>A multistep horizon forecast may not result in a more accurate forecast for smaller forecast horizons. Some time series may have a strong relationship with a 12 month lag, but less with a 1 month or 2 month lag. This means there is strong yearly seasonality in the data. If there is not a strong relationship with 1 month or 2 month lag, then having multiple sub models optimize for each future month in a multistep horizon approach may not result in more accurate forecasts. Consider doing some <span style="text-decoration: underline; cursor: help;" title="Data analysis that helps us better understand our historical data before we start feature engineering and training models.">exploratory data analysis</span> to see what kind of relationships there are with historical lags of your target variable and other features.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>The new multistep horizon forecasting approach in finnts allows users to create even more accurate forecasts, regardless of their forecast horizon length. If you’d like to learn more check out the <a href="https://microsoft.github.io/finnts/articles/models-used-in-finnts.html#multistep-horizon-models">official finnts documentation</a> to see how you can use the newest multistep horizon feature!</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <category>finnts</category>
  <guid>https://mftokic.github.io/posts/2024-05-13-finnts-multistep-horizon/index.html</guid>
  <pubDate>Mon, 13 May 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-05-13-finnts-multistep-horizon/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: Capture Uncertainty</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the eighth principle of a good time series forecast, capture uncertainty. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/"><strong>Capture Uncertainty</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="building-trust" class="level3">
<h3 class="anchored" data-anchor-id="building-trust">Building Trust</h3>
<p>Would you give your retirement savings to a hedge fund manager because they asked nicely? Probably not. Instead, you would like to do your research about them. Ask them how well they performed in the market historically, and also see how they expect the future markets to unravel in the near term. If their answer to those questions are, “I don’t have a historical track record” and “I have no clue what the future holds” then you are probably not going to give them one penny of your hard earned money. The same holds true for using a time series forecast created by machine learning (ML) models. In order to build trust with the end user of the forecast, you need to show them how a similar forecast would have performed historically and also quantify some aspect about the future. Let’s dive into each one.</p>
</section>
<section id="past-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="past-uncertainty">Past Uncertainty</h3>
<p>Before a ML model can be used to forecast the future, we need to see how it has handled the past. This is called back testing, where we see how a model performed historically. This can give us a good proxy around how it could perform in the future.</p>
<p>Back testing at its core is all about training a model on a portion of your historical data set (training data), then using the trained model on another portion of the historical data (testing data). This can be as simple as using the first 80% of your historical data to train a model, and use the last 20% for testing. Check out a <a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">previous post</a> to learn more about why the order of that train/test split is important.</p>
<p>There are also more advanced methods of doing this, like time series cross-validation. This involves many rounds of training a model and then creating a prediction on the testing data. Time series cross-validation can be used to tune model hyperparameters (inputs a model cannot learn from but must be given by a human) but is especially useful for model back testing. Check out the chart below that shows how we can effectively back test using a time series cross-validation approach. Each pass has its own train and test split, and the testing splits can overlap from one pass to another.</p>
<dl>
<dt><img src="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/chart1.png" class="img-fluid"></dt>
<dd>
<p>Source: Uber Engineering</p>
</dd>
</dl>
<p>In order to capture how accurate the back testing is, we need to calculate a metric that summarizes the model’s performance on the testing data splits. There are countless metrics we can use, each with their own pros and cons. That kind of discussion is out of scope for this post but let’s highlight a few common ones you could use in determining how accurate a model is during back testing.</p>
<ol type="1">
<li><strong>Mean Absolute Error (MAE)</strong>
<ul>
<li><strong>Description</strong>: MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It’s calculated as the average of the absolute differences between forecasts and actual observations.</li>
<li><strong>Strengths</strong>: MAE is straightforward and easy to interpret as it directly represents average error magnitude.</li>
<li><strong>Weaknesses</strong>: MAE treats all errors with the same weight, thus large errors have the same influence as small ones, which might not be optimal for all applications.</li>
</ul></li>
<li><strong>Root Mean Squared Error (RMSE)</strong>
<ul>
<li><strong>Description</strong>: RMSE is the square root of the mean of the squared errors. It measures the average magnitude of the error, with the squaring giving higher weight to larger errors.</li>
<li><strong>Strengths</strong>: RMSE is sensitive to outliers and provides a measure of how large errors are when they occur, which can be crucial for many practical applications.</li>
<li><strong>Weaknesses</strong>: Like MSE, RMSE can be heavily influenced by outliers and large errors, possibly leading to overestimations of the typical error if the error distribution is skewed.</li>
</ul></li>
<li><strong>Mean Absolute Percentage Error (MAPE)</strong>
<ul>
<li><strong>Description</strong>: MAPE expresses accuracy as a percentage, and it measures the size of the error in percentage terms. It is calculated as the average of the absolute errors divided by the actual values, expressed as a percentage.</li>
<li><strong>Strengths</strong>: MAPE is scale-independent and provides a clear interpretation in terms of percentage errors, making it easy to communicate.</li>
<li><strong>Weaknesses</strong>: MAPE can be highly skewed when dealing with values close to zero, and it disproportionately penalizes underestimations compared to overestimations.</li>
</ul></li>
</ol>
</section>
<section id="future-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="future-uncertainty">Future Uncertainty</h3>
<p>Now that we’ve quantified how well our model works historically, we can just give the future forecast to our end user right? Not so fast. Our model might say that next month our company’s product will make $100, but if that’s all the info we provide to the end user of that forecast that’s not a good way to build trust. Instead we need to show how confident we are in that $100 forecast. How likely are we to hit that number? That’s where prediction intervals come in.</p>
<p>Prediction intervals help quantify the future uncertainty in our model’s forecast. They are statistical ranges, typically based on the forecast error, used to indicate the likelihood that the future value of a time series will fall within a specified range at a certain confidence level. Common ranges for a prediction interval are 80% and 95%. For example, the future forecast may be $100 but have a 95% prediction interval of $75 and $125. This means that there is a 95% likelihood that the future value will fall between $75 and $125. The tighter the range, the less uncertainty there is in the forecast. Below is an example forecast with 80% and 95% prediction intervals.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/chart2.png" class="img-fluid"></p>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>The back testing process can only ever be a proxy of what kind of results to expect on the future forecast. It follows the assumption that <a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">the future will be similar to the past</a>. Sometimes this is not the case, and future results may be worse than historical back testing performance.</p>
<p>While prediction intervals help quantify uncertainty, they also do not do a perfect job. There may be times where the future forecast will fall outside of the ranges. It’s not the end of the world when it does, but instead shows that the future is often different than what happened in the past. This is where strong domain knowledge comes in to understand what’s truly an outlier and what’s a new fundamental factor in your business going forward. For example, a new product launch in the future is hard to quantify with a prediction interval, but once it happens we can learn from that information and try to capture it the next time we train our model.</p>
</section>
<section id="finnts" class="level3">
<h3 class="anchored" data-anchor-id="finnts">finnts</h3>
<p>Back testing and prediction intervals is tough work. Thankfully my forecasting package, <a href="https://microsoft.github.io/finnts/index.html">finnts</a>, takes care of both of these for you. You can even customize the back testing process to fit your needs. Check out the package and see just how easy forecasting can be.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Capturing uncertainty in time series forecasting is essential for creating robust forecasts that stakeholders can rely on. Utilizing back testing and prediction intervals not only strengthens the credibility of forecasts but also provides users with a clearer perspective on potential risks and variations. In the end these approaches help build trust with the forecast end user. The more trust we can build, the more likely the ML forecast will be used.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/index.html</guid>
  <pubDate>Tue, 07 May 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: Simple Models Are Better Models</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the seventh principle of a good time series forecast, simple models are better models. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/"><strong>Simple Models Are Better Models</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="occams-ml-model-razor" class="level3">
<h3 class="anchored" data-anchor-id="occams-ml-model-razor">Occam’s ML Model Razor</h3>
<p>William of Ockham was a 14th-century English Franciscan friar, philosopher, and theologian. In his work he preached that for most things in life the simplest explanation is the correct one. I’ve learned this inadvertently in my life many times. For example, when I was studying for the ACT in high school a teacher told me that on the english questions it’s usually the shortest answer that is often correct. You could get a decent score just by following this one rule, even if you couldn’t read or speak english. This one tip saved my ass more than I’d like to admit, and I could read and speak english. Or so I thought.</p>
<p>Often in life, just like the ACT english section, it’s usually the simplest approaches that provide the best results. You can hire a fitness coach and buy all the supplements in the world but you’ll probably get similar results following a handful of simple exercise and eating tips. The same applies in the world of machine learning. The more complexity you add to your data and models, the less likely they are going to be useful in the end. Let’s walk through how simplicity helps in all aspects of machine learning, from the data you use all the way down to models you train.</p>
</section>
<section id="more-features-more-problems" class="level3">
<h3 class="anchored" data-anchor-id="more-features-more-problems">More Features, More Problems</h3>
<p>In the world of time series forecasting, there are so many ways we can do feature engineering. Learn more about feature engineering in a <a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">previous post</a>. A dataset containing two columns, a date and value column, can be transformed into 100+ new features. This can easily get out of hand once we add external regressors (outside variables like consumer sentiment or inflation data) and create new features from them.</p>
<p>Each feature you add to a dataset hurts your model in multiple ways.</p>
<ol type="1">
<li>Train Time: It can slow down model training, meaning it will take longer to train the model. This may not seem like a big deal with small datasets but once you start having tens of thousands of rows in a dataset, adding a new feature can really slow things down.</li>
<li>Overfitting: Adding more features can lead to overfitting, meaning your model might be very accurate on the data it was trained on but cannot generalize well to unseen data in the future. Your model will learn from the noise in the data instead of the signal.</li>
<li>Interpretability: Adding more features makes it harder to explain the model’s predictions. If you can’t explain your forecast to non-technical business partners, then the forecast may not be used by anyone. I’ve seen this countless times in my work. An accurate model doesn’t help anyone if the end user ultimately wants to know how the prediction was created. More on that in <a href="https://mftokic.github.io/posts/2023-02-11-three-levels-of-ml-adoption/">this post</a>.</li>
</ol>
</section>
<section id="feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="feature-selection">Feature Selection</h3>
<p>One way to simplify your data before model fitting is to implement a feature selection process. It’s called selection but it’s more like removal, where we drop any features that do not contribute to a model that can generalize well to new data. Here are a few techniques for feature selection.</p>
<ol type="1">
<li>Domain Expertise: Remove features that don’t make sense to you as a human. For example, the annual rain fall in Iceland might be perfectly correlated to Coca Cola sales in South America, but it doesn’t pass our smell test of being a factor that impacts the business. When in doubt take it out.</li>
<li>Correlation: If a feature has a strong correlation to the target variable (what we want to forecast) then we keep it in, but only after it passes our domain knowledge smell test.</li>
<li>Model Specific: Some models, like certain flavors of linear regression, have built in feature selection or feature importance. We can use that info to remove features and can then retrain on any kind of ML model.</li>
</ol>
<p>There are many other methods for feature selection, but are out of the scope of this post. The ones called out above are a good starting point.</p>
</section>
<section id="simple-models" class="level3">
<h3 class="anchored" data-anchor-id="simple-models">Simple Models</h3>
<p>Simplifying our data is helpful, but sometimes simplifying our models is even better. When starting a new forecast project, you might feel tempted to go out and build an advanced deep learning model, using all of the latest bells and whistles. That model may show promising results, but often a simpler model like linear regression can get the same or even better results. Models like linear regression are faster to train and have better model interpretability.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/image2.png" class="img-fluid"></p>
<p>We can even go one level deeper and not use any features at all. Univariate statistical models like ARIMA or exponential smoothing are classic time series forecasting models that only need one column of data, the historical values of your target variable. That’s what makes them univariate (one variable). They have built in feature engineering under the hood that allows them to learn from historical trends and seasonality in the data, so no additional work is needed to create features. Often in time series forecasting competitions a large team of deep learning researchers can just barely beat a single person team who uses simple models like ARIMA or random forest models. More on that in a future post.</p>
</section>
<section id="finnts" class="level3">
<h3 class="anchored" data-anchor-id="finnts">finnts</h3>
<p>My forecasting package, <a href="https://microsoft.github.io/finnts/index.html">finnts</a>, has built in feature selection and other techniques to ensure simple models are built in ways that produce accurate forecasts. Check out the package and see for yourself.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Ultimately, the goal of any forecasting model is to provide clear, accurate, and quick results. Simpler models often meet these criteria better than complex ones because they’re easier to understand, faster to run, and just as accurate. By focusing on simplicity and minimizing inputs, we ensure that our forecasts are not only effective but also user-friendly. This approach doesn’t just save time; it makes the insights gained from the data accessible to everyone involved in the decision-making process. Simplicity, therefore, isn’t just a principle; it’s a practical strategy for better forecasting.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/index.html</guid>
  <pubDate>Fri, 03 May 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: The Magic Is In The Feature Engineering</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-05-01-time-series-features/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-05-01-time-series-features/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the sixth principle of a good time series forecast, the magic is in the feature engineering. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/"><strong>The Magic Is In The Feature Engineering</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="turning-data-into-insight" class="level3">
<h3 class="anchored" data-anchor-id="turning-data-into-insight">Turning Data Into Insight</h3>
<p>A machine learning (ML) model is only as good as the data it’s fed. The process of transforming data, to make it easier for a model to learn from that data, is called feature engineering. It’s a technical term that is actually very simple in nature, really just data transformations. In the world of time series forecasting, feature engineering can make or break a good forecast.</p>
<p>Creating high quality features is a combination of strong domain expertise and data transformation skills. We have already covered how domain expertise impacts a forecast in a <a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">previous post</a>, so this post will cover how simple data transformations can drastically improve the accuracy of a machine learning forecast. Check out each category of time series feature engineering below to learn more.</p>
</section>
<section id="date-features" class="level3">
<h3 class="anchored" data-anchor-id="date-features">Date Features</h3>
<p>The most common type of feature engineering for time series is around dates. Date features allow us to capture seasonality patterns in our data. Think of seasonality as repeating peaks and valleys in our data. For example, our business might make most of its revenue in Q4 every year, with a subsequent dip in sales in Q1.</p>
<p>Let’s use the example time series below to illustrate each type of feature engineering.</p>
<table class="table">
<caption>Fake Time Series Data</caption>
<thead>
<tr class="header">
<th>Date</th>
<th>Sales ($)</th>
<th>Consumer Sentiment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>100,000</td>
<td>68</td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>110,000</td>
<td>67</td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>120,000</td>
<td>65</td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>115,000</td>
<td>70</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>130,000</td>
<td>72</td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>125,000</td>
<td>73</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>135,000</td>
<td>74</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>140,000</td>
<td>75</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>130,000</td>
<td>70</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>145,000</td>
<td>72</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>150,000</td>
<td>71</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>160,000</td>
<td>75</td>
</tr>
</tbody>
</table>
<p>In this time series we would like to forecast monthly sales. We also have information about consumer sentiment that we can use to help forecast sales. A multivariate machine learning model cannot easily use the date column as is, so we have to do some data transformations (aka feature engineering) to make it easier for a model to understand how date information can help predict sales. Let’s go through a few examples of new features we can create from the date column. It’s important to note that after we create these new features it’s a good idea to remove the original date column before training a ML model.</p>
<p>Since the data is monthly there are a lot of simple features we can use. We can pull out the specific month, quarter, and even year into their own columns to use as features. If our data was at a daily level, we can even go deeper and get features related to day of the week, day of year, week of month, etc.</p>
<table class="table">
<thead>
<tr class="header">
<th>Date</th>
<th>Month</th>
<th>Quarter</th>
<th>Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>January</td>
<td>Q1</td>
<td>2023</td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>February</td>
<td>Q1</td>
<td>2023</td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>March</td>
<td>Q1</td>
<td>2023</td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>April</td>
<td>Q2</td>
<td>2023</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>May</td>
<td>Q2</td>
<td>2023</td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>June</td>
<td>Q2</td>
<td>2023</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>July</td>
<td>Q3</td>
<td>2023</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>August</td>
<td>Q3</td>
<td>2023</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>September</td>
<td>Q3</td>
<td>2023</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>October</td>
<td>Q4</td>
<td>2023</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>November</td>
<td>Q4</td>
<td>2023</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>December</td>
<td>Q4</td>
<td>2023</td>
</tr>
</tbody>
</table>
<p>That seems pretty straight forward right? Let’s keep squeezing our date fruit for more juice and see what other kinds of features we can create. Since this is a time series, adding some order of time can be helpful. This can be something as simple as an index starting at 1 (or even convert your date to a seconds format). This helps establish the proper order of our data and makes is easier for a model to pick up growing or declining trends over time. There is also slight differences in how many days there are from month to month, so we can add that too. If you don’t think that’s important then you have never been stung by the harsh mistress that is leap year. There have been multiple times where finance exec’s have dismissed forecasts for the quarter that includes February, where in the end we didn’t account for the fact that it was a leap year or we are one year removed from one. You can even take this one step further and add the number of business days for each month.</p>
<table class="table">
<caption>Adding a time index and other day related features</caption>
<thead>
<tr class="header">
<th>Date</th>
<th>Index</th>
<th>Days in Month</th>
<th>Business Days</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>1</td>
<td>31</td>
<td>22</td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>2</td>
<td>28</td>
<td>20</td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>3</td>
<td>31</td>
<td>23</td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>4</td>
<td>30</td>
<td>20</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>5</td>
<td>31</td>
<td>23</td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>6</td>
<td>30</td>
<td>22</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>7</td>
<td>31</td>
<td>21</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>8</td>
<td>31</td>
<td>23</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>9</td>
<td>30</td>
<td>21</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>10</td>
<td>31</td>
<td>22</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>11</td>
<td>30</td>
<td>22</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>12</td>
<td>31</td>
<td>21</td>
</tr>
</tbody>
</table>
<p>To get the final drop of juice out of the date column, we can also add Fourier series features. A Fourier series feature in time series forecasting is a component that captures seasonal patterns using sine and cosine functions to model periodic cycles in the data. In a nutshell they are just recurring peaks and valleys that can occur at various date grains like monthly or daily. These features can help capture more complex seasonality in your data. The chart below shows some standard Fourier series at the monthly and quarterly grain.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-01-time-series-features/chart1.png" class="img-fluid"></p>
</section>
<section id="lag-features" class="level3">
<h3 class="anchored" data-anchor-id="lag-features">Lag Features</h3>
<p>Time series forecasting is all about learning from the past to forecast the future. In order to learn about the past we have to create lags on our data. Often what we’re trying to forecast today is correlated to what happened in the past. This is a concept known as autocorrelation. For our monthly forecast example, a 3 month lag may be highly correlated to sales with a 0 month lag (or sales today). Consumer sentiment can also be correlated with sales, but this time a lag of 6 might have higher correlation, since there is most likely a long delay between customer purchase patters and how it affects our company’s product. Lags can be created for any amount, depending on your domain knowledge of the business and results from more exploratory data analysis (deep dive for a different day).</p>
<table class="table">
<caption>Adding lag features</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Sales ($)</th>
<th>Consumer Sentiment</th>
<th>Sales 3-Month Lag</th>
<th>Sentiment 6-Month Lag</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>100,000</td>
<td>68</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>110,000</td>
<td>67</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>120,000</td>
<td>65</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>115,000</td>
<td>70</td>
<td>100,000</td>
<td></td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>130,000</td>
<td>72</td>
<td>110,000</td>
<td></td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>125,000</td>
<td>73</td>
<td>120,000</td>
<td></td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>135,000</td>
<td>74</td>
<td>115,000</td>
<td>68</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>140,000</td>
<td>75</td>
<td>130,000</td>
<td>67</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>130,000</td>
<td>70</td>
<td>125,000</td>
<td>65</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>145,000</td>
<td>72</td>
<td>135,000</td>
<td>70</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>150,000</td>
<td>71</td>
<td>140,000</td>
<td>72</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>160,000</td>
<td>75</td>
<td>130,000</td>
<td>73</td>
</tr>
</tbody>
</table>
<p>Last thing I’ll say here is that you can also create leading features, especially for features that you know with 100% certainty ahead of time. For example, customers knowing of a new product launch in the future will definitely change how they purchase similar products you sell for the periods leading up to the launch. Someone may hold off on buying a new iPhone until the latest one gets released in a few months. Same goes for cars and many other products.</p>
</section>
<section id="rolling-window-features" class="level3">
<h3 class="anchored" data-anchor-id="rolling-window-features">Rolling Window Features</h3>
<p>Often using pure historical lags is not enough. The historical data of our target variable (what we want to forecast) can be very noisy, making it hard for a model to learn the proper trends and seasonality. One way to handle this is through rolling window transformations.</p>
<p>Rolling window features in time series forecasting help smooth out data, reduce noise, and capture essential trends and cycles by averaging or computing other statistics over a specified period. For a monthly forecast we can create rolling window features of averages, min/max, and other statistical calculations.</p>
<dl>
<dt><img src="https://mftokic.github.io/posts/2024-05-01-time-series-features/chart2.png" class="img-fluid"></dt>
<dd>
<p>Rolling Window Averages aka Moving Average</p>
</dd>
</dl>
<p>It’s best to calculate rolling window features based on your existing lag features. That way there is no <a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/#data-leakage">data leakage</a> during initial model training. See below for example of creating a 3 month rolling window average of the 3 month sales lag.</p>
<table class="table">
<caption>Rolling 3 month average applied to the 3 month sales lag</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 16%">
<col style="width: 27%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Sales ($)</th>
<th>Sales 3-Month Lag</th>
<th>3-Month Rolling Avg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>100,000</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>110,000</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>120,000</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>115,000</td>
<td>100,000</td>
<td></td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>130,000</td>
<td>110,000</td>
<td></td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>125,000</td>
<td>120,000</td>
<td>110,000</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>135,000</td>
<td>115,000</td>
<td>115,000</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>140,000</td>
<td>130,000</td>
<td>121,667</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>130,000</td>
<td>125,000</td>
<td>123,333</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>145,000</td>
<td>135,000</td>
<td>130,000</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>150,000</td>
<td>140,000</td>
<td>133,333</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>160,000</td>
<td>130,000</td>
<td>135,000</td>
</tr>
</tbody>
</table>
</section>
<section id="polynomial-features" class="level3">
<h3 class="anchored" data-anchor-id="polynomial-features">Polynomial Features</h3>
<p>The final type of feature engineering I’d like to discuss are polynomial transformations. Sometimes there is a non-linear relationship between your initial feature and the target variable. Some models, like ones that use decision trees, can handle this kind of relationship while others like linear regression cannot. To fix this we can transform the data via polynomials like squaring, cubing, and even taking the log of the initial feature.</p>
<p>Let’s take our example monthly sales data and add some spice to it. This time creating an exponential relationship between consumer sentiment and sales.</p>
<table class="table">
<caption>Updated sales data with an exponential relationship with consumer sentiment</caption>
<thead>
<tr class="header">
<th>Date</th>
<th>Sales ($)</th>
<th>Consumer Sentiment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>1,309,000</td>
<td>68</td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>1,204,000</td>
<td>67</td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>1,000,000</td>
<td>65</td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>1,525,000</td>
<td>70</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>1,849,000</td>
<td>72</td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>1,964,000</td>
<td>73</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>2,121,000</td>
<td>74</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>2,500,000</td>
<td>75</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>1,525,000</td>
<td>70</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>1,849,000</td>
<td>72</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>1,764,000</td>
<td>71</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>2,500,000</td>
<td>75</td>
</tr>
<tr class="odd">
<td>January 2024</td>
<td>2,890,000</td>
<td>76</td>
</tr>
<tr class="even">
<td>February 2024</td>
<td>3,361,000</td>
<td>78</td>
</tr>
<tr class="odd">
<td>March 2024</td>
<td>3,844,000</td>
<td>79</td>
</tr>
<tr class="even">
<td>April 2024</td>
<td>4,641,000</td>
<td>81</td>
</tr>
</tbody>
</table>
<p>When graphing the data, see how the increase in consumer sentiment has an exponential effect on sales?</p>
<p><img src="https://mftokic.github.io/posts/2024-05-01-time-series-features/chart3.png" class="img-fluid"></p>
<p>To account for this, we can square the values of consumer sentiment and create a new feature to use. This new feature will make it easier for models like linear regression to capture these kinds of non-linear relationships.</p>
<table class="table">
<caption>New polynomial feature added</caption>
<colgroup>
<col style="width: 21%">
<col style="width: 15%">
<col style="width: 25%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Sales ($)</th>
<th>Consumer Sentiment</th>
<th>Consumer Sentiment Squared</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>1,309,000</td>
<td>68</td>
<td>4,624</td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>1,204,000</td>
<td>67</td>
<td>4,489</td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>1,000,000</td>
<td>65</td>
<td>4,225</td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>1,525,000</td>
<td>70</td>
<td>4,900</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>1,849,000</td>
<td>72</td>
<td>5,184</td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>1,964,000</td>
<td>73</td>
<td>5,329</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>2,121,000</td>
<td>74</td>
<td>5,476</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>2,500,000</td>
<td>75</td>
<td>5,625</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>1,525,000</td>
<td>70</td>
<td>4,900</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>1,849,000</td>
<td>72</td>
<td>5,184</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>1,764,000</td>
<td>71</td>
<td>5,041</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>2,500,000</td>
<td>75</td>
<td>5,625</td>
</tr>
<tr class="odd">
<td>January 2024</td>
<td>2,890,000</td>
<td>76</td>
<td>5,776</td>
</tr>
<tr class="even">
<td>February 2024</td>
<td>3,361,000</td>
<td>78</td>
<td>6,084</td>
</tr>
<tr class="odd">
<td>March 2024</td>
<td>3,844,000</td>
<td>79</td>
<td>6,241</td>
</tr>
<tr class="even">
<td>April 2024</td>
<td>4,641,000</td>
<td>81</td>
<td>6,561</td>
</tr>
</tbody>
</table>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>Sometimes too much of a good thing can be a bad thing. Adding a lot of new features can increase the chance that a model overfits. Overfitting in machine learning occurs when a model learns to capture noise or random fluctuations in the training data, leading to poor generalization and high performance on training data but low performance on unseen data. The best way to prevent this kind of overfitting is to limit the number of features used to train a model. This will be discussed in greater detail in another post in this series.</p>
<p>Did you notice that when creating lags and rolling window features we had a lot of missing data at the start of the time series for those new features? This can be a problem. Some ML models do not like missing data, so we need to deal with those missing values. An easy way is to just drop the initial rows in the time series that have blank values for the new lags and rolling window features. This can work well if you have a lot of historical data. Dropping data can hurt model performance though, and if you don’t have a lot of data to start with it becomes a less favorable option. You could also replace the missing values, either by using a simple model to impute the value or just use the closest available value in the time series to “fill in” the missing values. Both of these missing value replacement approaches have their own pros and cons but could be a better strategy then just simply dropping rows with missing values.</p>
<table class="table">
<caption>Filling in missing values with their closest available value</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 16%">
<col style="width: 27%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Sales ($)</th>
<th>Sales 3-Month Lag</th>
<th>3-Month Rolling Avg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2023</td>
<td>100,000</td>
<td>100,000</td>
<td>110,000</td>
</tr>
<tr class="even">
<td>February 2023</td>
<td>110,000</td>
<td>100,000</td>
<td>110,000</td>
</tr>
<tr class="odd">
<td>March 2023</td>
<td>120,000</td>
<td>100,000</td>
<td>110,000</td>
</tr>
<tr class="even">
<td>April 2023</td>
<td>115,000</td>
<td>100,000</td>
<td>110,000</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>130,000</td>
<td>110,000</td>
<td>110,000</td>
</tr>
<tr class="even">
<td>June 2023</td>
<td>125,000</td>
<td>120,000</td>
<td>110,000</td>
</tr>
<tr class="odd">
<td>July 2023</td>
<td>135,000</td>
<td>115,000</td>
<td>115,000</td>
</tr>
<tr class="even">
<td>August 2023</td>
<td>140,000</td>
<td>130,000</td>
<td>121,667</td>
</tr>
<tr class="odd">
<td>September 2023</td>
<td>130,000</td>
<td>125,000</td>
<td>123,333</td>
</tr>
<tr class="even">
<td>October 2023</td>
<td>145,000</td>
<td>135,000</td>
<td>130,000</td>
</tr>
<tr class="odd">
<td>November 2023</td>
<td>150,000</td>
<td>140,000</td>
<td>133,333</td>
</tr>
<tr class="even">
<td>December 2023</td>
<td>160,000</td>
<td>130,000</td>
<td>135,000</td>
</tr>
</tbody>
</table>
</section>
<section id="other-pre-processing" class="level3">
<h3 class="anchored" data-anchor-id="other-pre-processing">Other Pre-Processing</h3>
<p>One thing I wanted to add that technically isn’t considered feature engineering are other data pre-processing methods. These are things you apply before you start your feature engineering process. They are specific to time series forecasting and can greatly improve forecast accuracy. Here are two pre-processing methods you should know about.</p>
<p>First is making your data stationary. This is a time series technical term that pretty much means removing the trend component of your data, where the time series has a constant mean and standard deviation. We can make a time series stationary by the process of differencing. This involves taking the difference between each date observation and using that as the new time series to train models with. Check out the example below. See how the upward trend gets removed when we simply use the difference between months instead of the original monthly values? Some machine learning models, like ones that rely on decision trees, cannot extrapolate trends. So differencing the data removes any trend pattern, making it a lot easier for these models to produce high quality forecasts.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-01-time-series-features/chart4.png" class="img-fluid"></p>
<p>Another pre-processing technique is a box-cox transformation. This helps remove any exponentially increasing trends by applying various types of power transformations. For example, taking the log of your time series. Removing non-linear trends can make it a lot easier for a model to create accurate forecasts. See the example below of a time series with a non-linear trend. We can then apply a box-cox transformation and then difference the data. See how nice the final time series looks? It will be way easier for a ML model to learn the patterns in the final transformed time series.</p>
<p><img src="https://mftokic.github.io/posts/2024-05-01-time-series-features/chart5.png" class="img-fluid"></p>
</section>
<section id="finnts" class="level3">
<h3 class="anchored" data-anchor-id="finnts">finnts</h3>
<p>There’s a lot to unpack on feature engineering for time series forecasting. Thankfully my package, <a href="https://microsoft.github.io/finnts/index.html">finnts</a>, can automatically handle all of the feature engineering for you. It does everything I called out in this post plus more. Check it out and see just how easy ML forecasting can be.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Feature engineering is the backbone of successful time series forecasting, allowing models to uncover hidden patterns and relationships within the data, ultimately leading to more accurate predictions. By transforming raw data into meaningful features like date-related attributes, lag features, rolling window statistics, and polynomial transformations, we equip machine learning models with the necessary insights to make informed forecasts. However, it’s crucial to strike a balance between adding informative features and avoiding overfitting, as too many features can lead to poor generalization on unseen data. With careful consideration and the right techniques, feature engineering becomes a powerful tool in the arsenal of any data scientist or analyst aiming to unlock the predictive potential of time series data.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-05-01-time-series-features/index.html</guid>
  <pubDate>Wed, 01 May 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-05-01-time-series-features/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: Order Is Important</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-23-time-series-order/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-23-time-series-order/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the fifth principle of a good time series forecast, order is important. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/"><strong>Order Is Important</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="baking-cakes-over-making-smoothies" class="level3">
<h3 class="anchored" data-anchor-id="baking-cakes-over-making-smoothies">Baking Cakes Over Making Smoothies</h3>
<p>Machine learning (ML) is a lot like cooking. You have various ingredients and can combine them together in clever ways to make for a tasty dish. Most machine learning approaches like classification (predicting an outcome) and regression (predicting a number) can follow a similar process to making a smoothie. We can take some data (fruits and veggies) and blend it all together inside of our model blender.</p>
<p>Time series forecasting is a whole other beast. It still technically falls under the regression family tree but has to be handled very differently. Forecasting is more like baking a cake, where the order in which you do things is very important. For example, you cannot switch when you add the eggs and when you add the frosting. If you do you will certainly not be invited back to your nephew’s birthday party next year. In order to bake something tasty please follow the below guidance.</p>
</section>
<section id="time-series-training" class="level3">
<h3 class="anchored" data-anchor-id="time-series-training">Time Series Training</h3>
<p>Training any sort of machine learning model often requires two separate historical data sets. One that is used to train the initial model, then another that is set aside to create predictions based on the initial model. We can then see how accurate the predictions were on the test data set. This ensures that our new ML model can generalize well to new and unseen data, making sure our model doesn’t overfit to the training data.</p>
<p>Common ML approaches like classification and regression don’t need a lot of sophistication when splitting up the historical data between a training set and a testing set. Often it will be split randomly. This is similar to making a smoothie. You can randomly throw in bananas, apples, spinach, and blueberries. All without having to think about the order of when you do it.</p>
<p>Take the below housing data. This is a traditional regression problem. Let’s use the total square feet and number of bedrooms to predict how much the house will cost. We can randomly split 80% of the data to train the model, then hold out 20% of the data to test how accurate the model is. Randomly splitting the data ensures we get a healthy mix of different data in each split.</p>
<table class="table">
<caption>Example fake housing data for a regression model</caption>
<thead>
<tr class="header">
<th>Square_Feet</th>
<th>Bedrooms</th>
<th>Total_Cost</th>
<th>Split</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>3774</td>
<td>2</td>
<td>822732</td>
<td>Training</td>
</tr>
<tr class="even">
<td>1460</td>
<td>1</td>
<td>245280</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>1894</td>
<td>4</td>
<td>602292</td>
<td>Training</td>
</tr>
<tr class="even">
<td>1730</td>
<td>4</td>
<td>550140</td>
<td>Training</td>
</tr>
<tr class="odd">
<td><strong>1695</strong></td>
<td><strong>4</strong></td>
<td><strong>539010</strong></td>
<td><strong>Testing</strong></td>
</tr>
<tr class="even">
<td>3692</td>
<td>5</td>
<td>1358656</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>2238</td>
<td>1</td>
<td>375984</td>
<td>Training</td>
</tr>
<tr class="even">
<td>2769</td>
<td>5</td>
<td>1018992</td>
<td>Training</td>
</tr>
<tr class="odd">
<td><strong>1066</strong></td>
<td><strong>5</strong></td>
<td><strong>392288</strong></td>
<td><strong>Testing</strong></td>
</tr>
<tr class="even">
<td>1838</td>
<td>1</td>
<td>308784</td>
<td>Training</td>
</tr>
</tbody>
</table>
<p>A time series has a built in order to it. It’s said right there in the name, time. Ignoring the order based on time can have disastrous consequences, resulting in your final future forecast not being accurate. Just like baking a cake, we need to make sure how we train a model is done in the right order. When splitting a historical time series into a training set and a testing set, splitting not at random but based on time is the proper way to go. Using the oldest data as the training set and the newest data as the testing set makes sure we respect the order of our data based on time. The example table below is a made up time series of the price of one specific house. In reality we would need a lot more data to train a good time series model but just be cool for a minute and go with me on this one. The split column now has the test data set at the very end instead of randomly split across time. We can now use <a href="https://developers.google.com/machine-learning/crash-course/framing/ml-terminology">features</a> like interest rates and gdp growth to help us forecast the price of this house over time. The first 9 months of data will train the model, and the final 3 months will be used to test the model’s accuracy.</p>
<table class="table">
<caption>Example fake time series for the price of a specific house</caption>
<colgroup>
<col style="width: 24%">
<col style="width: 23%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Interest_Rate</th>
<th>GDP_Growth</th>
<th>Total_Cost</th>
<th>Split</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2002</td>
<td>3.43635</td>
<td>1.58111</td>
<td>315052</td>
<td>Training</td>
</tr>
<tr class="even">
<td>February 2002</td>
<td>4.87679</td>
<td>0.03085</td>
<td>314723</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>March 2002</td>
<td>4.32998</td>
<td>-0.04544</td>
<td>312854</td>
<td>Training</td>
</tr>
<tr class="even">
<td>April 2002</td>
<td>3.99665</td>
<td>-0.04149</td>
<td>311865</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>May 2002</td>
<td>2.89005</td>
<td>0.26061</td>
<td>309452</td>
<td>Training</td>
</tr>
<tr class="even">
<td>June 2002</td>
<td>2.88999</td>
<td>0.81189</td>
<td>311106</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>July 2002</td>
<td>2.64521</td>
<td>0.57986</td>
<td>309675</td>
<td>Training</td>
</tr>
<tr class="even">
<td>August 2002</td>
<td>4.66544</td>
<td>0.22807</td>
<td>314681</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>September 2002</td>
<td>4.00279</td>
<td>1.02963</td>
<td>315097</td>
<td>Training</td>
</tr>
<tr class="even">
<td><strong>October 2002</strong></td>
<td><strong>4.27018</strong></td>
<td><strong>-0.15127</strong></td>
<td><strong>312357</strong></td>
<td><strong>Testing</strong></td>
</tr>
<tr class="odd">
<td><strong>November 2002</strong></td>
<td><strong>2.55146</strong></td>
<td><strong>0.23036</strong></td>
<td><strong>308345</strong></td>
<td><strong>Testing</strong></td>
</tr>
<tr class="even">
<td><strong>December 2002</strong></td>
<td><strong>4.92477</strong></td>
<td><strong>0.41591</strong></td>
<td><strong>316022</strong></td>
<td><strong>Testing</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="data-leakage" class="level3">
<h3 class="anchored" data-anchor-id="data-leakage">Data Leakage</h3>
<p>Whenever time is involved in machine learning, the probability of shooting yourself in the foot rises. This has to do with the concept of <a href="https://machinelearningmastery.com/data-leakage-machine-learning/">data leakage</a>. Data leakage occurs when information from outside the training dataset is used to create the model, leading it to make overly optimistic predictions. It can also happen when we train with data that may not be available in the future when we need to create new predictions.</p>
<p>In time series forecasting we have already discussed one component of data leakage, related to splitting the data correctly based on time. Take the below table, instead of splitting properly by time the data is now split randomly. Our model can now “see ahead in time” when training, and in effect cheat when being evaluated on the testing splits. For example, for the test observation in July 2002 the model can learn from data on either side of that month. Figuring out previous and future trends and seasonality. This makes it easy to predict what the housing cost in July should be, since it has information before and after that month. With this approach our test accuracy will be a lot better than in the previous example where the splits are based on time. Future forecast performance will suffer though, since we have now trained and chosen a model that may only be good at figuring out how to extrapolate between two points, instead of trying to create predictions on unseen data in the future.</p>
<table class="table">
<caption>Incorrect train and test splits</caption>
<colgroup>
<col style="width: 24%">
<col style="width: 23%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Interest_Rate</th>
<th>GDP_Growth</th>
<th>Total_Cost</th>
<th>Split</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>January 2002</td>
<td>3.43635</td>
<td>1.58111</td>
<td>315052</td>
<td>Training</td>
</tr>
<tr class="even">
<td><strong>February 2002</strong></td>
<td><strong>4.87679</strong></td>
<td><strong>0.03085</strong></td>
<td><strong>314723</strong></td>
<td><strong>Testing</strong></td>
</tr>
<tr class="odd">
<td>March 2002</td>
<td>4.32998</td>
<td>-0.04544</td>
<td>312854</td>
<td>Training</td>
</tr>
<tr class="even">
<td>April 2002</td>
<td>3.99665</td>
<td>-0.04149</td>
<td>311865</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>May 2002</td>
<td>2.89005</td>
<td>0.26061</td>
<td>309452</td>
<td>Training</td>
</tr>
<tr class="even">
<td>June 2002</td>
<td>2.88999</td>
<td>0.81189</td>
<td>311106</td>
<td>Training</td>
</tr>
<tr class="odd">
<td><strong>July 2002</strong></td>
<td><strong>2.64521</strong></td>
<td><strong>0.57986</strong></td>
<td><strong>309675</strong></td>
<td><strong>Testing</strong></td>
</tr>
<tr class="even">
<td>August 2002</td>
<td>4.66544</td>
<td>0.22807</td>
<td>314681</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>September 2002</td>
<td>4.00279</td>
<td>1.02963</td>
<td>315097</td>
<td>Training</td>
</tr>
<tr class="even">
<td>October 2002</td>
<td>4.27018</td>
<td>-0.15127</td>
<td>312357</td>
<td>Training</td>
</tr>
<tr class="odd">
<td>November 2002</td>
<td>2.55146</td>
<td>0.23036</td>
<td>308345</td>
<td>Training</td>
</tr>
<tr class="even">
<td><strong>December 2002</strong></td>
<td><strong>4.92477</strong></td>
<td><strong>0.41591</strong></td>
<td><strong>316022</strong></td>
<td><strong>Testing</strong></td>
</tr>
</tbody>
</table>
<p>Ok, so we know not to split data randomly when training. Another thing to watch out for is how features are used in the model. In our time series housing example, we can use date information (month, quarter, etc) along with our macro features like interest rates and GDP growth. Let’s say we follow the right approach, split the data based on time, and see that we get good results on the test data. We can now take our model into production and try to create a forecast for the future. But wait, what do we do with the future feature values of interest rate and GDP growth? This is another potential data leakage issue, where data used to train the model is not available to create new predictions in the future. You might be thinking, no problem we can just create a forecast of future interest rates and gdp growth right? Wrong. If you can produce accurate interest rate and GDP growth forecasts, then you shouldn’t be reading this post. You should instead be sitting on your own private island, watching the return on your flagship hedge fund skyrocket. See where I’m going here? If you cannot perfectly predict future values of the feature you want to use, then you should consider not using that feature. You might be able to know with 100% certainty when a holiday or special event will take place, but not even expert economists can perfectly predict interest rate fluctuations. Instead you can look at using feature lags. Where instead of using real time interest rates or GDP growth you can instead use lags of them. For example, using a 3 or 12 month lag of each feature. Using lags in this example can help prevent <a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/#reversal">compounding errors</a> in your forecast.</p>
</section>
<section id="finnts" class="level3">
<h3 class="anchored" data-anchor-id="finnts">finnts</h3>
<p>Looking for a way to to never worry about the order of your time series data again? Have no fear because <a href="https://microsoft.github.io/finnts/index.html">finnts</a> is here! Ok enough with the used car salesman talk. The finnts package is something myself and other outstanding team members have built to automate all of the tedious aspects related to time series forecasting. The package can automatically handle the proper splits of your data and has build in data leakage prevention. Check out the package to learn for yourself how easy forecasting can be.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Remember, order is important in forecasting. Make sure you don’t mix up your data when training models, and keep a look out for data leakage. Do this right and you just might get invited back to your nephew’s birthday party next year.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-04-23-time-series-order/index.html</guid>
  <pubDate>Tue, 23 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-23-time-series-order/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (4/19/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-19-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-19-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://hbr.org/2023/12/use-strategic-thinking-to-create-the-life-you-want">Use Strategic Thinking to Create the Life You Want</a></li>
<li><a href="https://www.maximiliankiener.com/digitalprojects/time/">How Time Flies</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Time Series First Principles: Higher Grain, Higher Accuracy</a></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=5N4UFl9G00A">Dave Chappelle - Unforgiven</a></li>
<li><a href="https://www.youtube.com/watch?v=-9ROlCeB5FQ">Balaji on AI Gods</a></li>
<li><a href="https://www.youtube.com/watch?v=SEnuWRLMI88">Building Laser Focus</a></li>
<li><a href="https://www.youtube.com/watch?v=5qGItht6U0E">Overrated and Underrated Habits</a></li>
<li><a href="https://www.youtube.com/watch?v=FPFqB1P9BIo">Lessons Learned on Writing</a></li>
</ul>
</section>
<section id="sites" class="level2">
<h2 class="anchored" data-anchor-id="sites">Sites</h2>
<ul>
<li><a href="https://suno.com/">Make Music with AI</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://twitter.com/trungtphan/status/1780794237426323918?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">Building an Engineering Dream Team</a></li>
<li><a href="https://twitter.com/tunguz/status/1779532581274570991?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">Experiences &gt; Things</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-04-19-weekend-reads/index.html</guid>
  <pubDate>Fri, 19 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-19-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: Higher Grain Higher Accuracy</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-18-time-series-grain/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-18-time-series-grain/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the fourth principle of a good time series forecast, the higher the grain the higher the accuracy. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/"><strong>Higher Grain Higher Accuracy</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="clear-skies" class="level3">
<h3 class="anchored" data-anchor-id="clear-skies">Clear Skies</h3>
<p>When planes take off from the ground they climb high into the sky. During that 5-10 minute period passengers have to stay seated with their seatbelt fastened. It’s only after the plane reaches 10,000 feet people can start to get up and move around the plane. Eventually the plane can reach an altitude of 40,000 feet. To compare, the peak of Mount Everest is 29,000 feet off the ground. Planes go up that high because it’s easier to fly the plane and more efficient. If planes flew a few feet off the ground it would be a lot bumpier ride, having to deal with changing weather and turbulence.</p>
<p>Forecasting is similar to flying a plane. Training a machine learning (ML) model at a higher grain of data is akin to a plane climbing in altitude. There is less turbulence (noise) in the data and your forecast has a better chance of being more accurate. You can either climb in altitude at the individual time series grain, or by the date grain. Let’s discuss each of them along with other methods.</p>
</section>
<section id="time-series-grain" class="level3">
<h3 class="anchored" data-anchor-id="time-series-grain">Time Series Grain</h3>
<p>Think of a higher time series grain as an aggregation of your original data. For example you might have product sales across a bunch of cities, where each city is a time series. Individual cities might have hard to model trend and seasonality, but when combined at a total country-level, it can be easier to model. Take the example charts below. Each city might be noisy but climbing in altitude up to the county level makes it easier to spot trends and seasonality.</p>
<p><img src="https://mftokic.github.io/posts/2024-04-18-time-series-grain/chart2.png" class="img-fluid"> <img src="https://mftokic.github.io/posts/2024-04-18-time-series-grain/chart1.png" class="img-fluid"></p>
</section>
<section id="date-grain" class="level3">
<h3 class="anchored" data-anchor-id="date-grain">Date Grain</h3>
<p>In a perfect world we would be able to forecast our businesses down to the day, or even minute, across the next 10 years. This is sadly not the case. The more granular you try to forecast at the date grain, the noisier the data is going to be, and the harder it will be to create accurate forecasts. Unless there is an absolute need to forecast at a certain level, I almost always recommend a higher date grain. Take the example charts below. See how aggregating daily data to a monthly date grain level makes it easier to spot trends and seasonality.</p>
<p><img src="https://mftokic.github.io/posts/2024-04-18-time-series-grain/chart3.png" class="img-fluid"> <img src="https://mftokic.github.io/posts/2024-04-18-time-series-grain/chart4.png" class="img-fluid"></p>
<p>In the finance org, the most common date grain to forecast at is month. This gives a healthy balance of being able to forecast long periods of time while also being able to update your forecast with new historical data every few weeks.</p>
<p>Here is another important point to call out. The longer your forecast horizon, the higher the date grain you should forecast at. Here are some recommendations based on your forecast horizon (how many periods you want to forecast). For example, if you’re trying to forecast out the next 6 months at the daily grain, you might get better results if you aggregate up to the monthly grain and forecast by month instead.</p>
<ul>
<li>Daily Grain: 1-90 day forecast horizon</li>
<li>Weekly Grain: 1-12 week forecast horizon</li>
<li>Monthly Grain: 1-18 month forecast horizon</li>
<li>Quarterly Grain: 1-8 quarter forecast horizon</li>
<li>Yearly Grain: more than 1 year forecast horizon</li>
</ul>
</section>
<section id="hierarchical-forecasting" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-forecasting">Hierarchical Forecasting</h3>
<p>A potential “best of both worlds” solution to the data grain issue is to use a hierarchical forecast. This is where you can train models at different grains of the data, then use a statistical process to reconcile each forecast together so they are in sync. Our forecasting godfather, Rob Hyndman, has done a lot of great work in this space. Here is a <a href="https://otexts.com/fpp3/hierarchical.html">chapter from his book</a> on hierarchical forecasting.</p>
<p>Let’s go back to our time series grain example. Using a hierarchical forecast you could train models and create forecasts for each city, then do the same at the total country-level, then finally do the same at a total world wide level across all countries. This is a standard hierarchical approach shown in the chart below. This hierarchical process blends a “bottoms up” forecast of creating predictions at the lowest level by city, with a “tops down” forecast of creating predictions at the highest global level. A statistical process is then used to make the “tops down” forecast equal the “bottoms up” forecast, optimizing for accuracy at all levels of the hierarchy.</p>
<p><img src="https://mftokic.github.io/posts/2024-04-18-time-series-grain/chart5.png" class="img-fluid"></p>
<p>The same idea can be applied at the date grain too. Where you can forecast at the daily level, weekly level, and monthly level. Then use a reconciliation process to get the final forecast at the daily level that is also accurate when summing up by month. This can work well if a monthly forecast is more accurate, but the final forecast needs to be at a daily level.</p>
</section>
<section id="allocations" class="level3">
<h3 class="anchored" data-anchor-id="allocations">Allocations</h3>
<p>Another option is to take a forecast at a higher grain and allocate it down to a lower grain using simple allocation logic. This process can replace the more complicated hierarchical forecasting discussed earlier. Simple allocations can be done in two ways.</p>
<p>The first is to take historical values and create a percent split to apply to the final forecast. For example we can create a forecast at the country-level, then split that out by city. The split percent by city (allocation percent) can be calculated based on how much each city was the percent of total country over the last few years. This can be broken down by period. So you can get a specific percent split for each month on average in the past. This approach helps maintain historical seasonality across each time series (each city). See the charts below for an example of using two historical years of monthly data to create the final allocation percentages.</p>
<table class="table">
<caption>Historical splits by city</caption>
<thead>
<tr class="header">
<th>Month</th>
<th>City A %</th>
<th>City B %</th>
<th>City C %</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jan 2021</td>
<td>30.87%</td>
<td>30.08%</td>
<td>39.05%</td>
</tr>
<tr class="even">
<td>Feb 2021</td>
<td>28.11%</td>
<td>23.90%</td>
<td>47.99%</td>
</tr>
<tr class="odd">
<td>Mar 2021</td>
<td>23.77%</td>
<td>47.43%</td>
<td>28.81%</td>
</tr>
<tr class="even">
<td>Apr 2021</td>
<td>31.26%</td>
<td>18.42%</td>
<td>50.32%</td>
</tr>
<tr class="odd">
<td>May 2021</td>
<td>39.50%</td>
<td>34.08%</td>
<td>26.42%</td>
</tr>
<tr class="even">
<td>Jun 2021</td>
<td>50.58%</td>
<td>30.98%</td>
<td>18.44%</td>
</tr>
<tr class="odd">
<td>Jan 2022</td>
<td>36.33%</td>
<td>31.79%</td>
<td>31.88%</td>
</tr>
<tr class="even">
<td>Feb 2022</td>
<td>19.79%</td>
<td>40.74%</td>
<td>39.47%</td>
</tr>
<tr class="odd">
<td>Mar 2022</td>
<td>19.95%</td>
<td>28.99%</td>
<td>51.06%</td>
</tr>
<tr class="even">
<td>Apr 2022</td>
<td>20.37%</td>
<td>26.76%</td>
<td>52.87%</td>
</tr>
<tr class="odd">
<td>May 2022</td>
<td>41.37%</td>
<td>41.53%</td>
<td>17.10%</td>
</tr>
<tr class="even">
<td>Jun 2022</td>
<td>43.86%</td>
<td>41.10%</td>
<td>15.04%</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Average of city split by month</caption>
<thead>
<tr class="header">
<th>Month</th>
<th>City A %</th>
<th>City B %</th>
<th>City C %</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jan</td>
<td>33.60%</td>
<td>30.93%</td>
<td>35.46%</td>
</tr>
<tr class="even">
<td>Feb</td>
<td>23.95%</td>
<td>32.32%</td>
<td>43.73%</td>
</tr>
<tr class="odd">
<td>Mar</td>
<td>21.86%</td>
<td>38.21%</td>
<td>39.93%</td>
</tr>
<tr class="even">
<td>Apr</td>
<td>25.82%</td>
<td>22.59%</td>
<td>51.60%</td>
</tr>
<tr class="odd">
<td>May</td>
<td>40.43%</td>
<td>37.81%</td>
<td>21.76%</td>
</tr>
<tr class="even">
<td>Jun</td>
<td>47.22%</td>
<td>36.04%</td>
<td>16.74%</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Final forecast using the city splits</caption>
<colgroup>
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Month</th>
<th style="text-align: right;">Country Forecast</th>
<th style="text-align: right;">City A %</th>
<th style="text-align: right;">City B %</th>
<th style="text-align: right;">City C %</th>
<th style="text-align: right;">City A Forecast</th>
<th style="text-align: right;">City B Forecast</th>
<th style="text-align: right;">City C Forecast</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Jan 2023</td>
<td style="text-align: right;">15000</td>
<td style="text-align: right;">33.60</td>
<td style="text-align: right;">30.93</td>
<td style="text-align: right;">35.46</td>
<td style="text-align: right;">5040</td>
<td style="text-align: right;">4639.5</td>
<td style="text-align: right;">5319</td>
</tr>
<tr class="even">
<td style="text-align: left;">Feb 2023</td>
<td style="text-align: right;">15200</td>
<td style="text-align: right;">23.95</td>
<td style="text-align: right;">32.32</td>
<td style="text-align: right;">43.73</td>
<td style="text-align: right;">3640.4</td>
<td style="text-align: right;">4912.64</td>
<td style="text-align: right;">6646.96</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Mar 2023</td>
<td style="text-align: right;">15400</td>
<td style="text-align: right;">21.86</td>
<td style="text-align: right;">38.21</td>
<td style="text-align: right;">39.93</td>
<td style="text-align: right;">3366.44</td>
<td style="text-align: right;">5884.34</td>
<td style="text-align: right;">6149.22</td>
</tr>
<tr class="even">
<td style="text-align: left;">Apr 2023</td>
<td style="text-align: right;">15600</td>
<td style="text-align: right;">25.82</td>
<td style="text-align: right;">22.59</td>
<td style="text-align: right;">51.60</td>
<td style="text-align: right;">4027.92</td>
<td style="text-align: right;">3524.04</td>
<td style="text-align: right;">8049.6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">May 2023</td>
<td style="text-align: right;">15800</td>
<td style="text-align: right;">40.43</td>
<td style="text-align: right;">37.81</td>
<td style="text-align: right;">21.76</td>
<td style="text-align: right;">6387.94</td>
<td style="text-align: right;">5973.98</td>
<td style="text-align: right;">3438.08</td>
</tr>
<tr class="even">
<td style="text-align: left;">Jun 2023</td>
<td style="text-align: right;">16000</td>
<td style="text-align: right;">47.22</td>
<td style="text-align: right;">36.04</td>
<td style="text-align: right;">16.74</td>
<td style="text-align: right;">7555.2</td>
<td style="text-align: right;">5766.4</td>
<td style="text-align: right;">2678.4</td>
</tr>
</tbody>
</table>
<p>The second approach is to use a future forecast to create the allocation splits. For example we can create future forecasts at the country-level and also at the city-level. Then we can create the split percent for each city by taking the city forecast and summing it up to the country-level, then taking the percent split for each city. These splits can then be applied to the final country-level forecast to get the final forecast by city. This approach uses the more robust country-level forecast, while still trying to capture future changing trends and seasonality by city.</p>
<table class="table">
<caption>Initial forecast, where country and each city are forecasted separately</caption>
<colgroup>
<col style="width: 12%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>Month</th>
<th>Country Forecast</th>
<th>City A Forecast</th>
<th>City B Forecast</th>
<th>City C Forecast</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jan 2023</td>
<td>10,000</td>
<td>4,000</td>
<td>3,500</td>
<td>2,000</td>
</tr>
<tr class="even">
<td>Feb 2023</td>
<td>10,500</td>
<td>4,200</td>
<td>3,000</td>
<td>3,300</td>
</tr>
<tr class="odd">
<td>Mar 2023</td>
<td>11,000</td>
<td>4,500</td>
<td>3,200</td>
<td>3,300</td>
</tr>
<tr class="even">
<td>Apr 2023</td>
<td>11,500</td>
<td>4,800</td>
<td>3,400</td>
<td>3,300</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>12,000</td>
<td>5,000</td>
<td>3,500</td>
<td>3,500</td>
</tr>
<tr class="even">
<td>Jun 2023</td>
<td>12,500</td>
<td>5,200</td>
<td>3,800</td>
<td>3,500</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Calculating the percent splits by city</caption>
<thead>
<tr class="header">
<th>Month</th>
<th>City A %</th>
<th>City B %</th>
<th>City C %</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jan 2023</td>
<td>42.11%</td>
<td>36.84%</td>
<td>21.05%</td>
</tr>
<tr class="even">
<td>Feb 2023</td>
<td>40.00%</td>
<td>28.57%</td>
<td>31.43%</td>
</tr>
<tr class="odd">
<td>Mar 2023</td>
<td>40.91%</td>
<td>29.09%</td>
<td>30.00%</td>
</tr>
<tr class="even">
<td>Apr 2023</td>
<td>41.74%</td>
<td>29.57%</td>
<td>28.70%</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>41.67%</td>
<td>29.17%</td>
<td>29.17%</td>
</tr>
<tr class="even">
<td>Jun 2023</td>
<td>41.60%</td>
<td>30.40%</td>
<td>28.00%</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Final forecast after applying the city splits to the country-level forecast</caption>
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Month</th>
<th>City A Final Forecast</th>
<th>City B Final Forecast</th>
<th>City C Final Forecast</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jan 2023</td>
<td>4,211</td>
<td>3,684</td>
<td>2,105</td>
</tr>
<tr class="even">
<td>Feb 2023</td>
<td>4,200</td>
<td>3,000</td>
<td>3,300</td>
</tr>
<tr class="odd">
<td>Mar 2023</td>
<td>4,500</td>
<td>3,200</td>
<td>3,300</td>
</tr>
<tr class="even">
<td>Apr 2023</td>
<td>4,800</td>
<td>3,400</td>
<td>3,300</td>
</tr>
<tr class="odd">
<td>May 2023</td>
<td>5,000</td>
<td>3,500</td>
<td>3,500</td>
</tr>
<tr class="even">
<td>Jun 2023</td>
<td>5,200</td>
<td>3,800</td>
<td>3,500</td>
</tr>
</tbody>
</table>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>A more granular forecast can sometimes be more accurate, especially if the more detailed grain uncovers more stable trends and seasonality that can be modeled. Take for example a product whose sales are impacted by Chinese New Year. That holiday doesn’t happen on the same day every year, and it can even happen in different months. Sometimes in January, and sometimes in February. Since it happens over multiple days the split between the two months can change drastically from year to year. Creating a forecast at the daily level, adding information around when Chinese New Year is happening, could result in a more accurate forecast. You could also take the approach of a monthly forecast, and have a numeric feature that lists how many days of Chinese New Year falls within each month.</p>
<p>If your initial data at the higher grain is noisy or has low forecast accuracy, consider asking the domain expert if there could be more insightful trends and seasonality at a lower grain.</p>
</section>
<section id="finnts" class="level3">
<h3 class="anchored" data-anchor-id="finnts">finnts</h3>
<p>Hierarchical forecasting is a tricky business, thankfully my open-source package <a href="https://microsoft.github.io/finnts/index.html">finnts</a> can automatically do hierarchical forecasting. The package can even use external regressors (features) in the hierarchical approach! Today finnts supports hierarchical forecasting at the time series grain. Hopefully one day we will implement hierarchical forecasting at the date grain, stay tuned. This is the same package I use internally at my job, allowing my company to replace hundreds of billions of manual forecasts with machine learning. Check out the package and see for yourself.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Just as pilots navigate to higher altitudes to find smoother skies and better efficiency, so too must we elevate our approach to data granularity in forecasting when needed. By stepping back from the minutiae of daily or city-level data and ascending to monthly or country-level aggregations, we enable our models to capture more coherent patterns and deliver forecasts with improved precision. This strategic shift—from a granular view to a broader perspective—is not just about avoiding turbulence; it’s about leveraging stability to enhance predictability.</p>
<p>However, the real magic often lies in blending these approaches through hierarchical forecasting. This method combines the detailed insights available at lower levels with the clarity and simplicity of higher-level forecasts, ensuring both depth and breadth in our predictive capabilities. As we continue to refine our techniques and tools, like the finnts package, we are paving the way for a future where complex, multi-tiered forecasting is as streamlined as a flight cruising at 40,000 feet.</p>
<p>In your journey through data, remember that the right altitude can make all the difference. Rising above the noise can provide not just clearer views, but also far-reaching insights. So, buckle up—we’re about to take forecasting to new heights.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-04-18-time-series-grain/index.html</guid>
  <pubDate>Thu, 18 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-18-time-series-grain/image.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>Weekend Reads (4/12/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-12-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-12-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://tim.blog/wp-content/uploads/2020/01/17-Questions-That-Changed-My-Life.pdf">17 Important Questions</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Time Series First Principles: Garbage In, Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">Time Series First Principles: The Future Is Similar To The Past</a></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://youtu.be/Z2BnqYArwaw?si=tfQXzl1Zu4Zfom9R">Telling Good Stories</a></li>
<li><a href="https://youtu.be/_ZJpU43NA0c?si=-kIn8vjU9-PYWaE2">Power of Being a Contrarian</a></li>
<li><a href="https://youtu.be/sgVDljNavSc?si=YnSlsK_JgUqlv6Lp">Making Friends as an Adult</a></li>
</ul>
</section>
<section id="podcasts" class="level2">
<h2 class="anchored" data-anchor-id="podcasts">Podcasts</h2>
<ul>
<li><a href="https://open.spotify.com/episode/1Ab1UcjpAvbhAhUslDt0kA?si=oGRuirSFQaWt1G6z_gawaw">Protocols to Improve Your Sleep, Huberman Lab</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/jasonfried/status/1775918262259536230">Power of Motivation</a></li>
<li><a href="https://x.com/JamesLucasIT/status/1777026561947963709">Our Planet Rocks</a></li>
<li><a href="https://x.com/DeepLearningAI/status/1777345409007952098">Shipping on Fridays</a></li>
<li><a href="https://x.com/Alkibiades_/status/1777418763316466080">Cool Idea Around Building the Pyramids</a></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://www.amazon.com/Sapiens-Humankind-Yuval-Noah-Harari-ebook/dp/B00ICN066A/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.04mm2YQe9BvKUhAU-tuaKKTp_ekz9KX-YILKoI3_bfIEBt49_HpfeyFUJJlvIwSWAIPWrL_6wT9ArXYinHBdd26BvpLuJiO8L-PDmeH6Bp72MBNaBM3BIkDJczpjw__nnhyQBkyPBqqAxj5-FZHbC_wDc7NP_EpLiA253DUGUSSl1faJjZ8ThMS_HxUzPgC0WHQZRl5HkHwYJMTQgcFc-mGrBXCLrlR63IS6_1cyxs4.80oPRRInfnlKdy_MYM4yAdkI9w0YEtNugcGm04aOaDM&amp;qid=1712934638&amp;sr=8-1">Sapiens by Yuval Noah Harari</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-04-12-weekend-reads/index.html</guid>
  <pubDate>Fri, 12 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-12-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: The Future Is Similar To The Past</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-11-time-series-past-future/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the third principle of a good time series forecast, the future is similar to the past. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/"><strong>The Future Is Similar To The Past</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="here-comes-the-sun" class="level3">
<h3 class="anchored" data-anchor-id="here-comes-the-sun">Here Comes The Sun</h3>
<p>For whatever you’re trying to forecast, it will be a lot easier to do with with machine learning (ML) if the future is similar to the past. It’s as simple as that.</p>
<p>When you open the weather app on your phone, have you ever looked at when the sun is expected to rise and set? If you’re on the new human optimization craze about getting morning sunlight, you most likely have. That forecast is down to the minute, most likely even second, and has a high degree of accuracy. Is the forecast accurate because of expert human judgement, or the type of weather related <a href="https://vitalflux.com/what-are-features-in-machine-learning/">features</a> fed into a ML model? Nope. It’s accurate because the sun has risen and set at relatively the same time, based on time of year, for millions of years. We don’t expect future sun rises and sun sets to change that much going forward, that’s why your weather app gives you an exact time for the sun rise but gives you only a percent probability of rain. Even then, that chance of rain may not even be accurate. It’s almost a joke now how many times in Seattle I’ve seen a dry forecast only to step out of my house and have it immediately start raining. At least I know the exact minute when the sun will set that day.</p>
</section>
<section id="handling-a-changing-future" class="level3">
<h3 class="anchored" data-anchor-id="handling-a-changing-future">Handling A Changing Future</h3>
<p>Your business is most likely not like the sun. It’s constantly changing, reacting to market forces and industry competitors. The best way to teach a model about your expectations of the future is to give it data about the past and future.</p>
<p>Let’s use an example of a monthly revenue forecast for a product. If you only use historical sales data to forecast the product, then you are making the assumption that the future of the product will be almost identical to the past, especially the most recent past. For some established products in mature industries this could be totally fine, but often this is not the case.</p>
<p>One thing to try is adding features that can explain how outside forces impact the product. For example, how much money consumers have to spend might greatly impact who buys your product. So using an economic feature like consumer sentiment can help a model adjust it’s predictions based on changes in consumer spending habits.</p>
<p>We can add features into our data in two ways. The first is to just give historical values of that feature. This will force us to only use historical lags of the feature when training a ML model, since we don’t know what the future value of that feature will be. We can take that original feature and create new features (this is called feature engineering). Ones that are a 3 month lag, 6 month lag, or 12 month lag of the original data. Often macro data like consumer sentiment can be a lagging indicator. Meaning their impact is delayed and takes a while to flow through the economy. Changes in consumer sentiment from 6 months ago can actually have a strong correlation with how customers purchase our product today.</p>
<p>A second way is to use both historical values and future values. We could use a future forecast of consumer sentiment in our model, in addition to using the historical data. That way a model can learn from any lagged relationships as well as understand how changes in consumer sentiment impact our product in real time. These future values can either come from an expert forecast (like from famous economists) or created by your own ML solution.</p>
</section>
<section id="the-future-must-always-learn-from-the-past" class="level3">
<h3 class="anchored" data-anchor-id="the-future-must-always-learn-from-the-past">The Future Must Always Learn From The Past</h3>
<p>You might have a ton of ideas for new kinds of future information your can encode as features to train a model. In order to use this data we need to make sure there are historical examples for a model to learn from. The upcoming 2024 presidential election in the US could have a large impact on your business, which will impact your future forecast for the rest of 2024. We know exactly when the election is going to happen, so it’s easy to give that information into a ML model to learn from.</p>
<p>The catch is we need to make sure that we show examples from the past to allow the model to learn how previous elections impact our business and how the model should handle similar events in the future. If we only have product sales data from the last three years, then we cannot feed it future election data because we don’t have the data from the 2020 or 2016 US presidential elections.</p>
<p>If we know something is going to happen in the future, but we can’t quantify it with historical data for a model, then we need to go old school. Instead we need to use our domain expertise about the business to take the ML output, without knowledge of the future event, and make a manual adjustment to the forecast based on the expected impact of the future. For the election example, maybe your product sales will grow as we get closer to the election, so if you don’t have enough historical data for a model to learn about the election’s impact you can make a manual adjustment to the ML forecast based on your assumption about the election’s impact.</p>
<p>This kind of hybrid approach, ML first with a light human touch second, can create a powerful combination. A ML model can do 80-90% of the initial work and a human can make the final manual adjustments based on their domain expertise. This allows a human to add more insight into a forecast that is not easily quantifiable for a ML model to learn from.</p>
</section>
<section id="new-time-series" class="level3">
<h3 class="anchored" data-anchor-id="new-time-series">New Time Series</h3>
<p>A new product at your company might be exciting, but is harder to forecast accurately with ML models. The lack of historical data will make it hard for any new ML model to learn from. Initial trends and seasonality may not always carry into the future. For example there might be a big spike in initial sales around release but then taper off over time. The new product may not even be on sale yet, so you are now tasked with forecasting something with zero historical data.</p>
<p>If the time series in question has some historical data, ideally more than one year of historical observations, a good way to deal with it is to train a ML model with the new time series alongside similar existing products with a lot of historical data. This is sometimes called a “global model”, where a model learns from multiple time series instead of one. Training on one specific time series is sometimes called a “local model”. Training a global model allows the ML model to learn general trends and seasonality patters across similar time series and apply it to the newer time series. This can work well if the other time series are similar to one another.</p>
<p>If the product you want to forecast has no historical data, then you are in a tough boat. Traditional time series methods cannot help you, since they all rely on quality historical data. What you can do is take a more traditional machine learning regression approach. This involves taking all historical products that have launched over time and training a model to understand the initial demand of a new product and how it either grows or shrinks over time. For example with iPhone sales, you can train a model on the initial sales of each iPhone model from V1 to V14, then use that model to predict the kind of demand the latest V15 iPhone might have. This type of approach would need a more detailed post to explain fully, but hopefully you get the broader picture.</p>
<p>To learn more about forecasting new time series, check out the <a href="https://otexts.com/fpp3/judgmental.html">forecasting bible</a> written by our forecasting godfather Rob Hyndman. The chapter on judgemental forecasts goes deep into forecasting new products and discusses other approaches you can take.</p>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>When using future values of a feature, there is a risk of compounding errors. Let’s go back to the consumer sentiment example. If you create your own expectation of future consumer sentiment, or use an economist’s prediction, there is a good chance the forecast will be wrong. If the forecast about consumer sentiment is wrong, and that forecast is fed into a model to predict your product’s sales, then your sales forecast will be even more wrong. The errors compound. Add in other features and you can see how the house of cards can tumble pretty fast. Always be weary about using future values of features where you don’t have 100% confidence in their future value. For example using future holiday features are great because they will always happen on a specific day with 100% certainty, but trying to tell a model where inflation is headed in the future can get you in trouble.</p>
<p>Having a human make manual adjustments after the initial ML forecast can add unneeded human bias to the final forecast. This bias can sometimes be wrong and hurt the accuracy of the forecast. It’s good practice to capture these adjustments and always report on the forecast accuracy of the pure ML model and the accuracy for the model + human adjustments. That way you can track how helpful the manual adjustments are, and remember why they were made in the first place.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>When embarking on the journey of time series forecasting, remember it’s more art than exact science—akin to predicting rain in Seattle. The key takeaway? Use the past as a guide but sprinkle in educated guesses about the future with caution. Whether you’re launching new products or navigating established markets, blending machine learning with a dash of human intuition can create robust forecasts. May your forecasts be as reliable as the sunrise, with just enough flexibility to handle an unexpected downpour.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-04-11-time-series-past-future/index.html</guid>
  <pubDate>Thu, 11 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: Garbage In, Garbage Out</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-08-time-series-garbage/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the second principle of a good time series forecast, garbage in garbage out. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> in this series to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/">Domain Expertise</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/"><strong>Garbage In Garbage Out</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="youre-not-a-wizard-harry" class="level3">
<h3 class="anchored" data-anchor-id="youre-not-a-wizard-harry">You’re Not a Wizard, Harry</h3>
<p>A common I see people in finance make when trying to use machine learning (ML) is around approaching it like a magic wand. Thinking as long as they bring in some data and throw it over the fence to a ML process, a perfect forecast will come back to them. All shiny and clean. ML should be able to find all of the patterns in the data and do things we humans can’t fathom right? No, wrong. ML is not a cure all thing. Having a good ML forecast starts with having quality historical data for a model to learn from. Without good data, you won’t get a good forecast. It’s as simple as that. Let’s dive into ways data can be stinky and how we can sanitize it before training models. To help illustrate each point we’ll use an example of a monthly sales forecast.</p>
</section>
<section id="amount-of-historical-data" class="level3">
<h3 class="anchored" data-anchor-id="amount-of-historical-data">Amount of Historical Data</h3>
<p>Ideally you want to get as much historical data as possible. If we want to forecast the next quarter of sales, it’s a bad idea to only use the last 12 months of historical data to train a model. Usually I try to get 5+ years of historical data before training any model. This allows for enough year over year observations for a model to learn from. For monthly forecasts, I won’t even start a forecast project if there is less than 3 years of historical data.</p>
<p>Having sufficient historical data creates the opportunity to have sufficient model back testing. Where we can see how models performed over the last few months of the data. We can then use that back testing accuracy as a proxy for what to expect for the future forecast. The less historical data you have, the less you can back test.</p>
<p>The more data you have, the longer you can forecast into the future. If I only have 3 years of historical data, it’s a bad idea to try and forecast the next 2 years. A good heuristic is to cap your forecast horizon (periods you want to forecast out) to less than 50% of the historical data. So if you want to forecast out the next 3 years of monthly sales, you need at least 6 years of historical data. When in doubt always get more data.</p>
<p>What if I have tons of historical monthly sales data, but a cool new feature I want to use around sales pipeline is only available for the last 2 years? Most of the time, stick with using more historical data even if it’s at the expense of using highly correlated features but less historical data. Feel free to try both approaches, but often the one with the most historical data wins.</p>
</section>
<section id="trend-and-seasonality" class="level3">
<h3 class="anchored" data-anchor-id="trend-and-seasonality">Trend and Seasonality</h3>
<p>Most time series can be broken into three pieces. First is trend, is your data going up or down over time. Second is seasonality, are there peaks and valleys in your data that happen at the same time each year. Finally is the “error” or “residual” component, which is anything left over after accounting for trend and seasonality. Think of it as noise in your data. This approach of breaking down a time series into separate pieces is called time series decomposition.</p>
<p>Having recurring trends and seasonality in your historical data make things 100% easier to forecast in the future. If your data has trends that change month to month and seasonal patterns that evolve over time, your data is basically all noise. A noisy dataset is a bad dataset, one that can’t be modelled effectively by any ML model. Take a look at the below time series, each broken out by trend, seasonality, and residual. Now tell me which one would be easier to train a model on? Which would produce a high quality future forecast?</p>
<p><img src="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/chart1.png" class="img-fluid"></p>
<p>You can deal with noisy data like this in a few ways. The first is to just change the grain of the data. For example, if this was forecasting a specific product SKU, maybe instead sum it up to a higher level like product category. That way more stable trends and seasonality might appear. You can also try to add features (variables to your training data) to try to teach a model why the seasonality and trends in the data are messy. For example the main COVID years from 2020-2022 really throw a wrench in any trends or seasonal patterns in most data sets. So adding information to a data set that tells a model that there was a special one-off situation for specific periods can help a model learn the right kinds of relationships in the data and generalize well to new unseen data going forward.</p>
</section>
<section id="missing-data" class="level3">
<h3 class="anchored" data-anchor-id="missing-data">Missing Data</h3>
<p>Missing data is the silent killer in forecasting. If you don’t specifically look for it you might never know it’s the reason your forecasts perform poorly. Missing data is important because many models (either statistical models or ML models) often need all sequential date observations of the historical data to train a model. Even one period of missing data can throw off an entire model and lead to poor performance.</p>
<p>Often times financial systems will not have tons of missing data. It’s important to know if the data that is missing should mean treated as actually missing or seen as a true zero value. For example, if we have product sales missing for a specific month, should we classify that value as truly missing or just hardcode that value to zero? Make sure you clarify that with whoever owns the data.</p>
<p>If the missing should be zero then that’s a quick fix, but if it’s truly missing then you now have another problem on your hands around what to do. Simply replacing the missing value with zero can throw off any trend or seasonality patters like we discussed earlier. Common ML advice is to replace missing feature data with the median or mean value of that feature, but this is terrible advice for time series forecasting. Usually the best approach is to use some sort of simple statistical model that can understand the trends and patterns of data around the missing value and impute what the value should be. This will keep existing trends and seasonality patterns in the data, meaning your future forecast will be more robust.</p>
</section>
<section id="outliers" class="level3">
<h3 class="anchored" data-anchor-id="outliers">Outliers</h3>
<p>An outlier in time series forecasting is an atypical data point that significantly deviates from the overall pattern of the data. They can occur multiple times in a historical time series or just be a one off for a particular period. Either way, their presence can greatly impact how a model learns from the data.</p>
<p>Outlier detection in time series forecasting often involves statistical methods, anomaly detection algorithms, or visual inspection to identify data points that significantly deviate from the typical patterns of the series. Techniques include setting thresholds based on standard deviations, using moving averages to smooth the series and highlight anomalies, applying machine learning models like isolation forests, or utilizing robust decomposition methods (like STL) to separate the series into components and identify outliers in the residuals.</p>
<p>Take a look at the chart below. See how just one large value towards the end of the time series completely changes the trend and seasonality. A model might take this data and produce a huge forecast going forward, since the trend changed drastically based on the outlier. It might also have a huge spike for that specific period next year, since it learned that seasonality recently changed.</p>
<p><img src="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/chart2.png" class="img-fluid"></p>
<p>There are a few ways we can handle the presence of outliers. First we can leave it alone, and let it’s presence impact our future forecast. Maybe after talking with the business domain expert they say that there is a foundational change in the business (new product launch, tax change) that means we expect to see similar values in the future. Second we can add some more information to our data to explain what happened in that period and if we expect it to happen again in the future. If the outlier was caused by a new product launch, we can label that as a feature in the data and also tell the model if we expect any product launches in the future. A model will then learn of these one off patterns and adjust the forecast as needed. The final method is to remove the outlier altogether. Once removed, we can treat it like a missing value and replace it with a value more in line with recent trends and seasonality. If it’s truly a one off thing that will never happen again then removing it is sometimes the best approach. The choice you make always depends on the context of what caused the outlier and how we expect similar things to happen going forward.</p>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>Sometimes having more historical data is a bad thing, and can hurt model performance. For example having 30 years of historical data could produce a good forecast, but do the trends and patterns of the business 20 years ago still apply to the business today? Often in fast changing industries this is not the case, so sometimes deliberately shortening your data is the right idea. Five years from now we may want to exclude data from pre-2023 to remove all impacts of COVID. How your customers purchased your services in 2019 is most likely very different than how they will buy them in 2024. Gee, thanks COVID.</p>
</section>
<section id="automatic-data-cleaning-with-finnts" class="level3">
<h3 class="anchored" data-anchor-id="automatic-data-cleaning-with-finnts">Automatic Data Cleaning with finnts</h3>
<p>Thankfully there is a solution to most of these problems. My package, <a href="https://microsoft.github.io/finnts/index.html">finnts</a>, helps solve a lot of the data sanitizing needed to produce a high quality forecast. It can handle outliers and missing values automatically for you. It abstracts away all of these hard topics and makes it easy to get up and running with a forecast in one line of code. Check it out.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Messy data will always lead to a messy forecast. ML models can’t save you from bad data. There’s no magic wand to cure common data problems. What you can do though is make sure your data has solid historical trends/seasonality, no missing data, and good approach to handling outliers. With these taken care of, you’re own your way to building a high quality forecast.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-04-08-time-series-garbage/index.html</guid>
  <pubDate>Mon, 08 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (4/5/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-05-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-05-weekend-reads/image.png" class="img-fluid"></p>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://youtu.be/_Y-7liNT1Ok?si=VDIlw5FTQXCu2kYm">Improving Focus</a></li>
<li><a href="https://youtu.be/ha1ZbJIW1f8?si=2D0Gp15NkD9iup01">Dopamine and Motivation</a></li>
<li><a href="https://youtu.be/gR_f-iwUGY4?si=JHewqUkP7dautU1v">Optimal Morning Routine</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLOhHNjZItNnOoPxOF3dmq30UxYqFuxXKn">Sequoia AI Summit</a></li>
<li><a href="https://youtu.be/4t4YkHSTZbw?si=qqjiCcKg4_YmotoA">SBF, Gov Spending, and More on All In</a></li>
</ul>
</section>
<section id="podcasts" class="level2">
<h2 class="anchored" data-anchor-id="podcasts">Podcasts</h2>
<ul>
<li><a href="https://open.spotify.com/episode/4iqmP3Gys5AkyLpcXNU26N?si=zGiCV0c0Ts-8baaJ2j2k8g">Scott Glenn on Tim Ferriss</a></li>
<li><a href="https://open.spotify.com/episode/7ExrANvf3Rhha46GRX5W8X?si=ON6IJbN-QT-SDo6a7fOjMQ">Seth Godin on Tim Ferriss</a></li>
<li><a href="https://open.spotify.com/episode/4tnRkV3qL3GulapNmzirsy?si=3NYI2OFhSVWpFevtfxvK6Q">Dr.&nbsp;Rhonda Patrick on The Knowledge Project</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/gdb/status/1772334028009652415">Sora Goodness</a></li>
<li><a href="https://x.com/EMostaque/status/1772594194315436266">Satya Nadella Stays Undefeated</a></li>
<li><a href="https://x.com/thegarrettscott/status/1771645169151901952">Bezos Leadership Principles</a></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://ravinkumar.com/GenAiGuidebook/book_intro.html">GenAI Guidebook</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-04-05-weekend-reads/index.html</guid>
  <pubDate>Fri, 05 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-05-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time Series First Principles: Domain Expertise</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/image.png" class="img-fluid"></p>
<section id="time-series-first-principles-series" class="level3">
<h3 class="anchored" data-anchor-id="time-series-first-principles-series">Time Series First Principles Series</h3>
<p>This post dives into the first principle of a good time series forecast, domain expertise. Check out the <a href="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/">initial post</a> to get a high level view of each principle.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/"><strong>Domain Expertise</strong></a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/">Garbage In Garbage Out</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/">The Future Is Similar To The Past</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/">Higher Grain Higher Accuracy</a></li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/">Order Is Important</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/">The Magic Is In The Feature Engineering</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple Models Are Better Models</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/">Capture Uncertainty</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/">Model Combinations Are King</a></li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/">Deep Learning Last</a></li>
</ol>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>Any data scientist worth their salt can create a time series forecast for you. They can pull some data, train some machine learning (ML) models, and give you a forecast. All with you out of the loop. If that’s the case at your company, run! This is a big red flag. While that can sometimes yield good results, often the most important ingredient is missing, which is strong domain expertise about what you’re trying to forecast. This is where strong understanding of the business and market forces come into play. You know, the stuff that finance people excel at. Pairing robust ML models with strong domain expertise about the area being forecasted always yields the most accurate forecast. It also increases trust in that forecast, since the humans using that forecast know the model took into account important factors that influence the business. In this post we’ll use a hypothetical example of a company’s real estate spending to showcase the importance of domain expertise.</p>
</section>
<section id="translating-domain-expertise-into-features" class="level3">
<h3 class="anchored" data-anchor-id="translating-domain-expertise-into-features">Translating Domain Expertise Into Features</h3>
<p>How does domain expertise change how a ML model is created? This can manifest in many forms. The most common is changing the kind of data used in training a model. Variables that a model learns from are called “features”. Let’s apply this to our real estate spend forecast example. In the last few years, COVID and the work from home revolution have changed how people come into work. This changes how many people drink coffee, use the copier, and even which buildings stay in operation for a company. Simply pulling historical building expense data and training a model could get you ok results, but to get to peak performance you need domain expertise around what actually moves the needle for building expenses. Example features could be the square footage of a building, how many people actually badge into that building each month, even the periods where COVID was at its worse and a work from home mandate was in effect. All of these things are custom knowledge, most likely kept inside the heads of the finance workers who oversee the real estate space within a finance org.</p>
</section>
<section id="iteration-is-key" class="level3">
<h3 class="anchored" data-anchor-id="iteration-is-key">Iteration is Key</h3>
<p>Throwing all of your ideas as features into a model from the start is usually not a good idea. Instead having multiple rounds of iteration is key. In the real estate example, it’s best to start out with no external features. Just use historical spend to forecast future spend. Starting with this simpler approach can sometimes get you 90% of the accuracy you need, maybe even 100% if there are stable trends and seasonality that carries into the future. Run this first to see what the initial accuracy is, and if it doesn’t meet your requirements that when we can refine by adding new data.</p>
<p>Once you have the baseline, you can look deeper into the accuracy results to see where the forecast is performing poorly. This is where domain knowledge kicks in. Poor initial forecast performance can be fixed by asking the domain expert if there is a difference between what the model knows and what a human knows. If there is a gap, can that be quantified as data to teach a model? This kind of insight can be added into a model with easy to find numeric data, or even as binary yes or no values (1 or 0) to denote when a specific one off event happened. This iterative process is where the magic happens.</p>
<p>For the real estate forecast, maybe there was a period where expenses jumped sharply in one month and stayed at that new level for the rest of the year. This will be hard for a ML model to understand or even anticipate, but the domain expert of the real estate space knows that in that specific month there were two new building openings. So the expenses of course jumped up a significant degree and stayed like that going forward. Knowing this, we can get historical square footage information and add it into our model. We can even incorporate future buildings that might be removed or added going forward. This will help a model understand how changes in total buildings impact spend.</p>
<p>So we added total square footage to our model and the results improved compared to our initial baseline of no external features. But it didn’t move the needle that much. Even though our company might be adding more buildings, in recent years the spend may not have a perfect correlation with added square footage. Knowing this, the domain expert recommends using anonymous badge in data to see who is actually coming into work. Pre-covid this data may not have been useful, since most buildings were always at max capacity with everyone coming to work each day. Now in a post-covid world this has changed forever. Some teams might only be in their assigned building 2-3 days a week. Or maybe they never returned in person, deciding instead to buy ranches in Wyoming with fast WiFi. Combining the square footage and badge in data into the model yielded fantastic results, much better than the initial baseline.</p>
<p>After reviewing the improved results with the domain expert, the future forecast still seems a little low compared to the domain experts expectations. The domain expert has one last idea, trying to teach the model how COVID impacted spending. This can be quantified as a binary variable, where in all rows of the data we add a 1 if COVID was impacting the world, and 0 when it wasn’t. This means from early 2020 - early 2022 we have values of 1 and every period before and after we give a value of 0. A model can now understand that what happened over those two years was mostly a one off situation that is not expected going forward. After the ML model is trained with this new insight the back testing now looks great and the future forecast matches the expectations of the domain expert.</p>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>Getting high quality data to use as features in a model is always a good idea. There are times though where the amount of historical feature data might be lacking. For example, we may not be able to get more than 3 years of historical square footage data for our real estate expense forecast, even though we can get 5 years of historical spend data. What should we do? We can shorten the historical spend data to the last 3 years to match the square footage data, but having less data can sometimes degrade model performance. So in some cases choosing to use the full 5 years of historical spend without the square footage data is the best approach that yields the best accuracy.</p>
<p>When facing this dilemma, try both approaches and see how accuracy is effected. I’ve seen many times that using more historical data of what you’re trying to forecast is often more accurate than shortening that data to combine it with external features.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Starting any ML process without a business domain expert in the room is always a bad mistake. They are the cheat code in the video game that gets you to level 20 in half the time. Involving them early and often while also adopting a quick iteration approach can create a world class forecast that is trusted by the ultimate end users, which often are the domain experts themselves. At the end of the day most ML forecasts come down to trust by the end user. That’s why domain expertise is the first principle in building quality time series forecasts.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/index.html</guid>
  <pubDate>Tue, 02 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Thoughts on First Principles in Time Series Forecasting</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/image.png" class="img-fluid"></p>
<p>I’ve been doing time series forecasting with machine learning (ML) most of my career. I believe it’s still the best AI opportunity in corporate finance, even with all of the latest Generative AI developments in recent years. If you work for the CFO, chances are you often create predictions about the future. Those predictions take time and can always be more accurate. Machine learning can help in both areas. Before you build machine learning solutions in your finance org, it’s important to understand the true building blocks of making good forecasts.</p>
<p>In this post I will overview each first principle, and have follow-up posts digging deeper into each one. Let’s dive in.</p>
<ol type="1">
<li><a href="https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/"><strong>Domain Expertise</strong></a>: Knowing what factors actually influence what you are trying to forecast is more important than which ML model to train.</li>
<li><a href="https://mftokic.github.io/posts/2024-04-08-time-series-garbage/"><strong>Garbage In Garbage Out</strong></a>: Training a model on bad data leads to bad forecasts.</li>
<li><a href="https://mftokic.github.io/posts/2024-04-11-time-series-past-future/"><strong>The Future Is Similar To The Past</strong></a>: If you expect the future to be drastically different than past data, you will have a hard time training accurate models.<br>
</li>
<li><a href="https://mftokic.github.io/posts/2024-04-18-time-series-grain/"><strong>Higher Grain Higher Accuracy</strong></a>: Forecasting by country is often more accurate than forecasting by city. Forecasting by month is often more accurate than forecasting by day.</li>
<li><a href="https://mftokic.github.io/posts/2024-04-23-time-series-order/"><strong>Order Is Important</strong></a>: When time is involved, how your data is ordered makes all the difference.</li>
<li><a href="https://mftokic.github.io/posts/2024-05-01-time-series-features/"><strong>The Magic Is In The Feature Engineering</strong></a>: How you transform your data before model training can transform a mediocre forecast into a world class forecast.</li>
<li><a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/"><strong>Simple Models Are Better Models</strong></a>: Like occam’s razor, the best model is often the one with the least amount of inputs.</li>
<li><a href="https://mftokic.github.io/posts/2024-05-07-time-series-capture-uncertainty/"><strong>Capture Uncertainty</strong></a>: Showing the back testing results and future uncertainty of a model’s forecast builds more trust.</li>
<li><a href="https://mftokic.github.io/posts/2024-05-28-time-series-model-avg/"><strong>Model Combinations Are King</strong></a>: Usually a combination of multiple models is more accurate than just one model’s prediction.</li>
<li><a href="https://mftokic.github.io/posts/2024-05-31-time-series-deep-learning/"><strong>Deep Learning Last</strong></a>: Deep learning isn’t as effective as more traditional ML models.</li>
</ol>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>This is not an exhaustive list, but instead principles that I find particularly important when creating a time series forecast. Having a firm understanding of these principles is enough to get the ball rolling on any type of forecast you’re working on. Thankfully, the very same approach I use in my job to do forecasting is open source and freely available through my R forecasting package called <a href="https://microsoft.github.io/finnts/index.html">finnts</a>. Even if you’ve never done data science or used R before, finnts makes it easy to get off the ground fast without shooting yourself in the foot when dealing with the above principles. Stay tuned for more posts about each principle.</p>


</section>

 ]]></description>
  <category>time-series</category>
  <category>machine-learning</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/index.html</guid>
  <pubDate>Tue, 26 Mar 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (3/22/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-03-22-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-03-22-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://world.hey.com/dhh/developers-are-on-edge-4dfcf9c1">DHH On Coding AI Agents</a></li>
<li><a href="https://collabfund.com/blog/the-thin-line/">When Confidence Backfires</a></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://youtu.be/NdxFctWShtc?si=pFzzxt7EctaREoZY">Sahil Bloom on Building Life Systems</a></li>
<li><a href="https://youtu.be/jvqFAi7vkBc?si=v654_j6USVkIUGNx">Sam Altman on Lex Friedman</a></li>
<li><a href="https://youtu.be/lXLBTBBil2U?si=yEU-YxYkgusDFkEd">Jensen Huang at Stanford GSB</a></li>
<li><a href="https://youtu.be/uMajFsCkzxY?si=fwzKDf-jfCK-ZyKT">TikTok Ban, AI, and more on All In</a></li>
</ul>
</section>
<section id="podcasts" class="level2">
<h2 class="anchored" data-anchor-id="podcasts">Podcasts</h2>
<ul>
<li><a href="https://open.spotify.com/episode/11oI0JELKOohCSEwz8WOQD?si=1648IhapTUOdkaanwRM4Ug">Morgan Housel on Modern Wisdom</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/BallsackSports/status/1770999544911626266?s=20">Grateful that Kansas won their first round game</a></li>
<li><a href="https://x.com/george__mack/status/1769376253524496607?s=20">How Momentum Rules Your Life</a></li>
<li><a href="https://x.com/Feynmanism_/status/1753767517762596903?s=20">Cognitive Biases</a></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://www.amazon.com/Numbers-Game-Everything-About-Soccer-ebook/dp/B00BPDR3E2/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.rmUGJqVG-UDO-EJgjWaUjPm0ug1og2SXZQ8GiC45XXxuQBtP7Zt81fkEWNptjyu6-K4Lk6Dq4pKN867arj5xDiLron2Zl7KN5-fjRRh1w15sNA0UvwnPtIKnfWqyQEGEd475FjsPSiNH_CVWG5956NWPyp4f2j9I5mYgWmxLceICvMI-j9WKDdR5Xn9MwPaRwzIg0N5GNI9U_r2gIstQ0RlZhNonJR2TyxycZexvtKY.7_sZ4hdeMz5-fU0BCzqT3rFyOo0klmjutMl3rZ_qpn4&amp;qid=1711121115&amp;sr=8-4">The Numbers Game by Chris Anderson</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-03-22-weekend-reads/index.html</guid>
  <pubDate>Fri, 22 Mar 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-03-22-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (3/16/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-03-16-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-03-16-weekend-reads/image.png" class="img-fluid"></p>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=-gfEjOgxBfI">The Algebra of Happiness</a></li>
</ul>
</section>
<section id="podcasts" class="level2">
<h2 class="anchored" data-anchor-id="podcasts">Podcasts</h2>
<ul>
<li><a href="https://open.spotify.com/episode/6fJYHF4NOQZvoCpaCFt7lX?si=GkalASEQRzq22cxs77TYNw">Chris Davis On The Knowledge Project</a></li>
<li><a href="https://open.spotify.com/episode/7LQzv0OKaE6KWEPPXPWuv7?si=CA0dzU35Q96xKYkIQipI0g">Kimbal Musk On Lex Friedman</a></li>
<li><a href="https://open.spotify.com/episode/5TAmY56aFV2J6Byn0qg94H?si=G2jTl8QFR4-P40FxjXd9jw">Dr.&nbsp;Cal Newport On Huberman Lab</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://twitter.com/heyitswindy/status/1764023423485812995?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">Excellent Product Placement</a></li>
<li><a href="https://twitter.com/cognition_labs/status/1767548763134964000?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">Meet Devin, Your AI Dev Intern</a></li>
<li><a href="https://twitter.com/spacex/status/1768267464062943676?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">SpaceX Launch</a></li>
<li><a href="https://twitter.com/neilpatel/status/1768645880784314626?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">ChatGPT Writing Prompt</a></li>
<li><a href="https://twitter.com/thekriskay/status/1768665799638553068?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">Invest For The Long Haul</a></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://www.amazon.com/Great-Mental-Models-Thinking-Concepts-ebook/dp/B07P79P8ST/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.nqDtFB0egHNRqbrwj7r9Q_VC72or3xvMfmy7E8Mp0Jf450tLXd7icWtUFMWvgbxO9dAyqa7WCJgjoHxY_gFVtNrfRN0jweiog60OU-ohIGe6cOiS0lNSskb-ZSLy3T-YZr62UAI1EL6NaBwfeB68kg4YW61sMl7qJdAYRlVMFg5ymByXAbbwp11EadBruMWEyWfCnPSoVU1CNUpFRnr4WUj_3IAu4Uv2sihpLbmPf1Q.wzJzOHHNv35HioL8ZTZcL1y-Tl7sbyX4KoL6E-Vge04&amp;qid=1710597095&amp;sr=8-1">The Great Mental Models Volume 1 by Shane Parrish</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-03-16-weekend-reads/index.html</guid>
  <pubDate>Sat, 16 Mar 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-03-16-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Thoughts on Power</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-03-13-power-pursuits/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-03-13-power-pursuits/image.png" class="img-fluid"></p>
<p>A few years ago I was at dinner with a few friends. Out of the blue one of them asked me “what is the meaning of life?”. Without thinking I blurted out “love”. Thinking that in the end, everything comes down to love. It sounded cheesy and cliche coming out of my mouth. Over the years though, I continued to ponder the question and now think more than ever that it’s the right answer.</p>
<p>What most people want in life can mostly be boiled down to the pursuit and gaining of power. Some types of power are good for you, but the most common ones always leave you unfulfilled. You know what does fulfil you though? Love. It fills you up better than power ever could. Let’s review how most things we chase in life are just hidden forms of power.</p>
<section id="types-of-unfulfilling-power" class="level3">
<h3 class="anchored" data-anchor-id="types-of-unfulfilling-power">Types of Unfulfilling Power</h3>
<p>Starting with unfulfilling power. These are things that can be attained in ok ways, but doing them just for the pursuit of having it is a good way to waste your life.</p>
<ol type="1">
<li><strong>Money</strong>: The most popular form of power and game we play in society. Granted you want to get to a certain level of money to have a good life, but after that the more money you have the less fulfilled it makes you. Mo money, mo problems.</li>
<li><strong>Status</strong>: This is power over how people in society look at you. There are many ways to get status. Going to an elite college or working at a prestigious job are ways to gain status. You also gain status around how you spend your money. Living in a fancy house in a fancy neighborhood punches a ticket to a different level of status than someone living in a trailer park. It’s easy for people to see what you own, and most people own certain things to convey status. Does a Rolex tell more accurate time than your phone? No but it shows that you are the type of person who can spend $10,000 minimum on an accessory you don’t really need. Increases in status normally feed your ego, which is not good for anyone.</li>
<li><strong>Beauty</strong>: Having power over other’s attention and sexual desires. This is a weird one because it can either be gained naturally (just being born) or through external means (botox, plastic surgery). If you hit the genetic lottery, congrats, but the external route is a slippery slope that usually doesn’t end well.</li>
<li><strong>Fame</strong>: Having power over people’s attention. Will Smith says the process of becoming famous is fun, but maintaining fame is just ok, and losing fame is hell. You don’t know how important having a private life is until you become a famous person. Can Will Smith casually go to a local park with his family on a Sunday? Nope. His life is forever inconvenienced by his fame. How much would he pay to have a quiet afternoon on a park bench with no interruptions? It might be more than you think.</li>
<li><strong>Legacy</strong>: Having power after you’re dead. How many people donate tens of millions to a university anonymously? Almost none. Most donate and in return get their name on a building. Maybe they’re stewards of higher education but maybe they just want their name to be remembered after they’re dead. Who cares if people remember your name 100 years from now, you will be dead. I repeat, you will be dead. Has your grandpa ever talked to you about his grandpa while growing up? Probably not. People are forgotten and that’s ok.</li>
<li><strong>Leadership Roles</strong>: Having power over people’s careers. Most people think the further they progress in their careers, the more likely they will end up managing a large team or company. While that’s true for a lot of jobs, it may not be everything you expected. Maybe instead of the management promotion you actually just wanted to work on higher impact projects and have more autonomy over how you get your work done. Think about a band like the Rolling Stones. They are very good at their job, but it’s not like after their second album their record label said “you have been doing such a good job that we think you should be promoted and start overlooking other bands”. That would be crazy. Instead they were given every opportunity to write more songs and perform to bigger audiences. I think knowledge work will move more towards that in the future. Corporate rock-stars will forgo the management path and truly become the best in the world at something. With scalable technology the best person in the world at a task can literally do it for everyone else in the world.</li>
</ol>
</section>
<section id="types-of-fulfilling-power" class="level3">
<h3 class="anchored" data-anchor-id="types-of-fulfilling-power">Types of Fulfilling Power</h3>
<p>I’m not saying that we should all shave our head, sell our possessions, and live as a monk. It’s ok to do things in life that increase your power, but I recommend trying to increase types of power that can actually fulfill you instead of leaving you wanting more. There are types of power that compound as you continue to increase them. These are true super powers that should be prioritized in life. Here are the types of power worth pursuing.</p>
<ol type="1">
<li><strong>Freedom</strong>: Having power over how you spend your time. Why does America rock? People will say the freedom they have, which is another way to say they can truly do whatever they want. Having control over your time is the best power you can have.</li>
<li><strong>Health</strong>: Having power over your own body. You might have a million thoughts and worries bounce around your head in a typical day, but when you’re sick or injured you only think about one thing. Improve your sleep, diet, and exercise and see if your life doesn’t improve by an order of magnitude.</li>
<li><strong>Learning</strong>: How does that old saying go again? Oh yeah, knowledge is power. Some would argue it’s potential power, waiting to be applied. Noticed I listed this as learning and not knowledge. Having knowledge is great but there is never a reason to stop acquiring knowledge throughout life. This power compounds as you learn more. Lean into the eighth wonder of the world and keep learning.</li>
<li><strong>Reputation</strong>: Having power over other’s perceptions of your character. Warren Buffet can do billion dollar deals over the phone, no contract needed, because of his stellar reputation he built over a lifetime. A good reputation can increase your luck surface area in life. A good reputation takes time to build, but can be gone in an instant.<br>
</li>
<li><strong>Relationships</strong>: Having power over other people’s time. Loving friends, an amazing spouse, and children running around your house are some of the most rewarding things in life. Not having strong relationships is literally the equivalent to smoking when it comes to lifespan. I would choose these relationships wisely though. Once when I was in college my business class went to visit a local bank in Kansas City. The bank’s founder, a hunched over man in his 80s, came out to speak to us students. When asked for advice for living a good life, his response was simple. He said, “be around good people”. The older I get the more this advice makes more sense. You truly are the average of the five people you hang out with most. Choose wisely.</li>
</ol>
</section>
<section id="love-over-power" class="level3">
<h3 class="anchored" data-anchor-id="love-over-power">Love Over Power</h3>
<p>Love what you do, love who you spend your time with, and most importantly love yourself. The most important things in life boil down to love. Truly a first principle when it comes to living a good life. Call me a hippie but it’s the truth. Stay away from the most popular desires in life that ultimately are unfulfilling power, double down on power that does fulfill you, and most importantly optimize for more love in your life.</p>


</section>

 ]]></description>
  <category>life</category>
  <guid>https://mftokic.github.io/posts/2024-03-13-power-pursuits/index.html</guid>
  <pubDate>Wed, 13 Mar 2024 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-03-13-power-pursuits/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (2/23/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-02-23-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-02-23-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://openai.com/sora">Sora by OpenAI</a></li>
<li><a href="https://forum.openai.com/">OpenAI Forum</a></li>
<li><a href="https://bensbites.beehiiv.com/p/ignitetech-using-ai-change-business">Company Fires Employees Who Don’t Embrace New AI Tools</a></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=CX7Ng70IEwc">Aswath Damodaran on Prof G Markets</a></li>
<li><a href="https://www.youtube.com/watch?v=-vZXgApsPCQ">What I Learned From 100 Days of Rejection</a></li>
<li><a href="https://www.youtube.com/watch?v=XieCU9nzrl8">Charlie Houpert on Modern Wisdom</a></li>
</ul>
</section>
<section id="podcasts" class="level2">
<h2 class="anchored" data-anchor-id="podcasts">Podcasts</h2>
<ul>
<li><a href="https://open.spotify.com/episode/7iLniD7dXRCJVzvP8IPCtf?si=4MXVdJFkS52MttJH3s-49Q">Chris Williamson on Joe Rogan</a></li>
<li><a href="https://open.spotify.com/episode/3hSnWfuMS4TMsd1p7BTYyi?si=D7TerLvXSEK5MiFsqPfF5w">Latest AI Developments on All In</a></li>
<li><a href="https://open.spotify.com/episode/2b3r0hLbXz8oxCTB7lZN6X?si=FkTHisA2QoiG6Bx6Ka9ACw">Morgan Housel on Modern Wisdom</a></li>
</ul>
</section>
<section id="songs" class="level2">
<h2 class="anchored" data-anchor-id="songs">Songs</h2>
<ul>
<li><a href="https://open.spotify.com/track/52SCT6ImFklqEhH21lgErO?si=7b5b89bd51d7408d">Sweet City Woman by Stampeders</a></li>
</ul>
</section>
<section id="series" class="level2">
<h2 class="anchored" data-anchor-id="series">Series</h2>
<ul>
<li>Unbreakable Kimmy Schmidt on Netflix</li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-02-23-weekend-reads/index.html</guid>
  <pubDate>Fri, 23 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-02-23-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Thoughts on My Journey in Microsoft’s Finance Rotation Program</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-02-19-frp-journey/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-02-19-frp-journey/image.png" class="img-fluid"></p>
<p>On new years day of 2015, I got an email from a Microsoft recruiter to schedule a phone screen for Microsoft’s Finance Rotation Program (FRP). A week after the phone screen, I was reading the book <a href="https://www.amazon.com/Alchemist-Paulo-Coelho-ebook/dp/B00U6SFUSS/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.oUSaMmdTbyPBivuJLFm4Q1-NYaczN5ba008GOHDhQ9MOWgetjqBf7mHJx-PV4E6-kGeu5vWE_iQluiP7ZWLeFr1BIb5kFE3AaWUllmpUW-i1TbGQz95SeAAXu8D3mJs6t5MRYogHfFbhJ-tXXH-oIdjEK_veG5yAXDhFY2tOH4bRHh3hBoqlkL8qoLDFMJnESLJYbLoXadTMspNTNsDk-zbD2P3t-k7haUW7HWzd-BQ.TRSe7jlfvSeKC_Zh01wIH6cYm_jC_bsYxD8nY4LD0OY&amp;qid=1708359556&amp;sr=8-1">The Alchemist</a> during a study break and started to think about my <a href="https://www.literarytraveler.com/articles/what-is-your-personal-legend/#:~:text=Your%20Personal%20Legend%20is%20what%20you%20have%20always,to%20see%20happen%20to%20them%20in%20their%20lives.">personal legend</a>. I thought Microsoft would be a good opportunity and hoped for another interview. That’s right when my phone rang, it was the recruiter informing me that I was about to be chosen for the final super day in February. The weekend before the big interview in Redmond, my brother got me tickets to see the Oklahoma City Thunder take on the LA Clippers, a present for my 21st birthday. I told him I couldn’t go, because I needed time to prepare for the biggest interview of my life. Laughing, he said I had nothing to worry about, I would get the job, and we can use this weekend to celebrate the new job. His confidence in me, and the uncanny coincidence with the Alchemist book, were the “omens I’d follow” into my own personal legend. Thankfully the interview went well, I got the offer, and the rest is history.</p>
<p>The Finance Rotation Program at Microsoft is a two year program where recent college graduates complete four rotations across various groups in finance, each lasting six months. It’s a great opportunity to learn about different parts of Microsoft’s business, while also being a world class “try it before you buy it” experience for finding your optimal career path. You get to find what your destined to do, and Microsoft gets a well rounded finance professional that is tuned to find the exact job they want long term. A true win-win.</p>
<p>I often get asked to talk about my experience from would be FRP’s still in school and existing FRP’s in the program. My career path in the FRP is nontraditional in nature, but is hopefully one anyone with enough high agency can do as well. I write this to those high agency folks. People who want to do interesting things in the world and help others. What follows is my path in the FRP and what I recommend for today’s FRP’s.</p>
<section id="rotations" class="level2">
<h2 class="anchored" data-anchor-id="rotations">Rotations</h2>
<section id="internship-venture-integration" class="level3">
<h3 class="anchored" data-anchor-id="internship-venture-integration">Internship: Venture Integration</h3>
<p>I came into the FRP as an intern in the summer of 2015, the same summer Microsoft launched Windows 10. It was a fun time to join finance at Microsoft. Satya Nadella was only installed as CEO a few years back, same as Amy Hood the CFO. The stock price was in the 40s and no one thought Microsoft was doing anything cool or exciting. Safe to say most students at my college had MacBooks instead of Surfaces.</p>
<p>The Venture Integration team was responsible for helping acquired companies integrate successfully into Microsoft. While Corporate Development teams work on closing the deal, the Venture Integration team does everything else. From doing due diligence on the companies financial statements, digging through the products source code, all the way to determining if the acquired CEO would move to Redmond. It was a cool space to be in. Code names were used for each deal, and the deal flow was strong. Often we started a new deal every two weeks.</p>
<p>My role on the team didn’t involve running deals, although I did get to help with modeling the integration costs for one deal. I was tasked with running the quarterly scorecard process. This involved a lot of cat herding. For each recently closed deal, I would track down metrics to see if we were on track for a successful integration into Microsoft. This was more project management and less about financial modeling or analysis. The cool part was on the last day of my internship I completed the scorecard powerpoint and personally sent it to the CFO for review, who would then share it with the board of directors. So, in a way, I got to work on something that Bill Gate’s got to see. Most likely it was buried in the appendix of the board materials but I know my guy Bill loves to read! So I’m sure he saw it and was blown away by my excellence. At least that’s what I tell myself.</p>
<p>The life changing moment for me happened towards the end of the summer. The tech team responsible for reviewing the code of acquired companies hosted a brown bag lunch session about a new service called “Azure Machine Learning Studio”. They demoed a drag and drop tool that could build a machine learning model to predict if an event was going to happen or not. With a few clicks of their mouse they had a working model up and running in a self-serve UI. Only a few lines of code were written, with most of the magic happening in predefined lego blocks they pieced together. My mind was blown. It seemed like a magic trick to me, and I had to figure out how they did it. In school I always loved building three statement financial models to value a companies stock price. The biggest assumption we had to make was around future revenue growth, and that number was always made up. You could say xyz company’s revenue will continue to grow 10% because of xyz reason, but in the end it was a guess. The fact that you could build a machine learning model to create a more accurate prediction of the future was astounding to me, and I had to learn more.</p>
<p>Within a week after that presentation, all of the FRP interns got to meet with the CFO. A lot of questions were asked. I’m not even sure who asked it but a question around AI was brought up. Amy said that AI and machine learning will become very important in finance one day, and it will be an important skill for everyone to know. There are few moments of pure clarity in a lifetime where everything comes together and makes perfect sense. This was one of those moments for me. I had to figure out this AI thing. I had absolutely no clue how to start. I was only a finance major with zero technical skills. What I lacked in hard skills I made up for with enthusiasm to go figure it out any way possible.</p>
<p>The internship ended and thankfully I got the return offer. I remember the head of the FRP looking at my manager during the final review meeting. She said, “should you tell him or should I tell him”. My heart dropped, I thought I messed up and wasn’t getting the offer. Thankfully that confusion was cleared up real fast and I had a return offer in my hand. How can I say no to an opportunity to come back to Microsoft? Within a week back at school I accepted the offer and had total peace of mind going into my final year of undergrad.</p>
</section>
<section id="first-rotation-windows-cogs" class="level3">
<h3 class="anchored" data-anchor-id="first-rotation-windows-cogs">First Rotation: Windows COGS</h3>
<p>My first rotation was a classic rhythm of business (ROB) rotation in the world of Windows, Microsoft’s oldest business. It was a great place to earn my sea legs in traditional FP&amp;A work. I was responsible for owning the royalty portfolio for “codec” payments. Basically there is special software needed to read/write disks that are inserted into an optical drive on a computer. That software comes from companies like Dolbe, and Microsoft had to pay them to license the software on Windows OS. Wow, that makes me sound old. Working on royalties for optical drives on computers. Safe to say no one even thinks about optical drives anymore.</p>
<p>It wasn’t the prettiest work, but it helped me learn the basics of closing the books each month and forecasting the future each quarter. I had to submit journal entries and make manual adjustments to our payments when needed. Once you got the hang of pulling the data and making journal entries, the work wasn’t all that hard. So most of my time toward the end of the rotation was spent trying to automate every single part of the ROB process. What was initially a complex refresh process handed to me at the start of my rotation was transformed into a simple click to refresh excel that did all of the heavy lifting for you. It was my pride and joy.</p>
<p>My manager gave me a powerful piece of feedback towards the end of the rotation. He said that I liked building things. Some people like to start things, others like to keep a process going or optimize it. I was someone who liked to build new things. That idea stuck with me. I eventually became the guy on the team who could build any complex workflow as a model in excel. For example building out the new forecast consolidation file that all team members could add their component forecasts into. While it was fun to build this kind of stuff, it wasn’t AI work. For that I had to continue on my data hero’s journey.</p>
</section>
<section id="second-rotation-worldwide-commercial-solutions-finance" class="level3">
<h3 class="anchored" data-anchor-id="second-rotation-worldwide-commercial-solutions-finance">Second Rotation: Worldwide Commercial Solutions Finance</h3>
<p>For my second rotation I wanted to leave the world of ROB behind and get my hands dirty with data. I went to a team that did two things. First was analytics around discounts and customer renewals across Microsoft’s commercial business, and the second was around supporting the financing of customer purchases. Back in the day a customer could finance a large software purchase so they didn’t have to pay for most of it up front. We would partner with a bank to finance the payment or even do the financing ourselves through our Treasury department.</p>
<p>This rotation was all around analytics, which was exactly what I needed. I was able to analyze patterns around the type of discounts we give to customers, and how those discounts compound as a customer continues to renew their software purchase contracts. Another big ticket analytics item was around tracking special azure financing deals. This was a key metric we reported directly to the CFO, so a lot of eye balls were on it. I was the guy to track down this data and create interesting ways to understand it.</p>
<p>Power BI was recently released. No one on the team knew how to use it, but understood how powerful it could be when visualizing data. So I became the Power BI guy on the team. The one to figure out how to use it, then teach it to everyone else. Thankfully the previous FRP started them on the Power BI journey by building some initial dashboards. My job was to improve those dashboards, then get everyone else up to speed on how they could build their own. It was a solid experience in the world of analytics. One where no one could show you how to solve certain problems. You were on your own and had to figure everything out yourself.</p>
<p>The analytics experience was great, but still no AI. While on the team I tried to find ways we could apply AI and machine learning to specific areas but couldn’t find a good opportunity. At this point I started to learn more on my own through books and courses on the internet. I was flying blind, with no one to guide me to ensure I was headed in the right direction. That’s when the power of serendipity came and altered the course of my FRP career.</p>
<p>Another FRP analyst in my class got her last pick on her list of ranked rotations. Like choice number 32 out of 32 options. Right before she started on her team for the second rotation, there was a large re-org and she was able to now chose wherever she’d like to go in the broader org. A true choose your own adventure. She had an information systems background and found a team that was just starting to get into the world of machine learning. I heard about this and knew exactly where I wanted to go for my third rotation.</p>
</section>
<section id="third-rotation-finance-business-intelligence-services" class="level3">
<h3 class="anchored" data-anchor-id="third-rotation-finance-business-intelligence-services">Third Rotation: Finance Business Intelligence Services</h3>
<p>Working for the FBI, what a fun thing to say. The FBI Services team was almost an in house consultancy team, who supported most folks in finance. If someone wanted a special dashboard, custom tool, or even machine learning model they could reach out to this team and get the help they needed. The team consisted mostly of program manager (PM) type roles for full time employees, and various technical roles for vendors.</p>
<p>Coming to this team was being at the right place at the right time. In the summer of 2015 (during my internship) our CFO reached out to the head of the cloud engineering team, asking him to help get some initial machine learning solutions off the ground. Eventually this work was transferred to the FBI Services team, who hired a team of data science vendors to keep the work going. Most of the ML solutions centered around time series forecasting, since that is easily the biggest bang for buck ML work in the corporate finance space. Almost everyone under the CFO is responsible for some sort of forecast, so the impact with ML is enormous.</p>
<p>I came on the team as a PM who would partner with the data science vendors to build ML solutions. It was a dream come true. Finally I had people I can talk to about ML. Pick their brain. See how they think about ML problems. I also found a data science certification offered through Microsoft (on the EdX learning platform). It had a full learning track for python, no coding experience required. Thankfully as a Microsoft employee I could take the courses for free. While on the team I was able to make the learning part of my job, and even devote part of each day to taking the courses. It was a dream come true.</p>
<p>The big project on the team was around creating a centralized tool for our finance teams in the field, teams who support sales and sit all around the world, to use for their quarterly forecast of the commercial business. We were tasked with building a tool that could combine machine learning methods with existing sales pipeline based methods (like taking what’s in the sales pipeline and multiplying it by how many deals we have closed on average historically). One tool that everyone in the field could use instead of building their own manual excel model that eats up weeks of their time every forecast cycle.</p>
<p>It was a fun project to work on. The stakes were high, and no one had done anything like it before. It wasn’t just a machine learning project, but also a centralization and automation project. A crazy ven diagram of categories of technology. Over the course of my six month rotation we (and I say that lightly since I was the rookie on this project) were able to go from initial concept to working plugin in excel that could automatically calculate the forecast for the user, allow them to select what forecast methods they’d like to use, make any manual adjustments, and save that data back to a data cube. A herculean effort that had a few late nights toward the end of the project. It was a fantastic learning experience, with so many different opportunities to learn in one project. How to work with technical and non-technical people. Getting the most from ML models, and knowing their limitations. The change management required to get to people to want to use the new tool and move away from what they’ve always done.</p>
<p>I was also able to knock out the entire Microsoft certification in data science. I could now write python code to analyze data, train models, and create predictions. Everything that astounded me as an intern was now in my tool kit. I had data super powers and it felt awesome. The only problem is I had no idea what came next. Towards the end of the rotation I wanted to stay on the team and graduate early. Unfortunately the previous FRP was able to secure a full time spot on the team before I asked. Now I was in a tough spot. Knowing what I wanted to do, but not knowing where to do it. Thankfully serendipity came to my rescue.</p>
<p>At a FRP manager round table, my manager noted to the group that I was looking for a home for my fourth and final rotation. I wanted to work on machine learning but had no clue what team to rank highly. Another manager spoke up, saying they were just starting to dip their toes in the ML space and could have me on the team. That chance encounter lead me to ranking that rotation as my number one pick. Other FRP’s thought I was crazy. Usually that rotation went to a first year FRP, often as someone’s first rotation. I saw it as an opportunity to work on a technical team and carve out a path to working full time on ML. Safe to say after I joined the team every FRP who has worked on the team since has been a second year analyst.</p>
</section>
<section id="fourth-rotation-officedynamicsbing-business-intelligence" class="level3">
<h3 class="anchored" data-anchor-id="fourth-rotation-officedynamicsbing-business-intelligence">Fourth Rotation: Office/Dynamics/Bing Business Intelligence</h3>
<p>My final rotation was a BI team that supported finance teams in the Office, Dynamics, and Bing product spaces. Previous FRP’s worked on an executive scorecard that would get sent to senior leaders. I had my fill of scorecards while an intern so I was relieved that they were changing the rotation to allow me to work on machine learning problems. I felt like the luckiest guy in the world. I could actually write code to build machine learning models and get paid for it, all without having a degree in the subject.</p>
<p>I worked on two main projects while on the team. One was around forecasting search traffic volume for our Bing business partners, and another was focused on trying to predict if a potential customer purchase in our sales pipeline was going to close or not. The search volume project was exciting because I could write code from scratch to create the forecasts. It was my first true ML project that I was responsible for coding. Building something from nothing, it was exhilarating. Just like my first rotation manager said.</p>
<p>The second project was a tough one. Being able to create a classification model to predict the likelihood of a deal in our customer sales pipeline closing was a tricky project. One where getting high quality historical data was tough to get. I knew this was something analytics teams in sales had to of tried to solve before, so I sent out the bat signal through a few distribution groups and got a hit. A data science team in India had done the exact work I needed and could send me the results of their models prediction. What should have taken months of work was now widdled down to a few weeks to pull the prediction data and display it in a Power BI. Leveraging the work of others proved a powerful lesson for me, and allowed me to finish my project that much faster.</p>
<p>My time on the team flew by and I was quickly approaching the end of my FRP tenure, meaning I needed to find a full time job ASAP. Most of my time quickly shifted to checking internal job boards and emailing managers in other BI teams, hoping they had a spot for me. I wanted this ML train to keep rolling. My current team said that they could potentially offer me a job, but I had to wait a little longer. This did little to remove any fear of not finding a job post FRP graduation. FRP’s were given some flexibility in finding a full time job. After graduating the program in September, Microsoft gave you about 4-6 weeks more to settle into a final job. You would still get paid, even if you didn’t have a team to call home. Being in this corporate limbo sounds nice in theory but in reality is awful. Like your days are numbered.</p>
<p>The waiting ended in a re-org of another BI team joining ours. So there was a hiring freeze in the meantime while both teams were being combined. After that, a job was offered, and the rest is history. I’m still on that team today. We’ve been through a lot of re-orgs since 2018, but I still get to work on ML every single day. I consider myself lucky.</p>
</section>
</section>
<section id="advice" class="level2">
<h2 class="anchored" data-anchor-id="advice">Advice</h2>
<p>Here is my advice for anyone interested in the FRP, currently in the program, or FRP’s who are about to graduate and start the next phase of their career. I have to say that this advice may not stand the test of time, hiring practices constantly change. So take these next words with a grain of salt.</p>
<section id="aspiring-frps" class="level3">
<h3 class="anchored" data-anchor-id="aspiring-frps">Aspiring FRP’s</h3>
<p>Recruiting for the FRP used to be done at target schools. Places like Texas, Penn, and the University of Washington. Kids from these schools normally had the best shot at getting an interview, because Microsoft would come onto campus and do interviews. Thankfully this started to change when I applied for the internship. Now Microsoft finds FRPs from any school in the country, even recently expanding to other parts of the world. This opens up the opportunity of joining the FRP to almost anyone in the world, but because of this it becomes harder to get recognized in a sea full of applications.</p>
<p>Before you even apply, you need to put yourself in a strong position by building a portfolio of experiences and skills that make you a perfect match for the FRP. Here is what I recommend.</p>
<ol type="1">
<li>High Agency: Having good grades is a fantastic accomplishment, but nowadays everyone has good grades. It becomes more of a check box than something that differentiates yourself from others. Grades show that you can follow instructions, keep deadlines, and demonstrate some type of understanding of your study area. What companies want though are people who go out into the world and make things happen. People who are proactive instead of reactive, or better put have high agency. The best definition I’ve heard of high agency is “a person you would call to bail you out of a third world prison”. Someone who can do that can most likely figure out how to do any kind of job, and become indispensable to their company. The best way to showcase high agency to recruiters at Microsoft is to show how you spend your time outside of the classroom. If you have a 4.0 but only play video games when you’re not studying, your resume will most likely get thrown away. Don’t get me wrong, you could be a fantastic hire but a recruiter has no idea how you get along with others, your communication skills, or anything that’s not related to reading a textbook and taking a test to prove you read the textbook. The best way to showcase high agency is with leadership experience. Running your own business, being the vice president of your sorority, treasurer of your finance club, running your own charity, working a full time job to pay for school. These are all ways to demonstrate that you are someone who goes out and makes things happen. That you indeed have high agency.</li>
<li>Previous Work Experience: Having already done the job makes it easy to get a similar job. This can sometimes be a chicken or the egg situation, where needing a previous job to get your first job isn’t possible. That’s why I think you should start small. For me, it started the summer after 8th grade. I got a job in the concession stand of my local city pool. It wasn’t fun work, but lead to my second job working for the famous Jack Stack BBQ in the catering department. That job lead to multiple summers working at two different golf courses as a cart boy. All to say that it eventually lead to my first real business job working as an intern on Fridays during the school year at a financial advisor company. I didn’t do much, but I showed up every Friday ready to help. Having that experience gave me the opportunity to work in FP&amp;A at HR&amp;R Block in Kansas City as a legit intern. That experience then opened the door to work at Microsoft as an FRP intern. Small beginnings lead to massive results. Having a crap job at the beginning can lead to your dream job later down the line. Start this path as soon as you can, because hard work compounds.</li>
<li>Data Superpowers: In this modern age of AI, knowing how to work with data is critical. I’m not just talking excel skills. Being able to pull, manipulate, visualize, and tell stories with data is most of what you do in Finance at Microsoft. Having some programming or low code skills in data tools like python or Power BI can go a long way. This gets supercharged with tools like ChatGPT, where a little knowledge of coding can quickly make you on par with an entry level data scientist or software engineer. Imagine not learning email or Microsoft Office in the 90s. Not knowing email today is basically a firable offense. Using AI powered tools might have the same path in knowledge work. Get ahead and get data superpowers.</li>
</ol>
<p>You might have all of those experiences and skills called out above, but that’s only half the battle. You still have to get noticed somehow. Either by a recruiter or someone else who works at the company. Here is what I recommend.</p>
<ol type="1">
<li>Conferences: Microsoft has pivoted away from on campus interviews and now does a lot of recruiting at conferences. This is how the first round of interviews get offered. These conferences are usually meetings of large student organizations like Association of Latino Professionals for America (ALPFA), Management Leadership for Tomorrow (MLT), Out for Undergrad (O4U), and National Association of Black Accountants (NABA).</li>
<li>Employee Referral: Getting your resume referred by a current or FRP alum can go a long way, but it’s no guarantee of an interview. The best way to get a referral is by actually knowing someone who works at the company, or having a shared interest with them. Blindly messaging Microsoft employees on LinkedIn could work, but you’d have better success finding someone who went to your same high school or served in the same branch of the military. Having a shared connection around a place or thing helps.</li>
<li>Intern First: The best way to get a full time offer is to be an intern the summer before. 50-90% of full time FRP’s were an intern the previous summer. This is the path with the greatest opportunity of a job. Don’t go work at a bank in the summer, assuming you’ll get a shot at Microsoft in the fall if you don’t like your bank job. Be in it to win it from the start.</li>
</ol>
</section>
<section id="current-frps" class="level3">
<h3 class="anchored" data-anchor-id="current-frps">Current FRP’s</h3>
<p>For folks currently in the FRP, I hope you’re having just as much fun as I did. Normally when working with FRP’s today I have to fight the urge to grab them around the shoulders and beg them to cherish being in the FRP (just like <a href="https://youtu.be/rr9_EgFKr1Q?si=ZqfFmwwtVO6gMXh0">Billy Madison</a>). In order to get the most out of the program you should do the following.</p>
<ol type="1">
<li>Always ask for what you want. The biggest unlock I learned in the FRP is to just be up front with what you want in the rotation. Telling your manager at the beginning of the rotation what you’d hope to get out of the next six months can unlock doors you never thought possible. In my fourth rotation, they literally changed the entire rotation because I simply asked if I could solely work on building ML solutions. Don’t forget I’m still working in that job six years later. The best approach is to ask for what you want before you rank your next rotation. Bear in mind you can’t just say something like “I want to work with the CFO directly”. I’ve seen interns do this in the past, and it doesn’t end well for them. Know what you want, have some sort of skill or experience doing it, then ask for it.</li>
<li>Always see who else is working on something first. It’s always fun to build something from scratch. An important skill to learn in the FRP though is building on the work of others. This is a key component of how impact gets measured at the company. In my fourth rotation, I was able to have impact 10x as fast on the deal pipeline analysis project because I found another data scientist team who already had a deal pipeline conversion model I could leverage and start using immediately. If I didn’t ask I would have spent most of my time trying to build one, which may not have been useful at all. Always ask around before building something new.</li>
<li>Embrace serendipity. Your career path is never going to work out 100% exactly like you planned it, and you don’t want it to. You need to brace serendipity, keeping an open mind for making the most of new opportunities. The best example was the FRP in my class who got their dead last choice of rotation, but ended up working on that team full time post FRP. You never know where a road is going to take you. Don’t be afraid to explore different paths or see things through on an existing path.</li>
</ol>
</section>
<section id="graduating-frps" class="level3">
<h3 class="anchored" data-anchor-id="graduating-frps">Graduating FRP’s</h3>
<p>My last piece of advice comes to those who are ending their FRP tenure and now look on to the rest of their career. It can be a scary feeling, so here’s what I recommend.</p>
<ol type="1">
<li>Cast a wide net. Don’t just apply to one job, hoping you’re going to get it and end up with the perfect job. You need to apply to a crap ton of jobs. Don’t be picky. Even apply to jobs that don’t look exciting on paper, because that could change once you meet with the hiring manager. Serendipity could strike in your favor.</li>
<li>The best jobs go to people with high agency. Your perfect job is out there, but it may not be listed on the internal company job board. So have high agency and chase down opportunities that don’t even exist yet. This starts months before graduation. You need to network with teams you are interested in, meeting with potential hiring managers who could one day give you a job. For me, I went to every business intelligence team in finance. I emailed the director level leader, gave my short sales pitch saying I wanted do work on ML solutions for their team, and asked if we could chat to discuss any openings on their team. I’d even ask them if they knew any other team I should go talk to. Most didn’t offer me a job. Some continued to offer me interviews years after the FRP. You just never know. If you are talking to teams that aren’t hiring, you are basically in your own talent pool. Looking for opportunities that might materialize later once you graduate. If a job does open on that team, who is their first call? Probably the person who proactively reached out and made a connection well before a job was ever created. Use this to your advantage.</li>
<li>Join for the team, not the job. The job will eventually come. Being in the right position is important more than what you do. Most jobs after graduating may not be the most fun. They will be work, maybe even grueling. Someone needs to do the work and congrats it’s your turn to eat a plate of crap for the company. Going to the right team is definitely more important that getting the dream job you wanted on a crap team. For me, I took a job on my fourth rotations team. They said I could do ML work, but most of my time would be spent as a program manager (PM). I hated PM work, but knowing that part of my time could be doing ML work was all I needed to hear. Eventually my job morphed into 100% ML work after I was able to prove to my manager that I could have more impact on the ML side than the PM side of my job. Being on the right team or org allows you more opportunity to work on things you eventually want your career to morph into. The team I joined post FRP has now morphed into a 400+ person engineering team. One that’s quickly becoming the defacto engineering team in finance at Microsoft. Being on this team over the years has created much more opportunity compared to doing similar work on a different team. Thankfully I was well positioned, even though I didn’t have the ideal job initially. See what I mean? So don’t be too picky on the job, but more picky on the team.</li>
</ol>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Being an FRP teaches you a lot. How to ramp up quickly on new skills, being able to juggle many things at a time, effective communication and teamwork, and countless other skills. All things that make you a well rounded person both professionally and personally. Some of my favorite memories come from the summer internship or hanging out with my FRP coworkers in building 26 (before they tore it down). I think it’s a great idea for anyone who is interested in technology and business. If you’d like to apply to the program, please do so on the <a href="https://careers.microsoft.com/v2/global/en/financerotation">Microsoft career website</a>. Whether you’re interviewing for the FRP or trying to land your post FRP role, I wish you good luck!</p>


</section>

 ]]></description>
  <category>career</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2024-02-19-frp-journey/index.html</guid>
  <pubDate>Mon, 19 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-02-19-frp-journey/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (2/16/24)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2024-02-16-weekend-reads/index.html</link>
  <description><![CDATA[ 




<p><img src="https://mftokic.github.io/posts/2024-02-16-weekend-reads/image.png" class="img-fluid"></p>
<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<ul>
<li><a href="https://www.readtrung.com/p/8-lessons-from-curb-your-enthusiasm">8 Lessons from “Curb Your Enthusiasm”</a></li>
<li><a href="https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy/">The Knowledge Economy Is Over. Welcome to the Allocation Economy</a></li>
<li><a href="https://www.nytimes.com/2024/02/08/well/live/ozempic-muscle-loss-exercise.html">The Race Is On to Stop Ozempic Muscle Loss</a></li>
<li><a href="https://waitbutwhy.com/2024/02/vision-pro.html">All My Thoughts After 40 Hours in the Vision Pro</a></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://twitter.com/george__mack/status/1751522832545107992">High Agency by George Mack</a></li>
<li><a href="https://twitter.com/trungtphan/status/1757590076027281580?s=46&amp;t=8Xa2BngQ9d359SJzFrCFMA">Vision Pro Teardown by Trung Phan</a></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://www.amazon.com/Boys-Boat-Americans-Berlin-Olympics-ebook/dp/B00AEBETU2/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.KquVRXnik3uOg8hxrLmJfP_LahKB4s1W46vzNAgAb9wvj80R1_rinS9btDIvVMLrc4mooEEO2d9FMOJYI2OsrGfzFHNWTUH8LtJNa0moro5FM4CWZttdApwLepeP_x0lB_8eIRJXq3y7CcHf-Kn6a2p3hBhsY_P32sHQg7u7D5JEHOE4aAkLflmwMHHIPTd56wISovn7vw3oTtFnSPVL5yx8vuz-GGhu6En1F9ZeHoQ.0GJBdgRORD33beQuLvtA3nEpCNE0wzbCf6HNbAENZVg&amp;qid=1708101446&amp;sr=8-1">The Boys in the Boat by Daniel James Brown</a></li>
</ul>
</section>
<section id="products" class="level2">
<h2 class="anchored" data-anchor-id="products">Products</h2>
<ul>
<li><a href="https://mauinuivenison.com/collections/butcher-shop/products/sugar-free-pepper-stick-24-pack">Maui Nui Sugar Free Venison Jerky</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2024-02-16-weekend-reads/index.html</guid>
  <pubDate>Fri, 16 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2024-02-16-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
