<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Thoughts on Things</title>
<link>https://mftokic.github.io/</link>
<atom:link href="https://mftokic.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>A collection of thoughts on things from the mind of Mike Tokic</description>
<generator>quarto-1.5.57</generator>
<lastBuildDate>Mon, 13 Oct 2025 07:00:00 GMT</lastBuildDate>
<item>
  <title>Finn Forecasting AI Agent Launch</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-10-13-finn-agent-launch/</link>
  <description><![CDATA[ 





<section id="building-an-ai-finance-teammate" class="level3">
<h3 class="anchored" data-anchor-id="building-an-ai-finance-teammate">Building an AI Finance Teammate</h3>
<p>What would you do if your CFO asked you to build a finance teammate from scratch using AI? Where would you start? You might think about the main types of work people do in a company’s finance department. Let’s boil them down to the top three, according to Microsoft CFO Amy Hood.</p>
<ol type="1">
<li>Looking Forward</li>
<li>Looking Backward</li>
<li>Making the Next Best Decision</li>
</ol>
<p>In terms of which one is the most important, my vote would be for looking forward. Making decisions about the future is the essence of finance. Looking backward is for accountants. What makes finance fun is using data to make decisions about an uncertain future.</p>
<p>In order to make decisions about the future, you have to make a guess or prediction about what the future might be. This is the practice of forecasting. In finance our forecasts are based on numbers, which are in the form of a time series (numbers over time). Being able to forecast these time series effectively allows the CFO and the rest of the company to make the best decisions. Therefore the most important job you can do in finance is to make high quality time series forecasts.</p>
<p>Creating these forecasts are hard though. They take time, and can often be inaccurate. Thankfully time series forecasting is a perfect problem for AI and machine learning to solve. So when starting to build an AI teammate, the first thing you want it to be good at is the problem of forecasting.</p>
</section>
<section id="challenges-in-ml-forecast-adoption" class="level3">
<h3 class="anchored" data-anchor-id="challenges-in-ml-forecast-adoption">Challenges in ML Forecast Adoption</h3>
<p>Historically the practice of using machine learning in financial forecasting has been hard. Both in creating accurate forecasts and in getting finance humans to use them to drive business decision making.</p>
<p>The first challenge relies in knowing how to use the right grain of data and machine learning techniques to get an accurate forecast that can match or exceed the accuracy of existing manual forecasts created by humans. This takes a unique combination of data and machine learning knowledge, as well as the domain expertise of the business you are trying to forecast. Finance people have the domain knowledge, but lack the required data engineering and machine learning knowledge. In the past this means that expensive engineering teams would have to be created to put together these complex machine learning forecasts. These engineering teams would have to do a lot of trial and error around testing what data inputs and machine learning techniques produce the highest quality forecasts. This process can be very tedious. Which slows down how fast these forecasts can be created and how fast new forecast projects can be onboarded to a machine learning approach.</p>
<p>Once these machine learning outputs are created, the other major problem lies in getting finance humans to use the outputs created by a machine. With their manual forecasts created in excel, they can trace how the forecast was created cell by cell. Fully understanding the assumptions and thought process that went into the forecast. With machine learning, this excel model is now abstracted away behind the curtain of a machine learning model. A black box that only a talented data scientist can understand. This creates a problem of trust between a finance human and the machine learning forecast. Because they cannot understand it as easily as their manual excel process, they are less likely to use it for their decision making. Even if the machine learning forecast is proven to be more accurate, they are still hesitant.</p>
<p>These two problems have slowed down the adoption of machine learning forecasts in finance over the last decade. Good advancements have been made in democratizing machine learning tools to help reduce the need for engineers, but the accuracy and trust problems still persist. What we need is to not democratize machine learning to finance humans but to instead <strong>delegate the complex work of creating these forecasts into a digital finance employee</strong>. An AI teammate who at its core knows how to use AI and machine learning to help finance humans get more work done. This teammate is an AI agent, one who can work 24/7 at scale in the cloud alongside you. Allowing finance humans to do more than they ever thought possible.</p>
<p>That’s the purpose of recent work we’ve been doing in Microsoft finance to build the first version of our forecasting AI agent. It builds upon our existing <a href="https://microsoft.github.io/finnts/">machine learning forecast framework called Finn</a>, and adds a new AI agent on top of the framework to take forecasting to a whole new level. Let’s explore what the initial version of the agent can do.</p>
</section>
<section id="iterate-forecast" class="level3">
<h3 class="anchored" data-anchor-id="iterate-forecast">Iterate Forecast</h3>
<p>The first problem we wanted the agent to tackle was to automate the process of experimentation in trying to find the right combination of input data and machine learning techniques to create the most accurate forecast. This process is easily the biggest bottleneck in starting any new forecast project with machine learning.</p>
<p>We call this the <strong>iterate forecast skill</strong> in the Finn agent. The first thing it does when starting the iteration process is to teach itself about the historical data. It runs various exploratory data analysis steps to learn many things about the historical input data. For example, it will check for missing values and outliers, seasonal patterns, and what variables are most correlated to what we’re trying to forecast.</p>
<p>Once the agent has taught itself about the data, it thinks through what combination of data and machine learning techniques it should use in the first iteration of the machine learning forecast process. It bases this decision on what it learned during exploratory data analysis, the knowledge it has about using Finn, and custom domain knowledge we gave it based on our experience running thousands of forecast experiments over the years.</p>
<p>After the agent determines what inputs to use, it kicks off a machine learning run inside of Finn. Running through each stage in the Finn forecast process.</p>
<ol type="1">
<li><strong>Data Cleaning</strong>: fill in missing values, fix outliers, etc.</li>
<li><strong>Feature Engineering</strong>: transform the data before training models using lags, rolling window periods, etc.</li>
<li><strong>Model Back Testing</strong>: train various models on historical data.</li>
<li><strong>Best Model Selection</strong>: blend different models together and choose which model or combination of models are the most accurate.</li>
<li><strong>Final Forecast Output</strong>: consolidate the final results into a dataset that contains historical back test and future forecasts.</li>
</ol>
<p>When the Finn forecast process is finished, the agent will analyze the back testing results and make a decision to either stop or think through another set of inputs to try in a second iteration based on what it learned from the first run to improve accuracy. What determines if the agent keeps running or not is a set of constraints and goals we provide the agent.</p>
<ul>
<li><strong>Iteration Constraint</strong>: The number of times the agent will iterate on running forecast experiments. Looping through reasoning what inputs to try next, running the Finn forecast process, then analyzing the back test accuracy.</li>
<li><strong>Accuracy Goal</strong>: The mean absolute percent error (what % the forecast is off on average) the back test forecast should be lower than.</li>
</ul>
<p>The agent will continue to iterate on the forecast until it either reaches the iteration constraint, beats the accuracy goal, or runs out of ideas of what to try next (quits the run). These built in stopping mechanisms ensure the agent doesn’t run forever and gets us closer to our overall accuracy goals within a reasonable time limit.</p>
</section>
<section id="update-forecast" class="level3">
<h3 class="anchored" data-anchor-id="update-forecast">Update Forecast</h3>
<p>The iteration process can take a while to run, based on the size of the data and the constraint/goal you provide it. This makes it hard to use during tight forecast cycles where a finance team may only have a day or two to create a forecast end to end. That’s why we built the <strong>update forecast skill</strong> in the agent. This allows the agent to take already trained models from previous agent forecast iterations (or updates) and feed the latest historical data through them.</p>
<p>After updated forecasts are created, the agent will analyze the accuracy of this newest forecast with the accuracy obtained during the previous agent forecast iteration. If accuracy is considerably worse for most of the data, if allowed, it will kick off a new forecast iteration process to ensure the agent is creating the most accurate forecast on the data. This is totally optional, and controlled by the user of the agent.</p>
<p>Being able to easily update forecasts based on previously trained models allows us to cut down the total run time by up to 90% when compared to previous Finn version runs. This allows users of Finn to go from creating forecasts in hours to now creating forecasts in minutes. A true order of magnitude improvement.</p>
</section>
<section id="explain-forecast" class="level3">
<h3 class="anchored" data-anchor-id="explain-forecast">Explain Forecast</h3>
<p>The first two skills in the agent help us solve the first challenge of machine learning adoption around accuracy. What’s missing is being able to easily explain the outputs of the agent to a regular person, without the need of an expert data scientist. This is where the <strong>explain forecast skill</strong> comes to save the day.</p>
<p>When a user asks a question of the agent, it can think through the problem step by step and come up with an approach to answer it.</p>
<ol type="1">
<li><strong>Planning</strong>: The agent first takes the question and thinks through what steps it needs to accomplish to answer the question.</li>
<li><strong>Execute Steps</strong>: Then it will go through each one of these steps, writing and executing code to get data outputs for final analysis.</li>
<li><strong>Finalize Answer</strong>: After all steps in the plan are complete, it will synthesize the outputs from each step into a simple answer back to the user.</li>
</ol>
<p>This type of thinking process allows the agent to answer a various range of complex questions.</p>
<ul>
<li><strong>Historical Data</strong>
<ul>
<li>Are there any missing data or outliers in the data?</li>
<li>What external variables are correlated to revenue?</li>
</ul></li>
<li><strong>Forecast Output Review</strong>
<ul>
<li>What was the historical back testing accuracy?</li>
<li>Which models performed the best?</li>
</ul></li>
<li><strong>Run Settings and Model Selection</strong>
<ul>
<li>What data cleaning strategies were used in the final forecast?</li>
<li>What outside variables were used in the final forecast?</li>
</ul></li>
<li><strong>Model Explanation</strong>
<ul>
<li>What variables are the most important in the model?</li>
<li>Explain how the arima model works to produce the forecast?</li>
</ul></li>
</ul>
<p>Now finance humans can ask the agent any question about the machine learning forecast and get back answers in simple terms that enable them to understand exactly how the forecast was created. This removes the black box complexity and helps build trust. The agent will patiently answer any questions asked and is always available to chat 24/7.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>With an AI agent, we can now have forecasts that are accurate, fast, and easier to understand. This is the holy trinity of machine learning forecasting in finance. Solving these three areas removes 99% of common adoption roadblocks. This creates an exciting new world where finance humans can closely collaborate with AI teammates to do things never thought possible.</p>
<p>Once we are able to change the finance forecasting game with agents, it makes it easier to tackle the other two components of corporate finance work. If you can use AI to look into the future (forecasting), it makes it a lot easier to look into the past (financial close). Imagine having AI perfectly understand the forecast, which allows it to explain variances to forecast when it comes time to close the books at month end or quarter end. This is the true long term vision of these agents, expanding their capabilities until they turn into well rounded finance teammates.</p>
<p>The future of finance work is very exciting. If you’re interested in the Finn AI agent, <a href="https://microsoft.github.io/finnts/">check out the Finn open-source documentation to learn more</a>. May the MAPE ever be in your favor.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>finance</category>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-10-13-finn-agent-launch/</guid>
  <pubDate>Mon, 13 Oct 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-10-13-finn-agent-launch/image.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>First Thoughts on Forecasting AI Agents</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-06-26-forecasting-ai-agent/</link>
  <description><![CDATA[ 





<section id="democratize---delegate" class="level3">
<h3 class="anchored" data-anchor-id="democratize---delegate">Democratize -&gt; Delegate</h3>
<p>I’ve worked on machine learning (ML) forecasting for most of my career. The biggest opportunity I’ve found to scale the impact of machine learning was to <a href="https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/">democratize the technology</a> to an average person with no technical or coding background. Each user could become their own citizen data scientist. But now I’m starting to rethink that. Instead of trying to teach humans how to use AI/ML tools, how can we teach AI to use these tools? <strong>Shouldn’t AI be the best at using AI?</strong> I think so. This shifts my initial idea of <strong>democratizing to now delegating</strong> the task of creating ML forecasts to AI agents who can work on them 24/7. Having this full time virtual data scientist working for humans will have profound effects on the future of forecasting.</p>
</section>
<section id="why-forecasting-with-machine-learning-is-hard-in-finance" class="level3">
<h3 class="anchored" data-anchor-id="why-forecasting-with-machine-learning-is-hard-in-finance">Why Forecasting with Machine Learning is Hard in Finance</h3>
<p>Before we discuss the promise of new AI agents, let’s review why the current state of democratizing is hard to do. Most of the roadblocks to ML adoption end up in two buckets.</p>
<ol type="1">
<li><strong>Not Enough Time</strong>: Finance people are too busy doing their current jobs to learn how to do it any other way. They don’t have time to learn to use new tools. No time to analyze the ML output alongside their traditional forecast methods. Even if they wanted to use the democratized ML tools (or even have a data science do it for them) the process of iterating to find the best combination of data inputs and ML techniques takes up too much time.</li>
<li><strong>Black Box</strong>: There’s a certain leap of faith that needs to happen when using ML. Before with traditional excel models, a finance person could trace cell by cell how a specific forecast number was created. This goes out the window with ML. Making it harder to explain the forecasts to business partners and be accountable if the ML forecast is inaccurate. Either the finance person needs to be technical enough to explain the ML process and output or they need to come to someone like me to “read the ML tea leaves” for them to help understand the forecast output.</li>
</ol>
</section>
<section id="cant-llms-create-forecasts" class="level3">
<h3 class="anchored" data-anchor-id="cant-llms-create-forecasts">Can’t LLMs Create Forecasts?</h3>
<p>At this point, you might be thinking to yourself “I thought everyone is saying these new large language models (LLM) from places like OpenAI are close to superintelligence, can’t they just create the forecast for us?”. LLMs are good at text, not numbers. You cannot simply give them historical revenue data and expect them to output a sophisticated forecast. It will not work with today’s models. There are some companies like <a href="https://www.nixtla.io/">Nixtla</a> who have created generative AI models that are specific to time series that are worth looking into, but we’re still in the early days of these models.</p>
<p>Instead of training humans to use democratized ML tools, can we train AI to use the tools? This is where AI agents come into play. Think of them as LLMs who can call various tools and APIs on their own autonomously to accomplish a goal set by a human. In a sense they are like hiring a contractor or intern to go work on something for you, maybe check in from time to time, and continue to work for days or weeks until they finish the task.</p>
</section>
<section id="are-ai-agents-the-answer" class="level3">
<h3 class="anchored" data-anchor-id="are-ai-agents-the-answer">Are AI Agents The Answer?</h3>
<p>AI agents that can create forecasts will be like having a virtual data scientist right out of the box ready to go 24/7. Every finance person can have an agent working for them around the clock. Constantly iterating and updating their forecasts to make them more accurate and easier to understand. Agents will solve both of the biggest challenges in adopting ML forecasts. They fix the lack of time problem by being able to run 24/7 and at scale across the cloud. They also can help fix the black box problem by being able to easily explain any ML output in plain english to a user. This “chat with your forecast” capability will help teach finance users how ML works and help build their “ML intuition”. Let’s see what an AI forecast agent can actually do.</p>
</section>
<section id="what-can-an-ai-forecast-agent-do" class="level3">
<h3 class="anchored" data-anchor-id="what-can-an-ai-forecast-agent-do">What Can an AI Forecast Agent Do?</h3>
<p>Here are all of the “skills” or “workflows” I imagine an AI agent being able to do for finance users. Some require connecting to other agents, while others are self-contained within the realm of the forecast agent.</p>
<ol type="1">
<li><strong>Research</strong>
<ul>
<li>Being able to find and pull data to use in the ML forecast process. This is most likely done through a separate agent that specializes in this. For example, having an internal data agent in your company that allows other agents to connect to it and pull financial data from your core reporting systems.</li>
<li>Run analysis on potential things that are impacting your business, and therefore your forecast. For example, understanding the current state of tariffs, and how their impact should be reflected in the ML forecast. Either by adding input data around tariffs or applying some sort of adjustment after the ML forecast process runs.</li>
</ul></li>
<li><strong>Data Formatting</strong>
<ul>
<li>Once you have some data you want to use to produce a ML forecast, transform it in the right ways to make it easy for the ML forecast process to learn from the data and produce an accurate forecast.</li>
</ul></li>
<li><strong>Exploratory Data Analysis</strong>
<ul>
<li>Teach the LLM about your data set. Run all of the <a href="https://mftokic.github.io/posts/2024-10-03-ts-fundamentals-eda/">classic EDA techniques</a> and provide that information to the AI agent so it knows about the trends and patterns in your historical data.<br>
</li>
</ul></li>
<li><strong>Forecast Iteration</strong>
<ul>
<li>Allow the AI agent to start running ML forecasts on your behalf. This is where it connects to existing AutoML like tools where it can kick off new ML runs, analyze the forecast accuracy, and make tweaks to the data or ML inputs to get an even better forecast. The user can give the agent constraints around the maximum amount of runs it can do and the end goal of a forecast error it wants the agent to obtain.</li>
<li>Combining EDA with iteration is where the magic happens. This is where the agent can work 24/7 on constantly trying to improve the forecast and find new ways to make it even more accurate. This is how you get scalable impact by having a full time virtual data scientist working for you nonstop.</li>
<li>Most AutoML systems will optimize all time series at once. An AI agent can go one time series at a time, knowing exactly what inputs and ML parameters to use to get the maximum accuracy. Even in complex <a href="https://otexts.com/fpp3/hierarchical.html">hiearchical forecast</a> processes.</li>
</ul></li>
<li><strong>Forecast Update</strong>
<ul>
<li>Once you have that optimized forecast from skill #4, you might need to create updated forecasts every month going forward. The agent can now take new data and combine with what created the best forecasts previously to update new forecasts on the fly. This kind of memory helps save time and resources by not needing to run the whole AutoML forecast process from scratch each time you need a new forecast.</li>
<li>Over time, inputs that initially created the most accurate forecast initially may now longer be relevant in creating the most accurate forecast going forward. The agent will be able to recognize when these forecasts deviate from historical accuracy and know when to properly retrain or even go back to the drawing board and try new forecast iterations to get back to the proper level of accuracy.</li>
</ul></li>
<li><strong>Forecast Explanation</strong>
<ul>
<li>Users can ask the agent questions about the forecast and get answers back in plain english. The agent can rely on learnings from the EDA process, previous forecast iterations, and its research capabilities to answer any question.</li>
<li>For tougher analysis questions asked by users, the agent will be able to write and execute code on the fly to return tables and charts that give greater insight into the forecast.</li>
<li>This kind of QnA capability allows finance users to increase their understanding of the ML forecast output, which increases their trust in ML. Over time as this trust builds they will want to use the ML output even more, since now they know it’s accurate and are able to explain the outputs to their business partners.</li>
</ul></li>
<li><strong>Forecast Transformation</strong>
<ul>
<li>After the final ML forecast is created, users can then instruct the agent to allocate it down to even more granular levels. For example a ML forecast might be created at a worldwide level, then be allocated down to a country level. All done intelligently and on the fly by the agent.</li>
<li>Users can also make high level manual adjustments to the forecast and the agent will correct apply them. For example a user may want to adjust a revenue forecast by 10 million, and the agent can take that amount and spread it correctly to each country based on predetermined seasonality or any other technique asked by the user.</li>
</ul></li>
<li><strong>Scenario Analysis</strong>
<ul>
<li>Being able to ask “what if” questions about a ML forecast has been tough to do historically. It requires changes to the input data and feature engineering process to get the final outputs. But with an agent this all becomes a simple ask away. The agent will be able to adjust the data and re-run the ML forecast process based on the scenarios asked by the user and easily explain the changes in the forecast that arise.</li>
</ul></li>
<li><strong>Variance Analysis</strong>
<ul>
<li>If LLMs and agents can help us look into the future with forecasting, they can definitely help us look into the past and figure out the reasons why our forecast was different than what actually happened in the business for a specific quarter. Using ML to create future forecasts makes it easier to run variance analysis because everything is documented for the AI agent to sift through and understand. It knows exactly what historical data was used, what other ML params were chosen, and what the final ML models were that produced the forecast. It can fill in it’s gaps with its research skills to understand other internal and external factors that might have impacted the business as well. Making it easy to spot and explain forecast variances at scale.</li>
</ul></li>
</ol>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p><a href="https://mftokic.github.io/posts/2025-05-24-agent-manager/">Eventually all of us will be AI agent managers</a>. Being able to to build and wield these agents will become the ultimate source of leverage in business. Agents applied in the forecasting space have so much potential to help finance teams better plan and make decisions about the future. They will be able to work faster and do kinds of work never thought possible before.</p>
<p>I’m currently working on building AI agent capabilities directly into my <a href="https://microsoft.github.io/finnts/">automated ML forecast framework called Finn</a>. It’s completely open-source and free to use. Stay tuned for more updates if you’d like to use it!</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>machine-learning</category>
  <category>forecasting</category>
  <category>time-series</category>
  <category>finance</category>
  <guid>https://mftokic.github.io/posts/2025-06-26-forecasting-ai-agent/</guid>
  <pubDate>Thu, 26 Jun 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-06-26-forecasting-ai-agent/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Weekend Reads (6/1/25)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-06-01-weekend-reads/</link>
  <description><![CDATA[ 





<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<div class="callout callout-style-default callout-tip callout-titled" title="Kevin Rose on Tim Ferriss">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Kevin Rose on Tim Ferriss
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://www.youtube.com/watch?v=Eql0VFUc4Dc">Link to Video</a></p>
<section id="personalized-medicine-preventive-health" class="level3">
<h3 class="anchored" data-anchor-id="personalized-medicine-preventive-health">Personalized Medicine &amp; Preventive Health</h3>
<section id="genomics-driven-supplement-playbook" class="level4">
<h4 class="anchored" data-anchor-id="genomics-driven-supplement-playbook">Genomics-Driven Supplement “Playbook”</h4>
<ul>
<li>Kevin sequenced his <strong>entire genome</strong> for ≈ $700 (full‐genome, not 23-and-Me).<br>
</li>
<li>AI + VCF file located an <em>MTHFR</em> mutation ➜ explains chronically high <strong>homocysteine</strong> (CVD risk marker).<br>
</li>
<li>Iterative stack (added one lever at a time):
<ul>
<li>Methyl-B vitamins (methyl-folate, methyl-B12).<br>
</li>
<li><strong>N-Acetyl-Cysteine (NAC)</strong> as extra methyl donor → finally dropped homocysteine to <em>normal range</em> after “years of failure.”<br>
</li>
</ul></li>
<li>Take-away → expect LLM-driven “omic” protocols that surface <em>root-cause</em> bottlenecks, not just blanket supplement lists.</li>
</ul>
</section>
<section id="annual-check-ups-early-detection" class="level4">
<h4 class="anchored" data-anchor-id="annual-check-ups-early-detection">Annual Check-ups &amp; Early Detection</h4>
<ul>
<li>Colonoscopy schedule: Tim keeps rigid 5-year cadence after friend’s fatal metastatic colon cancer.
<ul>
<li>Pro-tip: ask anesthesiologist for a <strong>“slow ramp”</strong> propofol drip (60 s mild euphoria before lights-out).<br>
</li>
</ul></li>
<li>Full-body MRI: caught a stable micro-aneurysm in Kevin’s brain; now scanned yearly.
<ul>
<li>Downside = “incidentalomas” (false positives you must learn to ignore).<br>
</li>
</ul></li>
<li><strong>GRAIL blood test</strong> as needle-only multi-cancer screen for claustrophobic patients.<br>
</li>
<li>Baseline literacy books ­→ <em>Bad Science</em> (Ben Goldacre) for media-hype triage.</li>
</ul>
<hr>
</section>
</section>
<section id="everyday-bio-optimization-toolkit" class="level3">
<h3 class="anchored" data-anchor-id="everyday-bio-optimization-toolkit">Everyday Bio-Optimization Toolkit</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 30%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Tool / Habit</th>
<th>Key Details</th>
<th>Practical Tip</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>WHOOP “MG”</strong></td>
<td>12 % smaller; cuff-calibrated BP, ECG spot check, VO₂ max, “Whoop Age” composite.</td>
<td>Set custom HR zones or import lab VO₂ max to refine Zone-2 training.</td>
</tr>
<tr class="even">
<td><strong>Zone 2 cardio</strong></td>
<td>“Talk test” ≈ can speak full sentences, wouldn’t choose to.</td>
<td>Aim 30–60 min daily; compare wearables with <em>Quantified Scientist</em> benchmarks.</td>
</tr>
<tr class="odd">
<td><strong>Profi nasal hydro-gel</strong></td>
<td>Stanford tech; traps viruses/bacteria in mucosal matrix.</td>
<td>1 spray/nostril pre-flight or large indoor events.</td>
</tr>
<tr class="even">
<td><strong>Dashi tea-bags</strong></td>
<td>Okui 1871 packs bonito + anchovy + kelp as single-serve sachets.</td>
<td>Use like morning tea/coffee; mineral-rich umami without caffeine.</td>
</tr>
<tr class="odd">
<td><strong>Peloton seat caution</strong></td>
<td>Narrow saddle → perineal compression → numbness, fertility risk.</td>
<td>Swap seat or move to air-rower/Assault-bike with adjustable saddle.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="sobriety-journey-liver-reset" class="level3">
<h3 class="anchored" data-anchor-id="sobriety-journey-liver-reset">Sobriety Journey &amp; Liver Reset</h3>
<ul>
<li>Kevin: <strong>26+ dry days</strong> (goal ≥ 90).
<ul>
<li>Liver enzymes AST/ALT fell <strong>150 → low-30s</strong>.<br>
</li>
<li>Mood “+10 % baseline” and reduced sensitivity to criticism.<br>
</li>
</ul></li>
<li>Tools &amp; mindsets
<ul>
<li>24-hour pledge: “Not today—tomorrow is undecided.”<br>
</li>
<li>Phone-a-friend contact sheet; weekly men-only Zoom for accountability.<br>
</li>
<li>Substitute hobbies: adult <strong>LEGO art</strong> (<em>Great Wave</em> 1 k pcs), Nanoblocks cherry-blossom, golf w/ spouse.<br>
</li>
</ul></li>
<li>Aphorisms
<ul>
<li>“Drinking is <strong>borrowing happiness from tomorrow</strong>.”<br>
</li>
<li>“Discipline is the strongest form of self-love.”</li>
</ul></li>
</ul>
<hr>
</section>
<section id="neuro-tech-mental-health-experiments" class="level3">
<h3 class="anchored" data-anchor-id="neuro-tech-mental-health-experiments">Neuro-Tech &amp; Mental-Health Experiments</h3>
<section id="accelerated-tms-saint-protocol" class="level4">
<h4 class="anchored" data-anchor-id="accelerated-tms-saint-protocol">Accelerated TMS (SAINT protocol)</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 57%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Detail</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Course</strong></td>
<td>50 sessions × 9 min over 5 days (10 hrs total).</td>
</tr>
<tr class="even">
<td><strong>Target</strong></td>
<td>Anxiometic coil placement for OCD/rumination.</td>
</tr>
<tr class="odd">
<td><strong>Outcome #1</strong></td>
<td>2-week latency → 3–4 months full-symptom remission.</td>
</tr>
<tr class="even">
<td><strong>Outcome #2</strong></td>
<td>1-day &amp; 3-day boosters = no effect.</td>
</tr>
<tr class="odd">
<td><strong>Hypothesis</strong></td>
<td>Remission amplified by <strong>psychedelic priming</strong> ➜ heightened neuroplasticity.</td>
</tr>
<tr class="even">
<td><strong>Side-effect</strong></td>
<td>Transient <em>delayed ejaculation</em> (likely trazodone, not TMS).</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p><strong>Insurance</strong> covers conventional TMS for TR-depression; accelerated protocols may follow once cost-benefit data mature.</p>
</blockquote>
<hr>
</section>
</section>
<section id="ai-privacy-the-trust-layer" class="level3">
<h3 class="anchored" data-anchor-id="ai-privacy-the-trust-layer">AI, Privacy &amp; the “Trust Layer”</h3>
<ul>
<li>Deep-fake Tim Ferriss ads (stock-tips) → 90 % realistic; glitchy head-tilts only giveaway.<br>
</li>
<li>LLMs fabricate persuasive product copy (<em>$6 headphones &gt; $500 model</em> test).<br>
</li>
<li><strong>World ID</strong> iris scan stores zero-knowledge proof on device → reusable “proof of personhood.”<br>
</li>
<li>Digg 2.0 (Kevin + Alexis Ohanian) exploring <strong>ZK-proof badges</strong> (e.g., “verified 5-yr Oura user”) to filter bot content.<br>
</li>
<li>Tim deleted 23-and-Me data post-acquisition: genome anonymity is illusion; custom bio-agents feasible once LLMs pair with wet-labs.</li>
</ul>
<hr>
</section>
<section id="travel-culture-experiential-picks" class="level3">
<h3 class="anchored" data-anchor-id="travel-culture-experiential-picks">Travel, Culture &amp; Experiential Picks</h3>
<section id="taiwan-visit-before-prc-re-absorption" class="level4">
<h4 class="anchored" data-anchor-id="taiwan-visit-before-prc-re-absorption">Taiwan (visit <em>before</em> PRC re-absorption?)</h4>
<ul>
<li>Locals oddly placid about geopolitics.<br>
</li>
<li>Highlights:
<ul>
<li><strong>“Really Good Seafood”</strong> (bronze sculptures inside).<br>
</li>
<li>Oriental Beauty Oolong &amp; rainforest hikes &lt; 60 min from Taipei.</li>
</ul></li>
</ul>
</section>
<section id="japan-coffee-circuit" class="level4">
<h4 class="anchored" data-anchor-id="japan-coffee-circuit">Japan Coffee Circuit</h4>
<ol type="1">
<li><strong>Glitch</strong> (Ginza) – latte w/ Hokkaido milk “witchcraft.”<br>
</li>
<li><strong>Bear Pond</strong> – “Angel-stain” viscous espresso.<br>
</li>
<li><strong>Send Gold</strong> – Colombian wine-yeast peach-honey beans.<br>
</li>
<li><strong>Café Mameya</strong> – reservation-only; serves aged geishas in wine snifters.</li>
</ol>
<p><em>Tip:</em> Yen weakness → tourist surge; book Studio-Ghibli tickets months ahead.</p>
</section>
<section id="indielow-stim-entertainment" class="level4">
<h4 class="anchored" data-anchor-id="indielow-stim-entertainment">Indie/Low-Stim Entertainment</h4>
<ul>
<li><em>32 Sounds</em> (headphones a must) – immersive docu-meditation on sound.<br>
</li>
<li><em>Flow</em> – Latvian low-poly, wordless post-apocalyptic cat saga; visual acclimation ≈ 5 min.<br>
</li>
<li>Adult LEGO “art series,” Nanoblocks cherry-blossom, POJ Studio for Japanese home goods.</li>
</ul>
<hr>
</section>
</section>
<section id="meditation-inner-work" class="level3">
<h3 class="anchored" data-anchor-id="meditation-inner-work">Meditation &amp; Inner Work</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 24%">
<col style="width: 54%">
</colgroup>
<thead>
<tr class="header">
<th>Retreat Style</th>
<th>Classic Sesshin</th>
<th>Hybrid “Warm-Bath” (NM mini-retreat)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wake-up</td>
<td>4–5 a.m.</td>
<td>9 a.m.</td>
</tr>
<tr class="even">
<td>Silence</td>
<td>100 %</td>
<td>Mixed: silent sits + dialog breaks</td>
</tr>
<tr class="odd">
<td>Food</td>
<td>Oryoki mush</td>
<td>Café lunches + group dinner</td>
</tr>
<tr class="even">
<td>Tim’s Outcome</td>
<td>Nervous-system crash (prior Vipassana)</td>
<td>Safe re-entry; regained momentum; now daily <em>Way</em> sessions</td>
</tr>
</tbody>
</table>
<p><em>Way</em> app ⇒ 30 free sits → <a href="https://thewayapp.com/tim" class="uri">https://thewayapp.com/tim</a></p>
<p><strong>Books for practice</strong><br>
- Anthony de Mello <em>Awareness</em> – lecture transcripts, dense insights.<br>
- Paul Madonna <em>Everything Is Its Own Reward</em> – illustrated urban essays; makes ordinary magic visible.</p>
<hr>
</section>
<section id="entrepreneurship-play" class="level3">
<h3 class="anchored" data-anchor-id="entrepreneurship-play">Entrepreneurship &amp; Play</h3>
<ul>
<li><strong>Coyote</strong> (Ferriss × Exploding Kittens)
<ul>
<li>Social bluff party game; Walmart exclusive → top seller; gameplay videos = most-watched in EK history.</li>
</ul></li>
<li><strong>True Ventures</strong> invests $15 M in UCSF protein tackling Alzheimer’s/dementia; Kevin joins board.</li>
</ul>
<hr>
</section>
<section id="favorite-quotes-aphorisms" class="level3">
<h3 class="anchored" data-anchor-id="favorite-quotes-aphorisms">Favorite Quotes &amp; Aphorisms</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Theme</th>
<th>Quote</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sobriety</td>
<td>“I had my first drink—and my last—to be a grown-up.”</td>
</tr>
<tr class="even">
<td>Momentum</td>
<td>“A habit missed once is no big deal; a habit missed twice is the start of a new habit.”</td>
</tr>
<tr class="odd">
<td>Focus</td>
<td>“Successful people say <em>no</em> to most things; the most successful say no to <em>everything</em>.”</td>
</tr>
<tr class="even">
<td>Ethics</td>
<td>“Growth for growth’s sake is the ideology of a cancer cell.”</td>
</tr>
<tr class="odd">
<td>Resilience</td>
<td>“Courage isn’t the absence of fear; it’s taking action in spite of it.”</td>
</tr>
</tbody>
</table>
</section>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="The Science Behind Intersellar">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Science Behind Intersellar
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://www.youtube.com/watch?v=4f9V-8BHONo">Link to Video</a></p>
<section id="kip-thorne-context-career-arc" class="level3">
<h3 class="anchored" data-anchor-id="kip-thorne-context-career-arc">Kip Thorne — context &amp; career arc</h3>
<ul>
<li><strong>Caltech theoretical physicist</strong> (Richard P. Feynman Professor Emeritus).<br>
</li>
<li>Co-author of the 1 200-page graduate text <strong><em>Gravitation</em></strong> (Misner–Thorne–Wheeler, 1973) – nicknamed <em>“the phone book”</em> for its Manhattan-yellow-pages thickness.<br>
</li>
<li>Research timeline
<ol type="1">
<li>1960-s–90-s Black-hole astrophysics &amp; relativistic stars.<br>
</li>
<li>1970-s  Conceptual seeds of gravitational-wave detection (inspired by Joe Weber’s resonant bars).<br>
</li>
<li>1984-2015 Co-founds &amp; steers <strong>LIGO</strong> → first direct wave detection (14 Sep 2015).<br>
</li>
<li>2005-present Science/arts cross-over: <em>Interstellar</em> (exec-producer), poetry-and-painting projects, sci-fi screenplay development.<br>
</li>
</ol></li>
<li><strong>Nobel Prize in Physics 2017</strong> (with Rainer Weiss &amp; Barry Barish) “for decisive contributions to the LIGO detector and the observation of gravitational waves.”</li>
</ul>
<hr>
</section>
<section id="interstellar-2014-science-baked-into-cinema" class="level2">
<h2 class="anchored" data-anchor-id="interstellar-2014-science-baked-into-cinema">Interstellar (2014) — science baked into cinema</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 40%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Production seed</th>
<th>Core scientific constraint</th>
<th>How it appears on-screen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1990s brainstorming between Thorne &amp; producer Linda Obst → “warp-side of the universe” premise</td>
<td><strong>No plot device may violate well-established physics; ‘wild’ elements must at least extrapolate existing theory.</strong></td>
<td>Wormhole near Saturn (valid under GR if exotic matter available); Gargantua black hole rendered via full relativistic ray-tracing.</td>
</tr>
<tr class="even">
<td>Christopher &amp; Jonathan Nolan rewrite Thorne/Obst outline</td>
<td>Preserve constraints, add human drama</td>
<td>Ending deliberately “Kubrick-mysterious”; detailed explanation relegated to Thorne’s tie-in book <strong><em>The Science of Interstellar</em></strong>.</td>
</tr>
</tbody>
</table>
<section id="two-widely-debated-scenes-explained" class="level4">
<h4 class="anchored" data-anchor-id="two-widely-debated-scenes-explained">Two widely debated scenes explained</h4>
<ol type="1">
<li><strong>Miller’s Planet giant wave</strong>
<ul>
<li>Modeled as a <strong>solitary (soliton) wave</strong> – a stable, non-breaking solution to the Korteweg–de Vries equation where non-linearity balances dispersion.<br>
</li>
<li>Wave amplitude ≈ 6× local water depth ⇒ must occur over deep ocean; protagonists stand on a subsurface island (Thorne’s back-story).<br>
</li>
<li>Tides driven by planet’s periodic re-orientation in Gargantua’s extreme gravitational gradient (not a simple “swell”).</li>
</ul></li>
<li><strong>1 h = 7 y time-dilation</strong>
<ul>
<li>Requires orbit at (or just outside) the <strong>innermost stable circular orbit (ISCO)</strong> of an <strong>extremely rapidly spinning (near-maximal Kerr) black hole</strong>.<br>
</li>
<li>Thorne derived an analytic series formula showing dilation factor ≈ (1 – a*)^{-1/3}; solving yields dimensionless spin (a*).<br>
</li>
<li>Spin this high is borderline but not forbidden by GR → challenge met.</li>
</ul></li>
</ol>
</section>
<section id="tessaract-5-d-bulk-travel" class="level4">
<h4 class="anchored" data-anchor-id="tessaract-5-d-bulk-travel">Tessaract &amp; 5-D “bulk travel”</h4>
<ul>
<li>Once Cooper crosses Gargantua’s horizon he is picked up by a 4-D cube spacecraft (tesseract) built by an advanced civilization.<br>
</li>
<li>Craft exits the hole through the higher-dimensional bulk, where Earth lies only a short 5-D distance away → avoids FTL violation in 4-D spacetime.</li>
</ul>
<hr>
</section>
</section>
<section id="wormholes-exotic-matter-time-machines" class="level2">
<h2 class="anchored" data-anchor-id="wormholes-exotic-matter-time-machines">Wormholes, exotic matter &amp; time machines</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th>Key term</th>
<th>Plain-language expansion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Wormhole throat</strong></td>
<td>3-D tunnel linking two distant 4-D regions. Stable only if its walls are <strong>repelled</strong> by negative-pressure, negative-energy <strong>exotic matter</strong>.</td>
</tr>
<tr class="even">
<td><strong>Exotic matter source</strong></td>
<td>In quantum field theory, regions where vacuum energy is <em>lower</em> than normal (Casimir effect between conducting plates). To hold a macroscopic throat open you would need vacuum-fluctuation engineering on planetary scale.</td>
</tr>
<tr class="odd">
<td><strong>Sum-over-histories (Feynman/Gell-Mann–Hartle)</strong></td>
<td>Quantum-mechanical picture where every possible spacetime geometry contributes; allows small probabilities for closed timelike curves ⇒ potential information loss.</td>
</tr>
<tr class="even">
<td><strong>Hawking–Thorne–Preskill bet (1990)</strong></td>
<td><ins>Issue</ins> Does black-hole evaporation destroy information?<br><strong>Hawking + Thorne:</strong> <em>Yes</em> (non-unitary).<br><strong>Preskill:</strong> <em>No</em>.<br>• 2004 Hawking conceded publicly in Dublin, gifting Preskill an encyclopedia “full of information”. Thorne withholds concession, citing viable info-loss within sum-over-histories quantum gravity.</td>
</tr>
</tbody>
</table>
<p><strong>Chronology protection</strong><br>
- Vacuum fluctuations would circulate through a newly created time machine, exponentially blueshift, and <em>likely</em> destroy the wormhole (Hawking “safe for historians” conjecture).<br>
- Final answer requires yet-to-be-completed <strong>quantum gravity</strong>.</p>
<hr>
</section>
<section id="gravitational-waves-ligo-from-phone-book-crazy-to-nobel" class="level2">
<h2 class="anchored" data-anchor-id="gravitational-waves-ligo-from-phone-book-crazy-to-nobel">Gravitational waves &amp; LIGO — from “phone-book crazy” to Nobel</h2>
<section id="conceptual-leap" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-leap">Conceptual leap</h3>
<ol type="1">
<li><strong>Joe Weber (1960s)</strong> – aluminium cylinders with piezoelectric transducers; claimed detections (later unconfirmed).<br>
</li>
<li><strong>Rainer Weiss (1972 MIT memo)</strong> – kilometre-scale <strong>laser interferometer</strong>; identified all noise sources; memo circulated but unpublished.<br>
</li>
<li><strong>Thorne (1973)</strong> in <em>Gravitation</em>: exercise “show this is impractical.” (He later changed mind.)<br>
</li>
<li><strong>Caltech–MIT collaboration (1980s)</strong> – private $2 M seed → NSF joins; Barry Barish leads construction of two 4 km detectors (Hanford WA &amp; Livingston LA).</li>
</ol>
</section>
<section id="technical-translation-of-einsteins-idea" class="level3">
<h3 class="anchored" data-anchor-id="technical-translation-of-einsteins-idea">Technical translation of Einstein’s idea</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 59%">
</colgroup>
<thead>
<tr class="header">
<th>Target signal</th>
<th>Required sensitivity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binary-black-hole merger at 400 Mpc → strain (h10^{-21})</td>
<td>Mirror displacement (ΔL h × 4 km ≈ 4 × 10^{-18},m) ≈ <strong>1/100 of a proton diameter</strong>, <strong>10 million × smaller than atomic spacing</strong>.</td>
</tr>
</tbody>
</table>
<section id="noise-beating-innovations" class="level4">
<h4 class="anchored" data-anchor-id="noise-beating-innovations">Noise-beating innovations</h4>
<ul>
<li><strong>Seismic isolation</strong>: quadruple pendulum suspensions, 10 m vacuum tubes, active feedback.<br>
</li>
<li><strong>Quantum-precision metrology</strong>: squeezed-light injection reduces shot noise below the “standard quantum limit” (circumventing Heisenberg via vacuum-fluctuation sculpting).<br>
</li>
<li><strong>Super-polished 40 kg test-mass mirrors</strong> with nanoradian alignment control.</li>
</ul>
</section>
</section>
<section id="milestone" class="level3">
<h3 class="anchored" data-anchor-id="milestone">Milestone</h3>
<ul>
<li><strong>GW150914</strong> detected 14 Sep 2015; announcement 11 Feb 2016.
<ul>
<li>36 M⊙ + 29 M⊙ → 62 M⊙ remnant (3 M⊙ radiated as gravitational energy).<br>
</li>
<li>7 ms arrival lag between sites matches light-speed travel through Earth.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="relativity-quantum-mechanics-the-incompatibility" class="level2">
<h2 class="anchored" data-anchor-id="relativity-quantum-mechanics-the-incompatibility">Relativity ↔︎ Quantum Mechanics: the incompatibility</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 51%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>General Relativity (GR)</th>
<th>Quantum Mechanics (QM)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Spacetime = smooth classical manifold; curvature sourced by mass-energy.</td>
<td>Fundamental dynamics probabilistic; <strong>unitarity</strong> forbids information loss.</td>
</tr>
<tr class="even">
<td>Predicts singularities (black-hole core, Big Bang) where curvature → ∞.</td>
<td>Fluctuating quantum fields demand discretized/uncertain geometry at Planck scale (~10⁻³⁵ m).</td>
</tr>
</tbody>
</table>
<p><strong>Outstanding goal</strong> – a self-consistent <strong>quantum gravity</strong> theory (string theory &amp; loop-quantum gravity are leading candidates).<br>
- Thorne: <em>“…string/M-theory likely path, but the problem is hard enough to span generations.”</em></p>
<hr>
</section>
<section id="vacuum-fluctuations-the-casimir-effect-mini-glossary" class="level2">
<h2 class="anchored" data-anchor-id="vacuum-fluctuations-the-casimir-effect-mini-glossary">Vacuum fluctuations &amp; the Casimir effect (mini-glossary)</h2>
<ul>
<li><strong>Vacuum fluctuation</strong> – transient “virtual” particle–antiparticle pairs mandated by the uncertainty principle.<br>
</li>
<li><strong>Casimir plates</strong> – two parallel conductors ∼µm apart restrict photon modes between them → lower vacuum energy inside → plates attract. Region exhibits <strong>negative energy density</strong> (prototype exotic matter).<br>
</li>
<li><strong>Quantum-precision measurement</strong> – technique (pioneered for LIGO) that squeezes vacuum noise in one quadrature while amplifying the other, beating standard quantum limits for displacement sensing.</li>
</ul>
<hr>
</section>
<section id="kip-thornes-current-future-creative-projects" class="level2">
<h2 class="anchored" data-anchor-id="kip-thornes-current-future-creative-projects">Kip Thorne’s current &amp; future creative projects</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 32%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Work in progress</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Literary</strong></td>
<td><em>The Warped Side of the Universe</em> – illustrated poetry with painter Lia Halloran (2024).</td>
</tr>
<tr class="even">
<td><strong>Film/TV</strong></td>
<td>Unrevealed sci-fi screenplay begun with Linda Obst &amp; the late Stephen Hawking; may become a novel if film stalls.</td>
</tr>
<tr class="odd">
<td><strong>History of science</strong></td>
<td>Multi-author narrative history of LIGO (draft 6 circulating; anticipated 2027 publication).</td>
</tr>
</tbody>
</table>
<hr>
<section id="quotable-take-aways" class="level3">
<h3 class="anchored" data-anchor-id="quotable-take-aways">Quotable take-aways</h3>
<blockquote class="blockquote">
<p>“If I see farther, it’s because I’ve stood on the shoulders of giants.” – paraphrasing Newton, Thorne emphasizes collaborative science.</p>
</blockquote>
<blockquote class="blockquote">
<p>“Some problems take 50 years. That doesn’t mean they’re impossible — just important.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“LIGO’s Nobel medal really belongs to a thousand people.”</p>
</blockquote>
<hr>
<section id="recommended-entry-points-for-deeper-study" class="level4">
<h4 class="anchored" data-anchor-id="recommended-entry-points-for-deeper-study">Recommended entry points for deeper study</h4>
<ul>
<li><strong><em>The Science of Interstellar</em></strong> (K. Thorne, 2014) – lay-level expansion of the film’s physics.<br>
</li>
<li><strong><em>Black Holes &amp; Time Warps</em></strong> (K. Thorne, 1994) – narrative history of relativistic astrophysics pre-LIGO.<br>
</li>
<li><strong>Caltech’s multimedia “Einstein’s Gravity Playlist”</strong> – video course on gravitational waves &amp; detectors.<br>
</li>
</ul>
</section>
</section>
</section>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Bryan Johnson on Lex Fridman">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bryan Johnson on Lex Fridman
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://www.youtube.com/watch?v=1YbcB6b4A2U">Link to Video</a></p>
<section id="demo-wearing-the-kernel-flow-headset" class="level2">
<h2 class="anchored" data-anchor-id="demo-wearing-the-kernel-flow-headset">1 Demo: wearing the <strong>Kernel Flow</strong> headset</h2>
<ul>
<li><strong>Hardware</strong>: 52 optode “modules,” each containing <strong>1 picosecond-pulsed laser + 6 photodetectors</strong> → ≈ 1 000 independent fNIRS* channels covering the whole cortex.<br>
</li>
<li><strong>Principle</strong>: time-resolved <strong>near-infra-red spectroscopy</strong> measures tiny changes (&lt;1 %) in blood-oxygenation caused by local neuronal firing; photon time-of-flight inversion reconstructs depth-specific activation maps.<br>
</li>
<li><strong>User experience</strong>: surprisingly comfortable; self-adjusting elastomer lattice supports large head sizes; silent; can be donned in &lt;30 s.<br>
</li>
<li><strong>Real-time stream</strong>: Ubuntu 20.04 machine next to Lex records gigabytes of raw photon counts → GPU pipeline → cortical heat-maps at ~ 10 Hz.<br>
</li>
<li><strong>Joke/No-smile task</strong>: live demo shows differential motor-cortex activity when Lex suppresses facial muscles; illustrates sub-second sensitivity.</li>
</ul>
<blockquote class="blockquote">
<p><em>fNIRS = functional Near-Infrared Spectroscopy — non-invasive cousin of fMRI; ~cm spatial, ~100 ms temporal resolution.</em></p>
</blockquote>
<hr>
</section>
<section id="from-toy-to-tool-why-this-matters" class="level2">
<h2 class="anchored" data-anchor-id="from-toy-to-tool-why-this-matters">2 From toy to tool — why this matters</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 41%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="header">
<th>Traditional “biometrics”</th>
<th><strong>Brainstream (Flow/Flux roadmap)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Steps, HR, HRV — single scalar per second</td>
<td>Thousands-dimensional activation vector every 10 ms</td>
</tr>
<tr class="even">
<td>1–2 sensors on wrist</td>
<td>Whole-cortex coverage</td>
</tr>
<tr class="odd">
<td>Ex-situ lab studies</td>
<td><strong>Wear anywhere:</strong> at home, work, therapy, meditation, gaming</td>
</tr>
<tr class="even">
<td>Manual self-report</td>
<td><strong>Passive, objective, self-supervised data</strong></td>
</tr>
</tbody>
</table>
<p>Potential applications Johnson highlights:<br>
1. <strong>Personalised cognitive load manager</strong> (tune meetings, learning blocks, meditation sessions).<br>
2. <strong>Clinical</strong>: closed-loop depression &amp; PTSD therapies; drug-dose optimisation (e.g., ketamine, psychedelics).<br>
3. <strong>Population research</strong>: large-N brain-behaviour datasets analogous to UK-Biobank for genetics.<br>
4. <strong>Human-computer symbiosis</strong>: adaptive UIs that pause podcasts when attention drifts, or rewrite content difficulty live.</p>
<hr>
</section>
<section id="kernels-go-to-market-logic-a-la-drake-equation" class="level2">
<h2 class="anchored" data-anchor-id="kernels-go-to-market-logic-a-la-drake-equation">3 Kernel’s go-to-market logic (a la <strong>Drake equation</strong>)</h2>
<blockquote class="blockquote">
<p>“Our job is <strong>not</strong> to guess one killer app.<br>
It’s to drop the sensor cost × data quality below a threshold that ignites an ecosystem.” — B.J.</p>
</blockquote>
<ul>
<li>Phase 1 (2022-24): sell Flow to research labs &amp; dev studios → seed algos/tools.<br>
</li>
<li>Phase 2 (~2025): consumer variant <strong>Flux</strong> (magnetoencephalography-on-chip) = full-HD brain movie.<br>
</li>
<li>Phase 3: third-party apps discover “the Angry-Birds moment” for BCIs.</li>
</ul>
<hr>
</section>
<section id="neuralink-vs-kernel-two-complements-not-rivals" class="level2">
<h2 class="anchored" data-anchor-id="neuralink-vs-kernel-two-complements-not-rivals">4 Neuralink vs Kernel — two complements, not “rivals”</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 41%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th><strong>Neuralink</strong></th>
<th><strong>Kernel</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Implant?</td>
<td>Yes (invasive micro-electrodes)</td>
<td>No (optical / magnetic)</td>
</tr>
<tr class="even">
<td>Channel count</td>
<td>1 000 spikes at 30 k S/s</td>
<td>1 000 hemodynamic voxels at 10 Hz</td>
</tr>
<tr class="odd">
<td>Spatial patch</td>
<td>mm-scale 4 K circle</td>
<td>Whole-head 1080p blur</td>
</tr>
<tr class="even">
<td>Use-case</td>
<td>Direct motor/sensory prosthesis</td>
<td>Behavioural &amp; cognitive analytics</td>
</tr>
<tr class="odd">
<td>Horizon</td>
<td>FDA 🧠 2028+</td>
<td>Research units shipping now</td>
</tr>
</tbody>
</table>
<p>Johnson’s bet: <em>“Seven-year window where high-resolution non-invasive will ignite developer culture before surgical BCIs become routine.”</em></p>
<hr>
</section>
<section id="zeroth-principle-thinking" class="level2">
<h2 class="anchored" data-anchor-id="zeroth-principle-thinking">5 Zeroth-principle thinking 🔭</h2>
<ul>
<li><strong>First principles</strong> = deduce from system laws (à la Sherlock’s <em>“once you eliminate the impossible…”</em>).<br>
</li>
<li><strong>Zeroth principles</strong> = hunt <em>building blocks</em> we don’t yet see — revolutionary “zeros” (Einsteinian spacetime; AlphaGo’s alien moves).<br>
</li>
<li>Algorithm:
<ol type="1">
<li>Map the <em>known unknowns</em> of today’s tech stack.<br>
</li>
<li>Ask which hidden variables, if measured, would spawn entirely new coordinate systems for society.<br>
</li>
<li>Design scaffolds (Kernel Flow) that lower the cost of discovering such variables.</li>
</ol></li>
</ul>
<hr>
</section>
<section id="personal-physiology-hacks-johnsons-n-1-protocol" class="level2">
<h2 class="anchored" data-anchor-id="personal-physiology-hacks-johnsons-n-1-protocol">6 Personal physiology hacks (Johnson’s n = 1 protocol)</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 38%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Johnson’s routine</th>
<th>Rationale / metrics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Diet</strong></td>
<td>1 meal/day at 08:30 — “Super-Veggie pudding” (broccoli, cauliflower, etc.), “Nutty pudding”, rotating bowl; 20 supplements; vegan.</td>
<td>Long fasting window → resting HR 42 bpm, deep-sleep ↑, HRV ↑.</td>
</tr>
<tr class="even">
<td><strong>Sleep</strong></td>
<td>21:30 lights-off; no calories ≥ 4 h before; Oura ring + EEG band.</td>
<td>Deep-sleep minutes predict next-day impulse control.</td>
</tr>
<tr class="odd">
<td><strong>Biomarkers</strong></td>
<td>200+ labs every 90 days (lipids, DNA-meth clocks, microbiome, NTs).</td>
<td>Remove “conscious Brian” from menu decisions; algorithmic grocery list.</td>
</tr>
<tr class="even">
<td><strong>Movement</strong></td>
<td>Fasted zone-2 cardio &amp; strength daily.</td>
<td>Insulin sensitivity, mood.</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>He compares his “autonomous self-care loop” to <strong>cryptocurrency</strong> smart contracts: encoded rules, minimal human whim.</p>
</blockquote>
<hr>
</section>
<section id="depression-kilimanjaro-the-death-match-with-reality" class="level2">
<h2 class="anchored" data-anchor-id="depression-kilimanjaro-the-death-match-with-reality">7 Depression, Kilimanjaro &amp; the <em>“death-match with reality”</em></h2>
<ul>
<li>2014: mid-divorce, leaving Mormon faith, chronic depression. Joined charity trek in Tanzania.<br>
</li>
<li>Summit day: viral gastroenteritis + altitude sickness, SaO₂ ≈ 50 %. Guide’s mantra: <strong>“Look up → breathe → step.”</strong><br>
</li>
<li>Personal reset: descent ≈ rebirth → decision to sell Braintree/Venmo (2013) and fund Kernel ($53 M seed).</li>
</ul>
<hr>
</section>
<section id="brains-money-freedom" class="level2">
<h2 class="anchored" data-anchor-id="brains-money-freedom">8 Brains ↔︎ Money ↔︎ Freedom</h2>
<ul>
<li>Payments history: door-to-door credit-card salesman → founded <strong>Braintree</strong> (2007) → acquired <strong>Venmo</strong> (2012) → PayPal buyout $800 M.<br>
</li>
<li>Crypto view: decentralised ledgers offer the same “autonomous accounting” we now need for brain data permissions (transparency + user control).<br>
</li>
<li>Privacy model: Kernel app lets wearer own/delete streams; future smart-contracts will grant time-bound, purpose-bound “brain-scope” to apps (akin to Android permissions).</li>
</ul>
<hr>
</section>
<section id="psychedelics-closed-loop-psychiatry" class="level2">
<h2 class="anchored" data-anchor-id="psychedelics-closed-loop-psychiatry">9 Psychedelics &amp; closed-loop psychiatry</h2>
<ul>
<li>Today: subjective narratives dominate (“trip reports”).<br>
</li>
<li>Future: Flow baseline → dose → post-integration scans → ML models quantify which molecule × dose × context remits which network (DMN hyper-connectivity, amygdala hyper-re-weighting, etc.).<br>
</li>
<li>Parallel: cardiology wouldn’t hand out statins without cholesterol numbers; psych should stop handing out SSRIs without neural numbers.</li>
</ul>
<hr>
</section>
<section id="advice-to-young-minds" class="level2">
<h2 class="anchored" data-anchor-id="advice-to-young-minds">10 Advice to young minds</h2>
<blockquote class="blockquote">
<ol type="1">
<li><strong>Gather advice as mirrors</strong>, not blueprints; decode each speaker’s <em>assumption stack</em>.<br>
</li>
<li>Optimise for <strong>projects whose impact is still obvious in 250 years</strong>; money is fuel, not the game.<br>
</li>
<li>Train empathy + zeroth-principle curiosity: “Expect most conscious thoughts to be at least partially wrong on landing — examine &amp; iterate.”</li>
</ol>
</blockquote>
<hr>
</section>
<section id="meaning-of-life-johnsons-current-stack" class="level2">
<h2 class="anchored" data-anchor-id="meaning-of-life-johnsons-current-stack">11 Meaning of life — Johnson’s current stack</h2>
<ol type="1">
<li><strong>Infinite games</strong>: ensure the game of intelligence continues.<br>
</li>
<li><strong>Goal alignment</strong>: negotiation among billions of biological &amp; synthetic agents.<br>
</li>
<li><strong>Exploration</strong>: use ever-cheaper designed intelligence to poke outside current reality’s “sandbox rules.”</li>
</ol>
<blockquote class="blockquote">
<p>“We may be the first generation that can genuinely <strong>upgrade consciousness</strong> beyond anything we can verbalise today… that aspiration alone is enough.”</p>
</blockquote>
<hr>
<section id="further-reading-listening" class="level3">
<h3 class="anchored" data-anchor-id="further-reading-listening">Further reading / listening</h3>
<ul>
<li><em>The Science of Brain Interfaces</em> — forthcoming Kernel white-paper series.<br>
</li>
<li>J. Horgan, “Spectroscopy of Thought” (<em>SciAm</em>, 2020) for fNIRS primer.<br>
</li>
<li>B. Johnson, blog post “Zeroth-Principles Thinking” (2020).<br>
</li>
<li>Lex Fridman Podcast #181 (full 2 h video).</li>
</ul>
</section>
</section>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Andrew Huberman on Theo Von">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Andrew Huberman on Theo Von
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://www.youtube.com/watch?v=gxHktBHVY5I">Link to Video</a></p>
<section id="podcastings-rise" class="level3">
<h3 class="anchored" data-anchor-id="podcastings-rise">Podcasting’s Rise</h3>
<ul>
<li><strong>Authenticity wins</strong> – shows launched in closets, bedrooms, skate-shop back rooms, so listeners sensed zero corporate filter.<br>
</li>
<li><strong>Long-form = modern campfire</strong> – multi-hour space lets comedians, scientists and musicians explore nuance mainstream outlets cut.<br>
</li>
<li><strong>Early-stage magic</strong> – when money and metrics aren’t dominant, creators operate in the “pre-conscious” zone Rick Rubin praises; audiences feel the difference.<br>
</li>
<li><strong>Ad tolerance rule</strong> – audiences accept ads if hosts genuinely use the products; trust stays intact.</li>
</ul>
<hr>
</section>
<section id="dopamine-101" class="level3">
<h3 class="anchored" data-anchor-id="dopamine-101">Dopamine 101</h3>
<ul>
<li>Dopamine is about <em>wanting</em> and <strong>anticipatory motivation</strong>, not the actual reward.<br>
</li>
<li><strong>Reward-prediction error</strong> determines mood afterward:
<ul>
<li>Better than expected → extended high.<br>
</li>
<li>Worse than expected → crash below baseline.<br>
</li>
</ul></li>
<li>Rapid, high-magnitude spikes (meth, gambling, extreme porn) produce deep troughs, driving compulsive reuse.<br>
</li>
<li>Healthy strategy: create slower, effort-based climbs (learning, training, creative work) to avoid the crash.</li>
</ul>
<hr>
</section>
<section id="pornography-intimacy-sexual-function" class="level3">
<h3 class="anchored" data-anchor-id="pornography-intimacy-sexual-function">Pornography, Intimacy &amp; Sexual Function</h3>
<ul>
<li>Online porn is the “methamphetamine” version of sex stimuli: intensity and novelty raise dopamine thresholds, making real intimacy feel flat.<br>
</li>
<li>Excess porn in adolescence rewires expectations during a period of peak neural plasticity (≈0-25 yrs).<br>
</li>
<li>Practical fixes:
<ul>
<li>Abstinence / “dopamine fast” periods to reset baseline.<br>
</li>
<li>Slow-build intimacy – multiple non-intercourse sessions before sex, emphasize communication and breathing to stay parasympathetic.<br>
</li>
<li>Treat erectile anxiety with openness, not immediate pharmacology; Tadalafil (2.5-5 mg) is helpful later in life, not as an early crutch.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="circadian-lifestyle-protocols" class="level3">
<h3 class="anchored" data-anchor-id="circadian-lifestyle-protocols">Circadian &amp; Lifestyle Protocols</h3>
<ul>
<li><strong>Morning anchors</strong>: sunlight to eyes, hydration, caffeine after 90 min, brief movement.<br>
</li>
<li><strong>Evening wind-down</strong>: dim screens or red-lens glasses, long exhale breathing, reduce stimulants.<br>
</li>
<li>Identify personal chronotype by testing bed/wake times for three days each.<br>
</li>
<li>Non-sleep deep rest (NSDR / yoga nidra) for 20-30 min restores dopamine ~60 %.</li>
</ul>
<hr>
</section>
<section id="views-on-science-pharma-replication" class="level3">
<h3 class="anchored" data-anchor-id="views-on-science-pharma-replication">Views on Science, Pharma &amp; Replication</h3>
<ul>
<li>Most scientists pursue truth, but career incentives can bias which data get published or repeated.<br>
</li>
<li>Big-pharma profit model favors repurposing old drugs under patent rather than creating new molecules.<br>
</li>
<li>Wakefield fraud tainted vaccine debate; Huberman calls for <strong>open, well-designed replication studies</strong> on all public-health interventions.</li>
</ul>
<hr>
</section>
<section id="psychedelics-mental-health" class="level3">
<h3 class="anchored" data-anchor-id="psychedelics-mental-health">Psychedelics &amp; Mental Health</h3>
<ul>
<li>Ibogaine + DMT protocol in veterans shows striking PTSD and addiction relief; Stanford’s Nolan Williams is imaging associated brain changes.<br>
</li>
<li>Huberman personally finds clinically guided MDMA and psilocybin transformative; stresses legality and expert supervision.</li>
</ul>
<hr>
</section>
<section id="faith-personal-practice" class="level3">
<h3 class="anchored" data-anchor-id="faith-personal-practice">Faith &amp; Personal Practice</h3>
<ul>
<li>Both hosts pray daily; Huberman reconciles faith with science by noting that human perception covers only a slice of reality’s spectrum.<br>
</li>
<li>Prayer provides grounding, reflection, and a sense of “agency as receptor” for creative ideas.</li>
</ul>
<hr>
</section>
<section id="miscellaneous-nuggets" class="level3">
<h3 class="anchored" data-anchor-id="miscellaneous-nuggets">Miscellaneous Nuggets</h3>
<ul>
<li>Finger-length ratio research: larger ring-to-index difference linked to higher prenatal testosterone; exaggerated in gay men.<br>
</li>
<li>Lesbians as “relationship coaches” – Huberman credits platonic lesbian friends for blunt, invaluable dating feedback.<br>
</li>
<li>Caffeine intake: Huberman consumes ~800 mg/day via yerba maté; warns against high-dose nicotine except low-milligram pouches early in day.<br>
</li>
<li>“Addiction = progressive narrowing of things that bring pleasure.” Aim for a wide palette of rewarding activities to stay mentally healthy.</li>
</ul>
</section>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Thomas DeLauer on Judd Lienhard">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Thomas DeLauer on Judd Lienhard
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://www.youtube.com/watch?v=7U5ErqPiZG8">Link to Video</a></p>
<section id="background-context" class="level3">
<h3 class="anchored" data-anchor-id="background-context">1. Background &amp; Context</h3>
<ul>
<li><strong>Thomas DeLauer</strong> – former 300-lb corporate exec ➜ lost 100 lb, reversed debilitating IBS, built a 4 M-subscriber channel on nutrition, recovery and exercise science.<br>
</li>
<li>Runs experiments on himself and publicly <strong>updates/ corrects</strong> advice when new data overturn earlier takes.<br>
</li>
<li>Core mission: translate dense biochemistry into <em>actionable</em> habits for ordinary people.</li>
</ul>
<hr>
</section>
<section id="nutrition-myths-debunked" class="level3">
<h3 class="anchored" data-anchor-id="nutrition-myths-debunked">2. Nutrition Myths Debunked</h3>
<p><em>Protein</em><br>
- “You can only absorb 30 g per meal.” → Human subjects assimilated <strong>100 g</strong> whey just as well as 25 g (labeled-leucine study, <em>Cell Metabolism</em> 2023). The surplus fuels protein synthesis for <strong>longer</strong>, not “wasted.”<br>
- “Anabolic window = 30 min post-lift.” → MPS is still climbing 6 h post-workout, peaks ~24 h.<br>
- “High protein hurts kidneys.” → No evidence in healthy kidneys; contraindicated only in late-stage disease. Longevity debate still open.</p>
<p><em>Meal frequency &amp; snacking</em><br>
- Frequent eating was popularized by bodybuilding; it <strong>mutes glucagon</strong>, never lets insulin fully drop and stalls fat mobilization.<br>
- DeLauer’s rule: <strong>clear, defined gaps</strong> between feedings—no Skittles “in the valley.”</p>
<p><em>Cortisol fear</em><br>
- Transient spikes (fasting, workouts) aid lipolysis and alertness; demonizing cortisol keeps trainees over-fed and under-trained.</p>
<p><em>Low-calorie grind</em><br>
- Chronic 1–200 kcal deficits backfire: metabolism adapts, muscle is lost, “cheat-meal” rebounds get stored as fat at a slower BMR.<br>
- <strong>High-energy flux</strong> (eat more + move more) outperforms <strong>eat less + move less</strong>: you burn extra calories just mobilizing larger energy throughput.</p>
<hr>
</section>
<section id="core-nutrition-principles" class="level3">
<h3 class="anchored" data-anchor-id="core-nutrition-principles">3. Core Nutrition Principles</h3>
<ol type="1">
<li><strong>Anchor every meal in protein</strong>
<ul>
<li>Target ≈ 1–1.2 g per lb <em>lean mass</em> (or per lb desired weight) to cover muscle, connective tissue, immune and enzyme needs.<br>
</li>
</ul></li>
<li><strong>Strategic fasting / calorie cycling</strong>
<ul>
<li>Large deficit days or 24-h fasts are easier mentally than tiny daily cuts; maintain near-maintenance on other days.<br>
</li>
</ul></li>
<li><strong>Whole-food quality &gt; calorie math</strong>
<ul>
<li>Micronutrients, fiber, resistant starch and satiety from foods like sweet potatoes, berries, aged cheese, lean beef, fatty fish.<br>
</li>
</ul></li>
<li><strong>Randomness &amp; adaptability</strong>
<ul>
<li>Rotate carb sources, caloric loads and even unusual foods to broaden the microbiome and keep hormones responsive.</li>
</ul></li>
</ol>
<hr>
</section>
<section id="fasting-valley-physiology" class="level3">
<h3 class="anchored" data-anchor-id="fasting-valley-physiology">4. Fasting &amp; “Valley” Physiology</h3>
<ul>
<li>Insulin falls ➜ glucagon rises ➜ hormone-sensitive lipase releases stored fat.<br>
</li>
<li>Benefits: gut motility (“rest-and-digest” finally engages), sharper cognition (ketones + evolutionary alertness), practical calorie control.<br>
</li>
<li>Safe even for extended periods <strong>if hydration and electrolytes are maintained</strong>.</li>
</ul>
<hr>
</section>
<section id="training-philosophy-rqi" class="level3">
<h3 class="anchored" data-anchor-id="training-philosophy-rqi">5. Training Philosophy (RQI)</h3>
<ol type="1">
<li><strong>Randomness / Adaptability</strong> – expose body to novel patterns, loads, planes; improvise when joints or recovery dictate.<br>
</li>
<li><strong>Quality</strong> – prioritize mind-muscle connection, controlled eccentrics, isometrics, full-range mechanics over arbitrary volume.<br>
</li>
<li><strong>Intuition</strong> – plan tomorrow’s session each night, but listen to fatigue, sleep and mood signals; shift goals to performance and feeling, not vanity metrics.</li>
</ol>
<hr>
</section>
<section id="supplement-short-list" class="level3">
<h3 class="anchored" data-anchor-id="supplement-short-list">6. Supplement Short-List</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Supplement</th>
<th>Core Reason &amp; Dose Thumb-Rules</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Whey protein isolate</td>
<td>Convenient leucine bolus; easy pre-grocery hunger control.</td>
</tr>
<tr class="even">
<td>Creatine monohydrate (5 g/day)</td>
<td>Strength, power, neuro-protective; universally safe.</td>
</tr>
<tr class="odd">
<td><strong>Taurine</strong> (4-6 g/day)</td>
<td>Antioxidant, membrane stabilizer, intra-workout recovery.</td>
</tr>
<tr class="even">
<td><strong>Betaine / TMG</strong> (2-3 g/day)</td>
<td>Methyl-donor; research shows concurrent muscle gain &amp; fat loss, supports homocysteine control.</td>
</tr>
<tr class="odd">
<td>L-Theanine (200-400 mg evening)</td>
<td>Parasympathetic shift, smooths caffeine, improves sleep quality.</td>
</tr>
</tbody>
</table>
<p><em>Watch-outs</em>:<br>
- <strong>Ashwagandha</strong> may blunt emotional highs for some; long wash-out times reported.<br>
- <strong>Methylene blue</strong>—emerging nootropic/ mitochondrial aid, but still experimental.</p>
<hr>
</section>
<section id="pantry-fridge-blueprint" class="level3">
<h3 class="anchored" data-anchor-id="pantry-fridge-blueprint">7. Pantry / Fridge Blueprint</h3>
<ul>
<li>Blueberries<br>
</li>
<li>93 % lean ground beef<br>
</li>
<li>Sardines / mackerel (omega-3 + vitamin D &amp; calcium)<br>
</li>
<li>Free-range eggs<br>
</li>
<li>A2 or raw milk (lower BCM-7 inflammation)<br>
</li>
<li>Sweet &amp; regular potatoes<br>
</li>
<li>Broccoli sprouts (sulforaphane, DIM)<br>
</li>
<li>Aged cheese (pecorino, cheddar, parmesan)<br>
</li>
<li>Macadamia nuts<br>
</li>
<li>Quality coffee or green tea</li>
</ul>
<p><strong>Why</strong>: maximal nutrient density, favorable fatty-acid and amino profiles, minimal processing.</p>
<hr>
</section>
<section id="ingredients-to-purge" class="level3">
<h3 class="anchored" data-anchor-id="ingredients-to-purge">8. Ingredients to Purge</h3>
<ol type="1">
<li><strong>Polysorbate-80/-65/-20</strong> – lab-grade emulsifier that perforates cell membranes; used experimentally to induce gut inflammation.<br>
</li>
<li><strong>Petroleum-based dyes</strong> (Red 40, Yellow 5/6, etc.) – behavioral effects in kids; unnecessary when beet or spirulina coloring exists.<br>
</li>
<li>Chronic ultra-processed snacks that merge sugar, refined grain, seed-oil and high emulsifier loads.</li>
</ol>
<hr>
</section>
<section id="mindset-discipline-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="mindset-discipline-takeaways">9. Mindset &amp; Discipline Takeaways</h3>
<ul>
<li><strong>Purpose-driven fitness</strong> – after fatherhood Thomas’ KPI shifted from abs to energy &amp; patience for family; physique improvements followed.<br>
</li>
<li><strong>Intention beats goal</strong> – set daily intentions (direction) instead of binary goals that breed dopamine crashes.<br>
</li>
<li><strong>Plan nightly, live daily</strong> – outline food, training and meetings before bed; frees cognitive load for in-moment intuition.<br>
</li>
<li><strong>Community matters</strong> – progress accelerates when tied to a team, mission or service larger than self.<br>
</li>
<li><strong>Accept the coping element</strong> – high achievers often channel trauma into training; use it, don’t impose it on family.</li>
</ul>
<hr>
</section>
<section id="entrepreneurship-risk" class="level3">
<h3 class="anchored" data-anchor-id="entrepreneurship-risk">10. Entrepreneurship &amp; Risk</h3>
<ul>
<li>Progress <strong>always involves risk</strong>: “You can’t steal second with your foot on first.”<br>
</li>
<li>DeLauer left high-pay corporate recruiting to solve his own IBS &amp; obesity, then monetized the <em>skill of articulating complex science</em>.<br>
</li>
<li>Tactical advice: start side-content while employed, prove value, then leap—own your schedule (and bathroom breaks).</li>
</ul>
</section>
</div>
</div>
</div>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/trungtphan/status/1925643955787423946?s=46">Apple reacts to OpenAI’s new AI device</a></li>
<li><a href="https://x.com/AutismCapital/status/1925683628589064682">ASMR is the most searched term on YouTube</a></li>
<li><a href="https://x.com/StartupArchive_/status/1926244088170320189">Peter Thiel’s advice to his younger self</a></li>
<li><a href="https://x.com/unusual_whales/status/1925913985007648932">No one actually eats INSIDE restaurants anymore</a></li>
<li><a href="https://x.com/george__mack/status/1924571262472560852?s=46">Being vague creates anxiety</a></li>
<li><a href="https://x.com/fitfounder/status/1927387176360137182?s=46">Beware of supplement scans on amazon</a></li>
<li><a href="https://x.com/nikitabier/status/1926400125007458790?s=46">Guys being dudes</a></li>
<li><a href="https://x.com/navalismhq/status/1928968738336026894?s=46">Meetings</a></li>
<li><a href="https://x.com/david_perell/status/1928591346182332754?s=46">Meetings, still the worst</a></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2025-06-01-weekend-reads/</guid>
  <pubDate>Sun, 01 Jun 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-06-01-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>AI Manager &gt; People Manager</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-05-24-agent-manager/</link>
  <description><![CDATA[ 





<section id="tldr" class="level3">
<h3 class="anchored" data-anchor-id="tldr">TL;DR</h3>
<p>Being able to manage armies of AI, in the form of agents that can perform tasks autonomously on their own, will enable more leverage than ever before. When making choices about your career, this should always be top of mind. When in doubt, choose managing AI over managing people. Doing both is better, but one requires permission, while the other does not. Anyone can start managing AI today, so why haven’t you started already?</p>
</section>
<section id="ai-layoffs-have-started" class="level3">
<h3 class="anchored" data-anchor-id="ai-layoffs-have-started">AI Layoffs Have Started</h3>
<p>Would you rather have your company spend 10x less or achieve 10x more? These are the two ends of the AI productivity spectrum. Right now senior leaders seem to be on the spend 10x less side, which is a bummer. The fastest way to grow earnings it seems is by cutting costs. They want to use AI tools that allow them to get the job done with less resources. This might make sense in a cash cow business with few competitors, but that’s rare and puts your business at risk of AI powered disruption. As Jeff Bezos used to say, “your margin is my opportunity”.</p>
<p>Spending 10x less is a known quantity, CFO’s can show how this impacts the bottom line and rewards shareholders. So of the two choices it’s the lower hanging fruit. Choosing to be 10x more productive with the same resources you have available is less certain. Will it lead to 10x sales? Maybe, but maybe not. This combined with economic uncertainty makes the choice easy for the CEO. They think they can make cuts AND achieve more, all powered by AI. Can you have your cake and eat it too? No one knows just yet.</p>
<p>We are starting to see less hiring in the tech space, even layoffs. When people leave teams, no one hires their back fill. That was the first wave of “silent layoffs”, now there are “loud layoffs” with thousands getting let go at major companies. This could be the start of a bigger trend. The classic tech era depictions on the HBO show “Silicon Valley” are now probably dead. The golden age of being a software developer are done. For decades, life was good if you had a rare set of skills that the world had an undying need for (writing code), but now AI can write the code. So the prickly coder who kept your companies core systems running is going from a necessary pain to one that can be replaced with AI powered tools. Specifically agentic AI systems that can do work on their own much like a person.</p>
<p>They say 2025 is the year of the AI agents, which you can also rephrase as the year of “non-human labor”. That is both terrifying and exciting. It’s only terrifying if you don’t change anything about your life, and very exciting if you know how to ride the wave. Let’s dig in.</p>
</section>
<section id="forms-of-leverage" class="level3">
<h3 class="anchored" data-anchor-id="forms-of-leverage">Forms of Leverage</h3>
<p>Naval Ravikant states there are three types of leverage.</p>
<ol type="1">
<li><strong>Labor</strong>: people working for you</li>
<li><strong>Capital</strong>: using money to build things</li>
<li><strong>Permissionless</strong>: code and media that works while you sleep</li>
</ol>
<p>Labor is the oldest form of leverage with the greatest prestige, capital has been the most popular in recent decades, but permissionless leverage is the hot new thing that is getting turbocharged by AI.</p>
<p>Think about how companies got off in the ground in the last decade. It was common to go raise a bunch of money around an idea, then hire a bunch of people to go build the idea, then use what you built (often through code) to make a profit. That’s how the companies got the most amount of leverage in the least amount of time. Just like Tony Montana: first you get the money, then you get the labor, then you get the profit. It’s a model that works, but one that requires permission. People have to agree to give you money, or agree to work with you.</p>
<p>In recent years this model was disrupted partly by people who are experts at either code or media. Joe Rogan makes tens of millions every year through his podcast, which at most is probably operated by 3-5 people. Instagram sold to Facebook for one billion with only a dozen employees. These people did not need permission to start a podcast or go build a viral app. They were using forms of permissionless leverage.</p>
<p>Permissionless leverage is now becoming orders of magnitude more important with the power of AI. AI is removing the need for the first two forms of leverage, labor and capital. Before you needed money to hire a team, but now AI is your team in the form of agents. This means a team of one with a bootstrapped budget can have the same impact as large companies. But for this to happen you need agents AND agency.</p>
</section>
<section id="ai-agent-agency" class="level3">
<h3 class="anchored" data-anchor-id="ai-agent-agency">AI Agent = Agency</h3>
<p>When AI agents can start doing tasks similar to a human, what’s left for humans to do?</p>
<p>The most important skill to have in this new AI future is proactively taking action, also known as having a <a href="https://www.highagency.com/">high degree of agency</a>. Being a high agency person means you get stuff done. No one has to tell you what to do. You are proactively doing things.</p>
<p>Having access to AI agents that can do human work for a few bucks now allows you to do anything you want. The only problem now is taking the agency to go out and do it. Have an idea for a company? Now you can deploy agents to get it off the ground. They will quickly be able to do most things you’d hire a human for.</p>
<ul>
<li>Build the product (app or service)</li>
<li>Track down potential customers to purchase the product, even sell to them</li>
<li>Answer support related questions from customers</li>
<li>Analyze the finances and recommend what market to expand into next</li>
</ul>
<p>People used to do these jobs, now agents are coming to do them. They will be used by people who have high agency, folks who go out and make a dent in the world instead of being told what to do. If your workday is driven by others telling you what to do instead of figuring out the most important thing to work on yourself. You might be in trouble. What’s stopping your boss from telling an AI agent to start doing that work instead of you? They give the same instructions to the agent, and it works 24/7. If you think about it from their point of view, it’s a no brainer. They’re going to choose the agent over a human. Having high agency means you think for yourself and proactively make choices that help your company. This might mean doing the opposite of what your boss asks you to do instead of being a yes man. If it helps the company in the end, you are called a maverick instead of insubordinate.</p>
</section>
<section id="future-career-paths" class="level3">
<h3 class="anchored" data-anchor-id="future-career-paths">Future Career Paths</h3>
<p>Career paths in a post AI agent world will never be the same again. Historically an ambitious career path might have looked like this.</p>
<ol type="1">
<li><strong>Intern</strong>: You don’t know anything, but are there to learn and try not to slow the team down too much. Your contribution to the company is gaining knowledge about how work gets done, not in completing the work itself.</li>
<li><strong>Junior Employee</strong>: You are fresh out of school and ready to kick butt. You get the lowest level work that needs to get done, but doing it well grows your reputation for doing good work. Which allows you to work on more interesting things.</li>
<li><strong>Senior Employee</strong>: You have gotten so good at your job that now your boss wants you coming up with fresh ideas and running new initiatives. You now have more freedom to choose what you work on and how you get it done because you’ve proven to be reliable. People can count on you.</li>
<li><strong>People Manager</strong>: Congrats, you’ve kicked so much butt at the senior level that you are now in charge of your own team! Now you are really calling the shots and providing the direction for your employees to run towards. The individual contributor work you did is now out the window. People rely on you to make decisions, not to output work items.</li>
<li><strong>Senior Management</strong>: You’ve proved that you can run successful teams, and the top dogs think you have real potential so they move you up to the big leagues. Now you are looking over teams of teams, which is a whole other level of decision making and judgement. Now you are in charge of the long term strategic vision of the organization. Everything is long term and at a 30,000 ft view. The days of tiny details are over for you, you simply don’t have the time for it.</li>
<li><strong>C-Suite</strong>: The final stop on a lifelong career. The highest summit for which to have impact. Single decisions made by you now impact thousands of employees and even shape financial markets. Shareholders are relying on you to make the right decisions to impossible problems.</li>
</ol>
<p>If you were good at your job and had leadership potential, the next logical step was to rise to the next level. Normally the act of making progress leads to happiness in life. So making progress on this career ladder has the <em>potential</em> to make you happy. Do you see how each new level of the ladder gives you more access to labor and capital leverage? To rise to a new level of labor and capital leverage, someone at a higher level has to give the green light. You can only move one level at a time. Unless you start your own thing. No one goes from intern to a senior manager overnight at a large company.</p>
<p>What happens when AI agents come into the picture? How does this career ladder change? An army of labor is now accessible starting at the intern level, with the same level of access as the C-Suite. These agents don’t take breaks. They start off at a few bucks a month and scaling them might cost thousands, not tens of thousands like a human. <strong>I think corporate careers will start to turn into the career paths similar to musicians and athletes.</strong> Where the better the individual is, the greater the stage for them to do what they do best.</p>
<p>Let’s take Taylor Swift as an example. Taylor Swift came onto the scene over 15 years ago back when I was in high school. Since then what she does has not changed much. She still writes songs, she still performs in front of fans, and hopefully soon will stop making breakup songs once her and Travis Kelce settle down and make some rugrats. What has changed is the level at which she does it. Her most recent tour, the Eras Tour, made over a billion dollars within a year. That’s insane. At no point in her career did a music exec say “you’re so good at your job, we’re going to promote you to running the record label or managing the careers of other bands”. Instead she was given every resource imaginable to do what she does best at the next highest level. Over the past 15 years she has continued to level up. Doing bigger and better shows until now becoming the biggest artist in the world.</p>
<p>The same goes for athletes like my main man Patrick Mahomes. They start out as peewee football players like in <a href="https://www.imdb.com/title/tt0110364/">“The Little Giants”</a> and step by step the game gets more competitive, the crowds get bigger, and the money starts to roll in. Mahomes has been playing the same game his entire life, it’s just the stage he performs on is now the biggest in the world.</p>
<p>I believe people in the corporate world will do something similar. The best person in the world at something will now be able to do it for everyone else around the world. Similar to how everyone listens to Taylor Swift (if you say you don’t you’re lying) or watches Patrick Mahomes every Sunday (either hate watching or as a fan). So instead of being the best at your company and rising through the ranks to gain more leverage, I think now you can skip to the final level sooner and leverage an army of AI agents to help maximize what you do best not just for your company but for everyone in the world who would benefit from your expertise.</p>
<p>What I’m unsure about in this new age of infinite leverage is how the best in the world will do their work. Will they still be a part of large companies, or will they have their own company? For example let’s take the worlds best design expert, Jony Ive. He worked at Apple for 27 years. Then he started his own design firm called LoveFrom in 2019. Then created a new AI product company called io. Recently <a href="https://x.com/sama/status/1925242282523103408">OpenAI acquired io</a> and now he will presumably work at OpenAI for the next few years. Jony is also a man in his late 50s, so maybe he’s still in the paradigm of the pre-AI work world even though he works on AI.</p>
<p>Maybe we’ll dig deeper into the “gig economy”. Where someone might come to a company for a “tour of duty”, work on a project for a few years, then move on. The human will use AI agents to scale up a new project, then let the agents continue to manage it after they leave. Going from zero to one on something will take human effort and AI, but keeping a developed project afloat might only take AI. Sometimes I fantasize about “hacker guilds” or collectives of people that are hired as a group to go work on something for a set time. Instead of hiring a standard consulting firm or individual people, you hire a packaged group who already work well together and can kick butt from day one. Kind of like the military with special operations units. Hiring the seal team six equivalent of coders has 100x more leverage than hiring a hodgepodge of random big tech coders or Stanford grads.</p>
<p>Something I’ve learned over the years in corporate america is that companies do not love you, and will not miss you when you’re gone. People who work with you might miss you, but everything eventually comes to an end in all aspects of life. You are not indispensable and you probably can be replaced. That doesn’t mean you shouldn’t be loyal to one company for many years. It just means not to attach too much of your identity to any one thing in life.</p>
<p>We’ll have to see how this plays out in the next few years. What I know for certain is that personal branding is going to rise to a whole new level. As AI agents give more people leverage, their impact can rise faster than it can within a single company. So having a strong personal brand amplified by superintelligence will be essential. If you aren’t working on your brand today, start now. The best time to plant a tree was 20 years ago, the next best time is today.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>We are quickly coming into a new world of infinite leverage. One where the only bottleneck is getting off your butt and taking action. Successful careers will no longer be measured in how much money you raised or how many people work for you, but instead in how much value you provide the world. Being able to work with and even directly manage people will still be important, but it will not be the biggest force multiplier anymore. Being able to leverage and manage AI will. Get started now.</p>
<p>Shameless plug…Did you enjoy this post? If so, sign up to never miss a post via email on the <a href="https://mftokic.github.io/">homepage</a>.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>career</category>
  <guid>https://mftokic.github.io/posts/2025-05-24-agent-manager/</guid>
  <pubDate>Sat, 24 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-05-24-agent-manager/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Weekend Reads (5/23/25)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-05-23-weekend-reads/</link>
  <description><![CDATA[ 





<section id="articles" class="level2">
<h2 class="anchored" data-anchor-id="articles">Articles</h2>
<section id="the-day-you-became-a-better-writer-by-scott-adams" class="level3">
<h3 class="anchored" data-anchor-id="the-day-you-became-a-better-writer-by-scott-adams"><a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/06/the_day_you_bec.html">The Day You Became A Better Writer By Scott Adams</a></h3>
<ul>
<li>Removing fluff and keeping your writing simple is key.</li>
</ul>
</section>
<section id="openai-rolls-out-codex-an-automated-coding-agent" class="level3">
<h3 class="anchored" data-anchor-id="openai-rolls-out-codex-an-automated-coding-agent"><a href="https://openai.com/index/introducing-codex/">OpenAI Rolls Out Codex, An Automated Coding Agent</a></h3>
<ul>
<li>This agent runs autonomously in the cloud to build many new software features in parallel.</li>
<li>For the longest time, I’ve been waiting for LLMs to get so good they can port my forecasting package, <a href="https://microsoft.github.io/finnts/">finnts</a>, from R to Python. I think now I might be able to get that work started. Exciting stuff!</li>
</ul>
</section>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<section id="dr.-rhonda-patrick-on-the-dr.-hyman-show" class="level3">
<h3 class="anchored" data-anchor-id="dr.-rhonda-patrick-on-the-dr.-hyman-show"><a href="https://www.youtube.com/watch?v=AH6EklgUbiM">Dr.&nbsp;Rhonda Patrick on the Dr.&nbsp;Hyman Show</a></h3>
<ul>
<li><strong>Vitamin D</strong>
<ul>
<li><strong>What it does</strong>: Acts like a hormone, flipping 200+ genes for immune function, mood, and bone strength.</li>
<li><strong>Problem</strong>: Indoor living leaves ~40 % of adults short.</li>
<li><strong>Fix</strong>: Supplement 2 000–4 000 IU of vitamin D₃ daily; pair with vitamin K₂ (≈ 100 µg) so calcium goes to bones, not arteries.</li>
</ul></li>
<li><strong>Omega 3</strong>
<ul>
<li><strong>Why care</strong>: Higher blood omega-3 can add years to life, cut triglycerides, and calm inflammation.</li>
<li><strong>Targets</strong>: 1000–2000 mg EPA + DHA daily from fatty fish or purified fish-/algal-oil capsules.</li>
</ul></li>
<li><strong>Magnesium</strong>
<ul>
<li><strong>Roles</strong>: Needed for 300+ enzymes, ATP energy, nerve balance, vitamin D activation.</li>
<li><strong>Shortfall</strong>: Nearly half the population under-consumes it.</li>
<li><strong>Dose</strong>: 200–400 mg nightly (glycinate, citrate, or malate). Bonus: deeper sleep, fewer cramps, steadier blood pressure.</li>
</ul></li>
<li><strong>Triage Theory</strong>
<ul>
<li>Minor shortages get “triaged” to urgent tasks (e.g., keeping blood clotting) while long-term maintenance (DNA repair, artery upkeep) is skipped. You feel fine today but sow seeds of cancer, heart disease, or dementia decades later.</li>
<li><strong>Solution</strong>: keep every micronutrient in the green zone, not just “barely adequate.”</li>
</ul></li>
<li><strong>Multivitamins</strong>
<ul>
<li>Over 90 % of people miss at least one essential nutrient from food. A quality multivitamin/mineral fills common gaps safely and cheaply. Urine color doesn’t equal wasted value; it simply shows water-soluble B-vitamins passing through.</li>
</ul></li>
<li><strong>Personalized Nutrition</strong>
<ul>
<li>Variants in genes like MTHFR (folate), vitamin D receptors, or magnesium transporters can raise your optimal intake. Simple DNA tests plus blood work reveal whether you need more of certain B-vitamins, choline, or others. One-size-fits-all dosing belongs in the last century.</li>
</ul></li>
<li><strong>Nutrient Synergy</strong>
<ul>
<li><strong>Magnesium + Vitamin D</strong>: Mg activates D; D can’t perform without it.</li>
<li><strong>Vitamin D + K2</strong>: D boosts calcium absorption; K2 directs calcium to bones.</li>
<li><strong>Food First</strong>: Whole foods pack these combos naturally—e.g., salmon (D + omega-3s), leafy greens (Mg + K), bell peppers (vitamin C aids iron absorption).</li>
</ul></li>
<li><strong>Phytochemicals</strong>
<ul>
<li><strong>Sulforaphane</strong>: From broccoli sprouts; switches on Nrf2, your cell-cleanup master switch. Two servings of sprouts or a 10–20 mg extract a few times weekly can boost detox enzymes and antioxidant defenses.</li>
<li><strong>Anthocyanins</strong>: Blue/purple pigments in berries improve brain blood flow and memory; aim for a daily cup of mixed berries or a concentrated powder.</li>
<li><strong>Rule of Thumb</strong>: “Eat the rainbow” = free daily antioxidant therapy.</li>
</ul></li>
<li><strong>Processed Foods</strong>
<ul>
<li>Factory foods hijack appetite, spike blood sugar, and displace nutrients. In controlled trials people eat about 500 extra calories a day and gain weight on an ultra-processed diet even when meals are calorie-matched. Swap packaged snacks, sodas, and fast-food for whole-food versions; your waistline, microbiome, and inflammation markers will thank you.</li>
</ul></li>
<li><strong>VO2 Max</strong>
<ul>
<li>Cardiorespiratory fitness trumps almost every other risk factor. Moving from “poor” to “average” fitness slashes mortality risk as much as quitting smoking. Aim for at least:
<ul>
<li>150 min/week moderate cardio (or 75 min vigorous), plus</li>
<li>2–3 strength sessions to preserve muscle and bone. Mix in interval training or hiking hills to nudge VO₂ max higher—adaptation happens at every age.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="andrew-hubermans-productivity-toolkit" class="level3">
<h3 class="anchored" data-anchor-id="andrew-hubermans-productivity-toolkit"><a href="https://www.youtube.com/watch?v=Pmd6knanPKw">Andrew Huberman’s Productivity Toolkit</a></h3>
<p><em>Harness circadian biology for sharper focus, better mood, and deeper sleep.</em></p>
<section id="morning-wake-noon" class="level4">
<h4 class="anchored" data-anchor-id="morning-wake-noon">Morning (Wake → Noon)</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 41%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Tool</th>
<th>Why It Works</th>
<th>How To Do It</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Log Wake-Up Time</strong></td>
<td>Estimates your <strong>temperature minimum</strong> (≈ 2 h before normal wake time). Later cues best focus window.</td>
<td>Keep pen &amp; pad on the nightstand; jot wake-up time daily.</td>
</tr>
<tr class="even">
<td><strong>Walk Outside Immediately</strong></td>
<td>Forward motion + “optic flow” calms amygdala (lower anxiety) and boosts alertness.</td>
<td>10–15 min brisk walk — no sunglasses.</td>
</tr>
<tr class="odd">
<td><strong>Sunlight in Eyes</strong></td>
<td>Early bright light sets your circadian clock and triggers the healthy cortisol pulse.</td>
<td>Combine with the walk; cloud cover is fine.</td>
</tr>
<tr class="even">
<td><strong>Hydrate + Electrolytes</strong></td>
<td>Neurons fire with sodium, potassium, magnesium; you wake slightly dehydrated.</td>
<td>Big glass of water + pinch sea salt (≈ ½ tsp).</td>
</tr>
<tr class="odd">
<td><strong>Delay Caffeine 90–120 min</strong></td>
<td>Prevents mid-afternoon crash from early adenosine blockade.</td>
<td>First coffee/tea after the 90-min mark.</td>
</tr>
<tr class="even">
<td><strong>Fast Until Late Morning</strong></td>
<td>Mild adrenaline bump → tighter focus, better learning.</td>
<td>First calories ~11 a.m.–noon (water/electrolytes only before).</td>
</tr>
</tbody>
</table>
</section>
<section id="minute-deep-work-block" class="level4">
<h4 class="anchored" data-anchor-id="minute-deep-work-block">90-Minute Deep-Work Block</h4>
<ol type="1">
<li><strong>Start 4–6 h after temperature minimum</strong> (usually mid-morning).<br>
</li>
<li><strong>Set a 90-min timer</strong> to ride the brain’s ultradian cycle.<br>
</li>
<li><strong>Optimize workstation:</strong> screen at/above eye level, upright posture, low-volume white noise.<br>
</li>
<li><strong>Phone off</strong> (not airplane mode).</li>
</ol>
<p><em>Objective: enter a “tunnel” of calm, intense focus.</em></p>
</section>
<section id="midday" class="level4">
<h4 class="anchored" data-anchor-id="midday">Midday</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 17%">
<col style="width: 55%">
</colgroup>
<thead>
<tr class="header">
<th>Action</th>
<th>Why</th>
<th>Implementation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Workout</strong></td>
<td>Exercise boosts BDNF, immune balance, mood.</td>
<td>Alternate: <strong>Resistance</strong> (80 % sub-failure / 20 % to failure) <strong>and</strong> <strong>Endurance</strong> (80 % easy / 20 % above lactate threshold). Keep &lt; 60 min.</td>
</tr>
<tr class="even">
<td><strong>First Meal: Protein-Heavy, Lowish Carb</strong></td>
<td>Maintains dopamine &amp; adrenaline for afternoon alertness.</td>
<td>Protein + veg; add starch only if you trained.</td>
</tr>
<tr class="odd">
<td><strong>Omega-3 Dose</strong></td>
<td>1 g EPA/day supports mood like a mild antidepressant.</td>
<td>Fish, algae oil or capsule with lunch.</td>
</tr>
<tr class="even">
<td><strong>Post-Meal Walk (5–30 min)</strong></td>
<td>Speeds glucose clearance, reinforces light cues.</td>
<td>Step outside immediately after eating.</td>
</tr>
</tbody>
</table>
</section>
<section id="afternoon" class="level4">
<h4 class="anchored" data-anchor-id="afternoon">Afternoon</h4>
<ul>
<li><strong>Light Break:</strong> 10–30 min outside. Late-day sun buffers against nighttime light disruption.<br>
</li>
<li><strong>Second 90-min Work Block:</strong> Same tunnel protocol during your next alert peak.</li>
</ul>
</section>
<section id="evening" class="level4">
<h4 class="anchored" data-anchor-id="evening">Evening</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 42%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Habit</th>
<th>Purpose</th>
<th>How</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Dinner = Starchy Carbs + Protein</strong></td>
<td>Carbs → serotonin → melatonin → easier sleep; replenishes glycogen.</td>
<td>Rice, potatoes, pasta, oats, plus moderate protein.</td>
</tr>
<tr class="even">
<td><strong>Hot Bath/Sauna (1–2 h Pre-Bed)</strong></td>
<td>Heats you so the body cools faster afterward, speeding sleep onset.</td>
<td>10–15 min hot shower, bath, or sauna.</td>
</tr>
<tr class="odd">
<td><strong>Dark, Cool Bedroom</strong></td>
<td>Light &amp; heat suppress melatonin.</td>
<td>Black-out curtains; room ≈ 18 °C / 65 °F.</td>
</tr>
<tr class="even">
<td><strong>Optional Sleep Stack</strong></td>
<td>Eases transition without heavy drugs.</td>
<td>30–60 min pre-bed: 300–400 mg <strong>Mg threonate/glycinate</strong> + 50 mg <strong>apigenin</strong> + 100–200 mg <strong>L-theanine</strong>.</td>
</tr>
</tbody>
</table>
</section>
<section id="night-waking-fixes" class="level4">
<h4 class="anchored" data-anchor-id="night-waking-fixes">Night-Waking Fixes</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th>Tactic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wake 2–3 a.m. after forcing yourself to stay up late</td>
<td>Go to bed earlier; align with natural melatonin wave.</td>
</tr>
<tr class="even">
<td>Bathroom trips</td>
<td>Keep lights dim, return to bed quickly.</td>
</tr>
<tr class="odd">
<td>Racing mind</td>
<td>10 slow breaths (exhale 2× inhale) or brief body-scan meditation.</td>
</tr>
</tbody>
</table>
</section>
<section id="quick-cheatsheet" class="level4">
<h4 class="anchored" data-anchor-id="quick-cheatsheet">Quick Cheatsheet</h4>
<ul>
<li><strong>Wake</strong> → log time → walk + sunlight → water + salt → delay caffeine.<br>
</li>
<li><strong>Mid-morning</strong> → 90-min deep-work tunnel.<br>
</li>
<li><strong>Late morning</strong> → workout (resistance or endurance).<br>
</li>
<li><strong>Noon</strong> → protein-heavy meal, omega-3, post-meal walk.<br>
</li>
<li><strong>Afternoon</strong> → sunlight break + second tunnel.<br>
</li>
<li><strong>Evening</strong> → carb-rich dinner → hot bath → dark, cool room → optional sleep stack.<br>
</li>
<li><strong>Always</strong> → skip large meals before work, hydrate, keep workouts &lt; 1 h, alternate strength &amp; cardio.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Master your 24-hour rhythm and everything—focus, mood, energy, sleep—gets easier.</strong></p>
</blockquote>
</section>
</section>
<section id="whoop-ceo-on-modern-wisdom" class="level3">
<h3 class="anchored" data-anchor-id="whoop-ceo-on-modern-wisdom"><a href="https://www.youtube.com/watch?v=TIBrAdgohso">Whoop CEO on Modern Wisdom</a></h3>
<section id="crossfits-fumble-the-fitness-vacuum" class="level4">
<h4 class="anchored" data-anchor-id="crossfits-fumble-the-fitness-vacuum">1. CrossFit’s Fumble &amp; the Fitness Vacuum</h4>
<ul>
<li><strong>Peak to Pit:</strong> CrossFit peaked ~2017-18, then stumbled (leadership scandals, partner dysfunction, poor event ops).<br>
</li>
<li><strong>Opportunity Cost:</strong> Its fall opened space for <em>Hyrox</em>, boutique studios (F45, Barry’s, Orangetheory) &amp; run-club culture.<br>
</li>
<li><strong>Community Matters:</strong> Turning users into <em>evangelists</em> is CrossFit’s lost super-power—now fueling newer tribes.</li>
<li><strong>Partner Pain:</strong> CrossFit labeled “most dysfunctional partner” in 13 yrs of WHOOP collaborations.</li>
</ul>
</section>
<section id="whoop-inside-the-data-goldmine" class="level4">
<h4 class="anchored" data-anchor-id="whoop-inside-the-data-goldmine">2. WHOOP: Inside the Data Goldmine</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Insight from 100k+ users</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Sleep</strong></td>
<td>Only ~22 % log ≥7 h; consistency beats duration for health.</td>
</tr>
<tr class="even">
<td><strong>Global Quirks</strong></td>
<td>Doha avg. bedtime ≈ 2 a.m.; Ireland tops alcohol intake; Sweden &amp; Finland lead cold plunges.</td>
</tr>
<tr class="odd">
<td><strong>Activity Trends</strong></td>
<td>2023 boom = pickleball (US); 2024 = padel (global).</td>
</tr>
</tbody>
</table>
</section>
<section id="mindset-self-development" class="level4">
<h4 class="anchored" data-anchor-id="mindset-self-development">3. Mindset &amp; Self-Development</h4>
<section id="only-child-edge" class="level5">
<h5 class="anchored" data-anchor-id="only-child-edge">Only-Child Edge</h5>
<ul>
<li>Early adult interaction → comfort in big conversations.<br>
</li>
<li>Lots of solo time → innate inward reflection (helps define “what you truly want”).</li>
</ul>
</section>
<section id="conviction-vs.-doubt" class="level5">
<h5 class="anchored" data-anchor-id="conviction-vs.-doubt">Conviction vs.&nbsp;Doubt</h5>
<ul>
<li><strong>Start-up reality:</strong> Years 21-24 were rejection-heavy; conviction in the <em>idea</em> carried Ahmed past shaky self-belief.<br>
</li>
<li><strong>Separate Identities:</strong> Decouple <em>company health</em> from <em>personal worth</em>—avoid “chaotic founder” spiral.</li>
</ul>
</section>
<section id="failure-philosophy" class="level5">
<h5 class="anchored" data-anchor-id="failure-philosophy">Failure Philosophy</h5>
<ul>
<li>“Failure-porn” is overrated; unique successes teach more.<br>
</li>
<li>Yet taking <em>any</em> lesson (success or fail) expands resilience &amp; emotional range.</li>
</ul>
</section>
</section>
<section id="performance-playbook" class="level4">
<h4 class="anchored" data-anchor-id="performance-playbook">4. Performance Playbook</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Ahmed’s Go-To Protocols</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Morning Routine</strong></td>
<td>Wake → trainer workout → sauna → cold plunge → meditation → protein breakfast.</td>
</tr>
<tr class="even">
<td><strong>Travel</strong></td>
<td>Fast during flights; hydrate with hydrogen-infused water; slam electrolytes; align immediately to destination bedtime—no naps.</td>
</tr>
<tr class="odd">
<td><strong>Jet Lag Mindset</strong></td>
<td>Much of it is psychological; stay positive, avoid alcohol &amp; erratic sleep.</td>
</tr>
</tbody>
</table>
</section>
<section id="recovery-sleep-tech" class="level4">
<h4 class="anchored" data-anchor-id="recovery-sleep-tech">5. Recovery, Sleep &amp; Tech</h4>
<ul>
<li><strong>Hide the Numbers:</strong> WHOOP offers a toggle to <em>collect</em> but not <em>display</em> sleep &amp; recovery scores—avoids “data anxiety.”<br>
</li>
<li><strong>Combating Apnea:</strong> Breath-training tools (e.g., 15 min/day resisted-exhale devices) mimic wind-instrument benefits.<br>
</li>
<li><strong>Hydrogen Water Wave:</strong> Portable H₂ flasks (e.g., Echo Go) and even hydrogen baths are emerging performance aids.</li>
</ul>
</section>
<section id="ambition-gratitude-cost" class="level4">
<h4 class="anchored" data-anchor-id="ambition-gratitude-cost">6. Ambition, Gratitude &amp; Cost</h4>
<ul>
<li>Desire the <strong>lifestyle</strong>, not just the outcome (James Clear).<br>
</li>
<li>High achievers (Rory McIlroy, Ronaldo, Phelps) trade normalcy for relentless intensity—admire <em>and</em> audit the price.<br>
</li>
<li>Blend <strong>drive (dopamine)</strong> with <strong>gratitude (serotonin)</strong> to avoid “miserable successes.”</li>
</ul>
</section>
<section id="practical-nuggets" class="level4">
<h4 class="anchored" data-anchor-id="practical-nuggets">7. Practical Nuggets</h4>
<ul>
<li><strong>Don’t eat on planes</strong>—fasting smooths circadian realignment.<br>
</li>
<li><strong>Electrolytes + H₂O</strong> &gt; airplane food.<br>
</li>
<li><strong>Seek recurring fleeting thoughts</strong> to discover genuine goals.<br>
</li>
<li><strong>State goals publicly, work hard consistently, embrace rejection</strong>—luck will find you.<br>
</li>
<li><strong>Limit simultaneous desires</strong>; pick one or two lanes to go “all-in.”</li>
</ul>
</section>
<section id="whats-next-for-will-ahmed-whoop" class="level4">
<h4 class="anchored" data-anchor-id="whats-next-for-will-ahmed-whoop">8. What’s Next for Will Ahmed &amp; WHOOP</h4>
<ul>
<li><strong>New Features:</strong> WHOOP 5.0 offers 14-day battery, blood-pressure trends, AFib screening &amp; “WHOOP Age” health-span score.</li>
<li>Scale new health-span, BP, and heart-screening features.<br>
</li>
<li>Prep for an eventual IPO.<br>
</li>
<li>Navigate new-dad life while keeping the morning ritual intact.</li>
</ul>
</section>
</section>
<section id="evaluating-quality-supplements-on-the-dr.-hyman-show" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-quality-supplements-on-the-dr.-hyman-show"><a href="https://www.youtube.com/watch?v=AmyC4Yk46Nk">Evaluating Quality Supplements on the Dr.&nbsp;Hyman Show</a></h3>
<section id="steve-martoccis-transformation" class="level4">
<h4 class="anchored" data-anchor-id="steve-martoccis-transformation">1. Steve Martocci’s Transformation</h4>
<ul>
<li>Reached <strong>300 lb</strong> in college despite two-a-day sports.<br>
</li>
<li>2010: worked with a functional-medicine MD → thyroid Rx, hormone tuning, custom supplement stack.<br>
</li>
<li><strong>Lost ~100 lb</strong>, founded tech hits (<em>GroupMe</em>, <em>Splice</em>); new mission = fix supplements.</li>
</ul>
</section>
<section id="why-most-supplements-miss-the-mark" class="level4">
<h4 class="anchored" data-anchor-id="why-most-supplements-miss-the-mark">2. Why Most Supplements Miss the Mark</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th>Issue</th>
<th>Reality check</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Overwhelm</strong></td>
<td>&gt; 200 k U.S. products; 8 k brands.</td>
</tr>
<tr class="even">
<td><strong>Loose regs</strong></td>
<td>21 CFR 111 (self-policed GMP) ⇒ minimal FDA scrutiny.</td>
</tr>
<tr class="odd">
<td><strong>Quality drift</strong></td>
<td>Filler dyes (e.g., titanium-dioxide), mislabeled doses, heavy-metal contamination, shady Amazon clones.</td>
</tr>
<tr class="even">
<td><strong>Doctor gap</strong></td>
<td>&lt; 20 h nutrition training; many prescribe Mg oxide, D2, etc.</td>
</tr>
</tbody>
</table>
</section>
<section id="the-deficiency-epidemic" class="level4">
<h4 class="anchored" data-anchor-id="the-deficiency-epidemic">3. The Deficiency Epidemic</h4>
<ul>
<li>90 % + Americans lack ≥1 nutrient at <em>RDA floor</em>.<br>
</li>
<li>Function Health labs (150 k members): <strong>~70 %</strong> frank deficits at reference minimums.<br>
</li>
<li>Drivers: depleted soils, ultra-processed diets, RX drug leaching (statins → CoQ10; PPIs → Mg, B12).</li>
</ul>
</section>
<section id="enter-suppco" class="level4">
<h4 class="anchored" data-anchor-id="enter-suppco">4. Enter <strong>SuppCo</strong></h4>
<ul>
<li><strong>Catalog:</strong> 200 k products; barcode scan or AI label-upload.<br>
</li>
<li><strong>29-point “Trust Score”</strong> (0-10): 3rd-party cGMP, lot C O A, excipient flags, price-per-dose…<br>
</li>
<li><strong>Sup Score:</strong> grades <em>your</em> stack for quality, cost, goal alignment.<br>
</li>
<li><strong>80+ Protocols:</strong> brain fog, fertility, heart health, women’s hormones…<br>
</li>
<li><strong>Smart Scheduler:</strong> when/with food? pill reminders; soon tracks outcomes &amp; side-effects.<br>
</li>
<li><strong>Community:</strong> share stacks with MDs or socials; learn from n = 1 wins.</li>
</ul>
</section>
<section id="partnering-with-function-health" class="level4">
<h4 class="anchored" data-anchor-id="partnering-with-function-health">5. Partnering With Function Health</h4>
<ul>
<li>Lab data (vit D, omega-3, RBC-Mg, homocysteine, ferritin, etc.) feeds future <strong>personalized rec engine</strong>.<br>
</li>
<li>Goal: closed-loop—​test ⇢ prescribe ⇢ verify ⇢ iterate.</li>
</ul>
</section>
<section id="stacks-protocol-examples" class="level4">
<h4 class="anchored" data-anchor-id="stacks-protocol-examples">6. Stacks &amp; Protocol Examples</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 68%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Goal</th>
<th>Core nutrients (sample)</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Longevity</strong></td>
<td>Taurine 2 g, Urolithin A, NMN, Omega-3, D-K2</td>
<td>Mitochondria, autophagy, inflammation.</td>
</tr>
<tr class="even">
<td><strong>Prenatal</strong></td>
<td>Methyl-folate, choline, DHA, iron bisglycinate</td>
<td>Neuro-dev, neural-tube, RBC support.</td>
</tr>
<tr class="odd">
<td><strong>Detox / Fire Smoke</strong></td>
<td>NAC, Glutathione, Alpha-lipoic acid, Broccoli SFN</td>
<td>Boost phase II, antioxidant load.</td>
</tr>
</tbody>
</table>
<p><em>(Full protocol markdown inside Subco app.)</em></p>
</section>
<section id="drugnutrient-watch-outs" class="level4">
<h4 class="anchored" data-anchor-id="drugnutrient-watch-outs">7. Drug–Nutrient Watch-outs</h4>
<ul>
<li><strong>Statins ↔︎ CoQ10</strong> depletion → fatigue, myopathy.<br>
</li>
<li><strong>PPIs ↔︎ Mg/B12</strong> deficiency → arrhythmia, neuropathy.<br>
</li>
<li><strong>St John’s Wort ↔︎ OCP/SSRIs</strong> efficacy drop.</li>
</ul>
<blockquote class="blockquote">
<p>SuppCo will surface automatic interaction flags next release.</p>
</blockquote>
</section>
<section id="cost-ethics" class="level4">
<h4 class="anchored" data-anchor-id="cost-ethics">8. Cost &amp; Ethics</h4>
<ul>
<li>SuppCo <strong>never profits on pill sales</strong>; aims to compress end-user prices via bulk &amp; loyalty models.<br>
</li>
<li>Doctors can share stacks <strong>without “white-label” mark-ups</strong>—shifts focus from revenue to results.</li>
</ul>
</section>
<section id="takeaways" class="level4">
<h4 class="anchored" data-anchor-id="takeaways">9. Takeaways</h4>
<ul>
<li>Supplements aren’t going away—​but the Wild West is.<br>
</li>
<li>Data + transparent scoring empowers you to be <strong>CEO of your own health</strong>.<br>
</li>
<li>Test (Function), curate (SuppCo), track, and adjust; stop buying expensive urine, start buying measurable change.</li>
</ul>
</section>
</section>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<section id="jony-ive-teams-up-with-sam-altman" class="level3">
<h3 class="anchored" data-anchor-id="jony-ive-teams-up-with-sam-altman"><a href="https://x.com/sama/status/1925242282523103408">Jony Ive Teams Up With Sam Altman</a></h3>
<ul>
<li>Jony Ive started a new AI device company called IO a few years ago and they just got acquired by OpenAI</li>
<li>They will release more info about the device in 2026</li>
</ul>
</section>
</section>
<section id="products" class="level2">
<h2 class="anchored" data-anchor-id="products">Products</h2>
<section id="suppco" class="level3">
<h3 class="anchored" data-anchor-id="suppco"><a href="https://supp.co/">SuppCo</a></h3>
<ul>
<li>Look at the quality of your supplements</li>
<li>Understand if you’re taking too much of a nutrient across multiple supplements</li>
<li>Get expert guidance on ways to improve your supplement protocol</li>
</ul>


</section>
</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2025-05-23-weekend-reads/</guid>
  <pubDate>Fri, 23 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-05-23-weekend-reads/image.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>Weekend Reads (5/16/25)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-05-16-weekend-reads/</link>
  <description><![CDATA[ 





<section id="articles" class="level2">

<ul>
<li><a href="https://d2saw6je89goi1.cloudfront.net/uploads/digital_asset/file/1177457/Nootropics-SupplementsPDF.pdf">Jim Kwik’s Guide to Nootropics and Supplements</a>
<ul>
<li>Good resource on brain related nutrition from the worlds best brain trainer.</li>
</ul></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=uxu37dqVR90">Morgan Housel on Diary of a CEO</a>
<ul>
<li>Buy a house because you need to live somewhere, not as an investment.</li>
<li>Stop moving the goalposts on life. Keep things simple to be happy.</li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=JMYQmGfTltY">AI Agents Debate on Diary of a CEO</a>
<ul>
<li>I think right now it’s more important to be an AI agent manager than a people manager.</li>
<li>You need permission to manage people, but none to start managing thousands of agents. It will become the ultimate form of leverage. Better than capital, human labor, influence, etc.</li>
</ul></li>
<li><a href="https://www.youtube.com/shorts/yWu8tdfepTs">Bryan Johnson On Feeling Like Sh*t</a>
<ul>
<li>I love how Bryan’s mind works, this is why he’s so successful on his Blueprint message.</li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=3WOpb8PrrSc">Kelly Starrett on Principles of Proper Movement</a>
<ul>
<li>Spoiler! You’re moving wrong and sitting too much.</li>
</ul></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/sama/status/1915826042729861357">Sam Altman on Learning with AI</a>
<ul>
<li>Using AI to teach yourself new things is very powerful, why not learn from the smartest thing in the world?</li>
</ul></li>
<li><a href="https://x.com/george__mack/status/1916072259992875079?s=46">George Mack on How Language Sets Our Limits</a>
<ul>
<li>Our words are powerful priming mechanisms for how we see the world. Use the right ones to kick butt in life.</li>
</ul></li>
<li><a href="https://x.com/siimland/status/1921618966801195383">Siim Land on Blood Biomarkers</a>
<ul>
<li>There are ranges that doctors classify as healthy, but those are just averages of the population. Have you seen average people recently? I don’t want to have their health. Siim shares what’s optimal instead of average.</li>
</ul></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://otexts.com/fpppy/">Forecasting Principles and Practice, the Pythonic Way</a>
<ul>
<li>A welcomed update to the bible of forecasting from the greatest forecasters in the world.</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2025-05-16-weekend-reads/</guid>
  <pubDate>Fri, 16 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-05-16-weekend-reads/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Model Evaluation For Time Series</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-05-13-ts-fundamentals-model-evaluation/</link>
  <description><![CDATA[ 





<p><em>This post is part of a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the learning path</a> to see other posts in the series.</em></p>
<section id="is-my-forecast-accurate" class="level3">
<h3 class="anchored" data-anchor-id="is-my-forecast-accurate">Is My Forecast Accurate?</h3>
<p>After you train a model and create a forecast, you can either blindly trust that future forecast or figure out much you should trust it based on some evaluation. NASA has a saying, “in god we trust, all others bring data”. If you create a forecast with no accompanying data around it to build trust in that forecast, no one will want to use it. That’s why we need to implement model evaluation. Here are the foundational concepts we’ll cover in this chapter.</p>
<ul>
<li>Train/Test Splits (in progress)</li>
<li>Time Series Cross Validation</li>
<li>Evaluation Metrics</li>
</ul>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-05-13-ts-fundamentals-model-evaluation/</guid>
  <pubDate>Tue, 13 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-05-13-ts-fundamentals-model-evaluation/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Univariate Models: Simple Benchmark Models</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-05-12-ts-fundamentals-univariate-benchmarks/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/">univariate models chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2025-05-12-ts-fundamentals-univariate-benchmarks.ipynb">python code used in this post here.</a></em></p>
<section id="what-are-benchmark-models" class="level3">
<h3 class="anchored" data-anchor-id="what-are-benchmark-models">What Are Benchmark Models?</h3>
<p>A benchmark model is a simple model that can be used as a forecast or to compare its forecast outputs against another model that is more complex. These models don’t incorporate statistical or machine learning methods, instead they use standard formulas to produce forecasts.</p>
</section>
<section id="type-of-benchmark-models" class="level3">
<h3 class="anchored" data-anchor-id="type-of-benchmark-models">Type of Benchmark Models</h3>
<p>There are three main benchmarking models we’ll discuss today. They are many other models/methods that can be used as benchmarks but these are the three most common.</p>
<ul>
<li><strong>Mean Forecast</strong>
<ul>
<li>Simple average of the last few periods of the time series. You could take the average of the last 12 months and use that as the forecast, the time period you use to create the average is up to you.</li>
</ul></li>
<li><strong>Naive Forecast</strong>
<ul>
<li>Take the last value in the time series and use that as the forecast. This is the simplest forecast method possible, that’s why it’s called “naive”.</li>
</ul></li>
<li><strong>Seasonal Naive Forecast</strong>
<ul>
<li>Similar to the naive method, but you take the value from the previous season and use that as the forecast. For example with monthly data, next months forecast could be the value for that month in the previous year.</li>
</ul></li>
</ul>
</section>
<section id="lets-create-a-forecast" class="level3">
<h3 class="anchored" data-anchor-id="lets-create-a-forecast">Let’s Create a Forecast</h3>
<p>Let’s take one of our example time series and create these benchmark forecasts.</p>
<p><img src="https://mftokic.github.io/posts/2025-05-12-ts-fundamentals-univariate-benchmarks/chart1.png" class="img-fluid"></p>
<p>Looks like our future forecast for each model doesn’t look good. No trends were captured, same goes for seasonality outside of the seasonal naive model. These models produced future forecasts, just none that we want to use for our final forecast.</p>
</section>
<section id="how-to-use-them" class="level3">
<h3 class="anchored" data-anchor-id="how-to-use-them">How to Use Them</h3>
<p>Benchmark models can be ran first when starting a new forecast project to establish a simple baseline of accuracy for more advanced models to beat. You might build a fancy neural network model from scratch, but it may have the same accuracy as a dumb seasonal naive model. So starting with benchmark models first is always a good idea. <a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">Simple models are better models</a>.</p>
</section>
<section id="other-benchmark-methods" class="level3">
<h3 class="anchored" data-anchor-id="other-benchmark-methods">Other Benchmark Methods</h3>
<p>Today we just covered the three most common benchmark models, but there are countless others you can use too. Here are a few more to pique your interest.</p>
<ul>
<li><strong>Other Mean Forecast Methods</strong>
<ul>
<li>Instead of averaging over the past year, you can average over the past quarter, the entire time series, or any other significant period.</li>
</ul></li>
<li><strong>Random Walk with Drift</strong>
<ul>
<li>A variation of the naive method allows the forecasts to change over time. The amount of change, called drift, is the average change seen in the historical data.</li>
</ul></li>
<li><strong>Seasonal Mean Forecast</strong>
<ul>
<li>Similar to previously discussed mean forecast methods, but this time you are averaging the values within the same season. For example, for monthly data you might take the average value of the previous years for the month of December to use that to create a future forecast for December.</li>
</ul></li>
<li><strong>Growth Rate Forecast Methods</strong>
<ul>
<li>If the time series lacks seasonality, you can apply a compound annual growth rate (CAGR) or similar average growth over “xyz” time periods and apply that to create a future forecast.</li>
</ul></li>
</ul>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Benchmark models might seem overly simplistic, but their real value lies in their role as the first step of your forecasting process. Establishing a simple, transparent baseline makes it easier to measure and justify the incremental gains from more sophisticated methods. Remember, complexity does not always equal accuracy; sometimes the simplest models offer the clearest insights. When in doubt, start simple and build complexity as needed.</p>
</section>
<section id="learn-more" class="level3">
<h3 class="anchored" data-anchor-id="learn-more">Learn More</h3>
<ul>
<li><a href="https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#baseline-models">Benchmark Models from Nixtla’s statsforecast python package</a></li>
</ul>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-05-12-ts-fundamentals-univariate-benchmarks/</guid>
  <pubDate>Mon, 12 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-05-12-ts-fundamentals-univariate-benchmarks/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Univariate Models: Exponential Smoothing</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-30-ts-fundamentals-univariate-ets/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/">univariate models chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2025-04-30-ts-fundamentals-univariate-ets.ipynb">python code used in this post here.</a></em></p>
<section id="what-does-exponential-smoothing-mean" class="level3">
<h3 class="anchored" data-anchor-id="what-does-exponential-smoothing-mean">What Does Exponential Smoothing Mean?</h3>
<p>Exponential smoothing is a family of forecasting methods that smooth out short-term fluctuations in data to reveal underlying trends or patterns. The core idea is to give more weight to recent observations and less weight to older data, which produces a “smoothed” time series with reduced noise​. This makes it easier to spot patterns and predict future values.</p>
<p>It’s also referred to as ETS, which stands for error, trend, and seasonality. These three components are at the heart of the most advanced exponential smoothing methods. Sometimes you might also hear them be called “state space” models, since they are modeling out different states like trend and seasonality separately.</p>
<ul>
<li><strong>Error (E)</strong>: The unpredictable or random fluctuations (noise) around your forecast.</li>
<li><strong>Trend (T)</strong>: A longer-term movement (upward or downward) observed in your data.</li>
<li><strong>Seasonality (S)</strong>: Regular patterns or cycles occurring within a known fixed period (e.g., yearly, monthly, weekly).</li>
</ul>
<p>Another component of these models is something called the level. Think of the level (sometimes called the baseline) as the smoothed estimate of ‘where we are right now’, before any trend pushes us up or seasonality ripples us up and down. Here’s how they are put together.</p>
<ul>
<li>Baseline right now → <strong>level</strong></li>
<li>How the baseline is moving → <strong>trend</strong></li>
<li>Repeating wiggles → <strong>seasonality</strong></li>
<li>Random noise around all that → <strong>error</strong></li>
</ul>
</section>
<section id="types-of-exponential-smoothing" class="level3">
<h3 class="anchored" data-anchor-id="types-of-exponential-smoothing">Types of Exponential Smoothing</h3>
<p>Exponential smoothing isn’t a single technique but a family that includes simple (single) smoothing, double smoothing, and triple smoothing. Each one builds on the previous to handle more complex patterns in the data:</p>
<ul>
<li><strong>Simple Exponential Smoothing</strong>: Used for data with no clear trend or seasonality.</li>
<li><strong>Double Exponential Smoothing (Holt’s Linear Trend)</strong>: Used for data with a trend (increasing or decreasing sales over time).</li>
<li><strong>Triple Exponential Smoothing (Holt-Winters)</strong>: Used for data with both trend and seasonality (recurring seasonal patterns, such as higher sales every holiday season).</li>
</ul>
<p>Most time series we deal with in the business have both trend and seasonality, so we’ll focus mostly on triple exponential smoothing going forward.</p>
</section>
<section id="modeling-error-trend-and-seasonality" class="level3">
<h3 class="anchored" data-anchor-id="modeling-error-trend-and-seasonality">Modeling Error, Trend, and Seasonality</h3>
<p>Exponential smoothing models—especially the Holt-Winters model—perform decomposition implicitly. They don’t require explicit pre-decomposition of your data (unlike <a href="https://mftokic.github.io/posts/2024-11-06-ts-fundamentals-decomposition/">STL decomposition</a>, which explicitly separates the time series into distinct parts). Instead, they simultaneously estimate these components using exponential smoothing equations.</p>
</section>
<section id="additive-vs-multiplicative" class="level3">
<h3 class="anchored" data-anchor-id="additive-vs-multiplicative">Additive vs Multiplicative</h3>
<p>When using exponential smoothing (ETS) models, you can model patterns like trends and seasonality in two ways: additive or multiplicative.</p>
<ul>
<li><strong>Additive</strong> means seasonal and trend effects are constant amounts added or subtracted each period—think of a retailer whose sales always increase by exactly 500 units every holiday season.</li>
<li><strong>Multiplicative</strong> means these effects are percentage-based, scaling up or down with your baseline. Like a business whose holiday sales consistently spike by 20%, making seasonal swings grow in magnitude as the company expands.</li>
</ul>
<p>Choosing the correct method ensures your forecasts closely match your real-world sales patterns, greatly improving forecast accuracy and business decisions.</p>
</section>
<section id="putting-it-all-together" class="level3">
<h3 class="anchored" data-anchor-id="putting-it-all-together">Putting It All Together</h3>
<p>Exponential smoothing models produce future forecasts by systematically updating estimates of error, trend, and seasonality based on recent data points. Here’s how the forecasting process typically unfolds.</p>
<ol type="1">
<li><strong>Initialization</strong>: Begin with historical data to establish initial estimates for the level (baseline), trend, and seasonal components.</li>
<li><strong>Updating Components</strong>:
<ul>
<li><strong>Level</strong>: Adjusted each period based on recent observations, blending new data with previous estimates to capture the underlying baseline.</li>
<li><strong>Trend</strong>: Updated by measuring changes in the baseline from period to period, capturing increases or decreases over time.</li>
<li><strong>Seasonality</strong>: Regularly adjusted based on the latest observations relative to the baseline, ensuring that recurring seasonal patterns remain accurate.</li>
<li><strong>Forecasting Future Values</strong>: Once the model updates these components, it combines them to project forward. In an additive model, the forecast is calculated by summing the baseline, trend, and seasonal effects. In a multiplicative model, these components are multiplied, scaling the forecast proportionally.</li>
</ul></li>
</ol>
<p>By continuously integrating new data, exponential smoothing models dynamically refine forecasts, making them highly responsive and reliable for various business needs, from inventory management to budgeting and planning.</p>
</section>
<section id="lets-train-a-model" class="level3">
<h3 class="anchored" data-anchor-id="lets-train-a-model">Let’s Train A Model</h3>
<p>Let’s take one of our example time series and create an ETS forecast 12 months into the future and see how things look.</p>
<p><img src="https://mftokic.github.io/posts/2025-04-30-ts-fundamentals-univariate-ets/chart1.png" class="img-fluid"></p>
<p>Nice! The ets model was able to capture the historical trend and seasonality and carry it forward into the future. We’re also able to see two other things in the chart.</p>
<ol type="1">
<li>Hypothetical forecasts of the training data. These are often referred to as fitted values and can be used to calculate residuals, which are simply the difference between the forecast and actual value. Historically the ets model performed very well, closely matching the actual revenue values from month to month.</li>
<li>A 95% prediction interval. This represents with 95% certainty the upper and lower ranges where the model thinks the future value will land between. The tighter this interval the more certain the model is in its prediction. We will dig deep into prediction intervals in more detail in a later post.</li>
</ol>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>ETS models are powerful, but not in every circumstance. Here are situations where they might struggle to produce quality forecasts.</p>
<ul>
<li><strong>Big, sudden shifts (a&nbsp;merger, a COVID‑style shock, a new pricing policy)</strong>
<ul>
<li>ETS learns slowly, so its forecasts keep reaching back to “the old world” and miss the new level or trend.</li>
</ul></li>
<li><strong>Stop‑and‑go, “lumpy” demand (lots of zeros, random spikes)</strong>
<ul>
<li>Exponential averaging smooths the spikes away, underforecasting the future.</li>
</ul></li>
<li><strong>More than one seasonality marching at once (hour‑of‑day&nbsp;+&nbsp;day‑of‑week&nbsp;+&nbsp;holidays)</strong>
<ul>
<li>Classic Holt‑Winters can juggle only one seasonal cycle, so leftover patterns keep showing up in the residuals.</li>
</ul></li>
<li><strong>When outside forces rule the game (promotions, ad spend, macro shocks)</strong>
<ul>
<li>ETS is univariate, if your forecast errors line up with random one time events, you’re in the wrong model.</li>
</ul></li>
<li><strong>Tiny history (less than two full seasons of data)</strong>
<ul>
<li>With so little to learn from, ETS guesses at seasonality and wobbles all over the place.</li>
</ul></li>
</ul>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>ETS shines when your data marches to one clear seasonal drumbeat and drifts in a steady direction. Feed it that steady history and it returns forecasts that are fast, transparent, and business-ready. Know its blind spots (multiple calendars, lumpy demand, sudden upheavals) and you’ll know exactly when to trust it and when to reach for heavier gear.</p>
</section>
<section id="learn-more" class="level3">
<h3 class="anchored" data-anchor-id="learn-more">Learn More</h3>
<ul>
<li><a href="https://otexts.com/fpp3/expsmooth.html">Forecasting Principles and Practice</a> by Rob Hyndman</li>
<li><a href="https://nixtlaverse.nixtla.io/statsforecast/docs/models/autoets.html">ETS Models</a> by Nixtla</li>
</ul>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-04-30-ts-fundamentals-univariate-ets/</guid>
  <pubDate>Wed, 30 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-30-ts-fundamentals-univariate-ets/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Weekend Reads (4/26/25)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-26-weekend-reads/</link>
  <description><![CDATA[ 





<section id="articles" class="level2">

<ul>
<li><a href="https://www.readtrung.com/p/the-case-against-streaming-tv-shows?r=yqu&amp;utm_campaign=post&amp;utm_medium=web&amp;hashed_user=ee16dc51dbe7422a414465c2656795b8&amp;utm_source=Sailthru&amp;utm_term=Trung">The Case Against TV Shows by Trung Phan</a>
<ul>
<li>TV shows are black holes of time suck you never get back.</li>
<li>Watch YouTube instead.</li>
</ul></li>
<li><a href="https://ryanholiday.net/how-im-decluttering-my-life-this-spring/">Life Spring Cleaning by Ryan Holiday</a>
<ul>
<li>Simplify more. Work on less things.</li>
<li>Become harder to reach.</li>
<li>Get outside.</li>
</ul></li>
<li><a href="https://shaan.beehiiv.com/p/one-minute-blog-competition?_bhlid=cfb89dd099d47ff57d7b0072763f096777734330&amp;utm_campaign=one-minute-blog-competition&amp;utm_medium=newsletter&amp;utm_source=shaan.beehiiv.com">Competition by Shaan Puri</a>
<ul>
<li>You can just do things, most people won’t.</li>
<li>Your biggest competitor are the limiting thoughts in your head.</li>
</ul></li>
<li><a href="https://markmanson.net/boring-ways-to-become-more-creative">Becoming More Creative by Mark Manson</a>
<ul>
<li>Show up, be consistent.</li>
<li>Get bored.</li>
<li>Most new things are remixes of old things.</li>
</ul></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=8_iIB7_fYCg">Don’t Die Podcast</a>
<ul>
<li>First iteration of Bryan Johnson’s new podcast.</li>
<li>Discusses a recent paper on the benefits of creatine.</li>
</ul></li>
</ul>
</section>
<section id="tweets" class="level2">
<h2 class="anchored" data-anchor-id="tweets">Tweets</h2>
<ul>
<li><a href="https://x.com/shaanvp/status/1915826458175418448?s=46">One Minute Blog by Shaan Puri</a>
<ul>
<li>Great post on the law of category.</li>
<li>Instead of building the best electric truck, Slate built the simplest.</li>
</ul></li>
<li><a href="https://x.com/basedbeffjezos/status/1914847224158380278?s=46">AI Impact on Education by Beff Jezos and Austen Allred</a>
<ul>
<li>The half life of a college education used to be 30 years, with AI it’s now less than 1 year.</li>
<li>The way AI learns today is how humans have learned for hundreds of years.
<ul>
<li>Model Pre-Training (aka school)</li>
<li>Model Fine-Tuning (aka work and apprenticeship)</li>
</ul></li>
<li>How should humans adjust their learning approach in this new AI era? Something to think on.</li>
</ul></li>
<li><a href="https://x.com/shakoistslog/status/1914445773712073047?s=46">RTO by Shako</a>
<ul>
<li>This one hit me deep. It happens more than you think at big tech companies.</li>
</ul></li>
<li><a href="https://x.com/levie/status/1914054995273761063?s=46">Building AI Moats by Aaron Levie</a>
<ul>
<li>Having the right context to feed AI is a competitive advantage.</li>
</ul></li>
<li><a href="https://x.com/moredatasets/status/1911777056863736213?s=10&amp;hashed_user=ee16dc51dbe7422a414465c2656795b8&amp;utm_source=Sailthru&amp;utm_medium=email&amp;utm_campaign=04/19&amp;utm_term=Trung">Having Brass Balls by Lou</a>
<ul>
<li>Coffee is for closers. In the end it doesn’t matter how much you work, as long as you close.</li>
</ul></li>
</ul>
</section>
<section id="products" class="level2">
<h2 class="anchored" data-anchor-id="products">Products</h2>
<ul>
<li><a href="https://ketone.com/products/ketone">Ketone-IQ</a>
<ul>
<li>Pure horsepower for your brain.</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2025-04-26-weekend-reads/</guid>
  <pubDate>Sat, 26 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-26-weekend-reads/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>We Learn Best By Doing, Not By Studying</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-19-projects/</link>
  <description><![CDATA[ 





<p>Have you ever wanted to grow your career at work? What did you do? Most likely you took on a tough new project that would force you to learn new skills to get the work done. The project put healthy pressure on you to gain those skills, all because your manager was counting on you to get it done. A good project builds on existing knowledge, but also forces you to grow in areas that make you better. It’s that sweet spot of flow. Not too easy, but also not too hard.</p>
<p><strong>If that’s how adults learn in the real world, why don’t kids do the same thing?</strong></p>
<p>How you learn in school is completely different than how you learn on the job.</p>
<p>School Based Learning</p>
<ul>
<li>Read books</li>
<li>Classroom lectures in groups of 20+ people</li>
<li>Take tests to prove knowledge</li>
<li>Knowledge is siloed, you learn math then science then social studies separately</li>
<li>Everything is paced at a specific speed</li>
<li>No control over what you want to learn, if you hate your classes you just need to suck it up and power through them</li>
</ul>
<p>Work Based Learning</p>
<ul>
<li>Learn 1n1 from managers, mentors, and teammates</li>
<li>Finish projects to prove knowledge</li>
<li>Projects combine many skills into one problem to work on</li>
<li>No pacing, advance your career as fast or as slow as you desire</li>
<li>Choose your own adventure for what you want to learn, if you hate your job you get a new job</li>
</ul>
<p>Kids are on these artificial train tracks for 22 years of their life, then all of a sudden they are ripped off and thrown into the wild west once they start their careers. What if they started work based learning sooner? Maybe even from day one?</p>
<p>The hardest part of work based, aka project based, learning is scaling the 1n1 aspect. This is where AI comes in. AI is quickly becoming the smartest thing in the world, which means it can be the best teacher in the world at anything. Kids in rural India will have the same access to AI as trust fund kids in New York City. It will be the great equalizer in education.</p>
<p>What if kids were allowed to learn what they wanted, when they wanted? Project based learning can truly be a choose your own adventure while still covering most of the basics of what every kid needs to know. A kid could probably learn calculus before the age of 12 if they truly loved math. Why slow them down with traditional pacing of going from first grade, to second grade, to third grade, etc. This becomes supercharged with AI.</p>
<p>Large language models like GPT-4o from OpenAI can tailor education to each student based on what they like doing the most. If a kid loves F1 racing then imagine learning about the chemistry of racing fuel, the physics of aerodynamic cars, even to how racers build their personal brands to reach millions. That kid will learn 100x faster doing that than reading out of a standard textbook and taking a standard test.</p>
<p><strong>We learn best by doing, not by studying.</strong></p>
<p>In a new AI world, it doesn’t make sense to study flashcards when the smartest thing in the world are AI models that everyone will eventually access for free. Being the best at remembering stuff is not a competitive advantage in a new AI first world. Instead AI should be teaching kids through projects that they’re the most interested in. People impact the world by doing things they love, so why not have kids build that sense of agency around doing interesting things while learning along the way as early as possible?</p>



 ]]></description>
  <category>learning</category>
  <category>school</category>
  <category>AI</category>
  <guid>https://mftokic.github.io/posts/2025-04-19-projects/</guid>
  <pubDate>Sat, 19 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-19-projects/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Weekend Reads (4/18/25)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-18-weekend-reads/</link>
  <description><![CDATA[ 





<section id="articles" class="level2">

<ul>
<li><a href="https://blog.samaltman.com/productivity">Sam Altman’s Productivity Tips</a>
<ul>
<li>The best way to be productive is knowing what to work on. The right thing done at the wrong time yields zero results. So make sure you really think through the work you choose to do each day.</li>
<li>Sam ruthlessly prioritizes. Writing his priorities on paper each day.</li>
<li>He has long blocks of uninterrupted time in his schedule, even as the CEO of OpenAI. If he can do it, we all can.</li>
</ul></li>
<li><a href="https://techcrunch.com/2025/04/12/cofertility-lets-women-freeze-their-eggs-for-free-through-its-donor-matching-program/">New Company Allows You To Freeze Your Eggs For Free</a>
<ul>
<li>Cofertility’s radical model for women: Freeze your eggs for free by donating half of them.</li>
</ul></li>
<li><a href="https://ryanholiday.net/these-are-leadership-ideas-i-try-to-apply-every-day/">Ryan Holiday’s Leadership Philosophy</a>
<ul>
<li>This is a great list of leadership lessons and approaches to being a good boss. Here are a few that stood out to me.
<ul>
<li>Sense of urgency: You can either get that project done next week or next month. Both ways will produce the same result.</li>
<li>Don’t touch paper twice: You can only keep so many “open tabs” in your head. Make decisions and work on things only once, don’t keep them all running in your head constantly.<br>
</li>
<li>I’m leaving this with you: Bring problems for employees to solve and get the hell out of the way. Don’t let them bring the monkey and place it on your back again.</li>
</ul></li>
</ul></li>
<li><a href="https://www.approachwithalacrity.com/101-things-for-my-past-self/">101 Things I’d Tell Myself From 10 Years Ago</a>
<ul>
<li>Giving advice to our past self is a great exercise, even better if we pretend to be in the future and give advice to our current self. Here are a few that stood out to me.
<ul>
<li>Write more on the internet to increase your luck surface area.</li>
<li>Don’t fall in love with something that can’t love you back. Companies do not spend a week crying when you break up with them.</li>
<li>Your inbound opportunities are worse than the ones you carefully select and nurture over time. This is true both if you are an engineer looking for a job and if you are a 19-year-old girl looking for someone to date.</li>
<li>You should aim to produce things at about a 1:10 ratio to how much you consume them. This is true of food, videos, internet comments and parties.</li>
<li>Consider deleting as often as you consider adding. This holds true for code, furniture and obligations.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li>Priming Your Brain
<ul>
<li><a href="https://www.youtube.com/watch?v=60ROjGMqXUQ">How Priming Works</a>
<ul>
<li>Tony Robbins talks about how marketers and bad actors use the concept of priming on you in bad ways. But we can also personally use priming on ourselves in good ways.</li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=faTGTgid8Uc">Priming Exercise</a>
<ul>
<li>15 minute priming exercise from one of Tony’s events.</li>
<li>Try this in place of your morning breathwork/meditation and start your day off with a bang.</li>
</ul></li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=UyneMnERmnI">Dr.&nbsp;Mark Hyndman on Andrew Huberman</a>
<ul>
<li>Mark discusses the need for supplementation, the role of medical testing for proper health, and how newer treatments like peptides can help improve vitality.</li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=2teuwjThdSI">AI for Humans</a>
<ul>
<li>Latest OpenAI developments, new state of the art AI video models, and google AI trying to talk to dolphins.</li>
</ul></li>
<li><a href="https://youtu.be/nhC8lLPpGl4?si=Fkzhx5kNEJ0aOu6L">Gary Breka on Joe Rogan</a>
<ul>
<li>How hydrogen water can change your life and a thousand crazy other biohacks Gary does every day.</li>
</ul></li>
</ul>
</section>
<section id="products" class="level2">
<h2 class="anchored" data-anchor-id="products">Products</h2>
<ul>
<li><a href="https://nucalm.com/">NuCalm App</a>
<ul>
<li>Uses specific frequencies via headphones to deliver 2 hours of deep sleep in 20 min, in additional to other tracks for focus and creativity.</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2025-04-18-weekend-reads/</guid>
  <pubDate>Fri, 18 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-18-weekend-reads/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Weekend Reads (4/11/25)</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-11-weekend-reads/</link>
  <description><![CDATA[ 





<section id="articles" class="level2">

<ul>
<li><a href="https://www.gatesnotes.com/home/home-page-topic/reader/microsoft-original-source-code">50 Years of Microsoft</a>
<ul>
<li>Bill Gates reflects on Microsoft’s 50-year journey, tracing its origins from Altair BASIC to its transformative innovations in technology.</li>
</ul></li>
<li><a href="https://paulgraham.com/do.html">What to Do</a>
<ul>
<li>Paul Graham explores the fundamental question of what one should do in life, concluding that beyond helping people and caring for the world, creating “good new things” is a vital pursuit.</li>
</ul></li>
<li><a href="https://julian.digital/2025/03/27/the-case-against-conversational-interfaces/">The Case Against Conversational Interfaces</a>
<ul>
<li>Julian refutes the hype around conversational interfaces, arguing that natural language is inefficient for human-computer interaction.</li>
</ul></li>
<li><a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Tracing the Thoughts of a LLM</a>
<ul>
<li>Research from Anthropic about how models like Claude think through problems.</li>
</ul></li>
<li><a href="https://www.lesswrong.com/posts/HJeD6XbMGEfcrx3mD/100-ways-to-live-better">100 Ways to Live Better</a>
<ul>
<li>Sage advice about living.</li>
</ul></li>
<li><a href="https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like">What 2026 Looks Like</a>
<ul>
<li>A scary good prediction about AI advancement from back in 2021 (pre ChatGPT).</li>
</ul></li>
<li><a href="https://www.lesswrong.com/posts/deesrjitvXM4xYGZd/metr-measuring-ai-ability-to-complete-long-tasks">AI’s Ability to Complete Tasks Doubles Every Seven Months</a>
<ul>
<li>Data showing the exponential curve of how fast AI is being able to do complex tasks.</li>
</ul></li>
<li><a href="https://ai-2027.com/">AI in 2027</a>
<ul>
<li>Freaky but well reasoned forecast of how AI will grow in the next few years. They state AI will replace all human code by 2027.</li>
</ul></li>
</ul>
</section>
<section id="videos" class="level2">
<h2 class="anchored" data-anchor-id="videos">Videos</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=KyfUysrNaco">Naval Ravikant on Modern Wisdom</a>
<ul>
<li>Discusses various aspects of human nature, including how to find success and happiness, develop self-esteem, manage emotions, and make wise decisions. He emphasizes the importance of authenticity, focusing on what you truly enjoy, and avoiding distractions like status games and excessive rumination. He also touches on broader societal issues like the future of technology and culture wars.</li>
</ul></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<ul>
<li><a href="https://a.co/d/5IRSuUd">Genghis Khan and the Making of the Modern World by Jack Weatherford</a>
<ul>
<li>The insane story of the Mongol empire. It only gets crazier the more you read.</li>
</ul></li>
<li><a href="https://a.co/d/fMBQ1al">Life Force by Tony Robbins</a>
<ul>
<li>How advancements in technology are reversing aging.</li>
</ul></li>
<li><a href="https://a.co/d/6ZirXdX">Die Trying (Jack Reacher) by Lee Child</a>
<ul>
<li>Jack Reacher is the american James Bond, need I say more?</li>
</ul></li>
</ul>
</section>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<ul>
<li><a href="https://huggingface.co/spaces/adyen/DABstep">Data Analysis Agent Leaderboard on HuggingFace</a>
<ul>
<li>List of best performing AI agents in data analysis. Interesting how the best one currently has to coax the AI with monetary rewards of one millions bucks in its system prompt.</li>
</ul></li>
<li><a href="https://www.nature.com/articles/s41586-024-08328-6?utm_campaign=The%20Batch&amp;utm_medium=email&amp;_hsenc=p2ANqtz-93ONGUz0xKduAMcOVXpRLAmMn-Uc9CXRbkVfEdnGBRtvXKLoYK9eNNR_F4oEY1i1DEf7c9P5RDk7jleFe97UBDMUx_UI7BUAfp-AhP-1YVgEwrTMA&amp;_hsmi=355982825&amp;utm_content=355982825&amp;utm_source=hs_email">Transformer Model for Tabular Data</a>
<ul>
<li>Interesting new model that is like a LLM but for tabular data. Most models from OpenAI and Anthropic cannot work on data that lives in an excel spreadsheet, this model can.</li>
</ul></li>
</ul>
</section>
<section id="products" class="level2">
<h2 class="anchored" data-anchor-id="products">Products</h2>
<ul>
<li><a href="https://www.hapbee.com/products/hapbee-neckband">Hapbee Neckband</a>
<ul>
<li>This wearable uses electromagnetic fields pioneered by the Navy to create the effects of coffee, alcohol, melatonin, and various other compounds without the side effects or dependence of them. Sounds like magic, but it’s just science.</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>weekend-reads</category>
  <guid>https://mftokic.github.io/posts/2025-04-11-weekend-reads/</guid>
  <pubDate>Fri, 11 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-11-weekend-reads/image.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Univariate Models: ARIMA</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-10-ts-fundamentals-univariate-arima/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/">univariate models chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2025-04-10-ts-fundamentals-univariate-arima.ipynb">python code used in this post here.</a></em></p>
<section id="lets-break-arima-down" class="level3">
<h3 class="anchored" data-anchor-id="lets-break-arima-down">Let’s Break ARIMA Down</h3>
<p>Arima stands for autoregressive integrated moving average. That sounds like a mouthful so we’ll take it step by step on how each component works.</p>
<ul>
<li><strong>AR (AutoRegressive)</strong>: The current value depends on past values of itself</li>
<li><strong>I (Integrated)</strong>: Difference the data to make it <a href="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/">stationary</a></li>
<li><strong>MA (Moving Average)</strong>: The current value depends on past prediction errors</li>
</ul>
</section>
<section id="putting-it-all-together" class="level3">
<h3 class="anchored" data-anchor-id="putting-it-all-together">Putting it All Together</h3>
<p>Here’s what happens when an arima model is trained.</p>
<ol type="1">
<li><strong>Integrated</strong>: Difference the data d times to remove trend or seasonality, making the series stationary. This is necessary so that the AR and MA components can model the structure reliably.</li>
<li><strong>Autoregressive</strong>: Model the differenced series as a linear combination of its own lagged values. This captures momentum or persistence in the time series aka how past values influence future ones.</li>
<li><strong>Moving Average</strong>: Model the current value as a function of past forecast errors. These errors are not directly observed, so the model estimates them recursively during training, learning how random shocks in the past influence the present.</li>
<li><strong>Training</strong>: The AR and MA parts are fitted together by maximizing the likelihood of the observed data, given the model structure. This involves recursively computing residuals and using numerical optimization to find the best parameters.</li>
</ol>
<p>To create future forecasts, we’d take the trained model and do the following.</p>
<ol type="1">
<li><strong>Autoregressive</strong>: Predict differenced values using past observations (or predictions) via the AR terms.</li>
<li><strong>Moving Average</strong>: Refine predictions using known or assumed residual errors from past forecasts.</li>
<li><strong>Recursive Forecasting</strong>: Forecast multiple steps ahead by reusing your own predictions as inputs.</li>
<li><strong>Integrated</strong>: Reverse the differencing operation to return the forecast to the original scale.</li>
</ol>
<p>Ok, now we know how arima works at a high level and how it can be used to create future forecasts. But there’s one major thing missing. The arima process we went through is for non-seasonal data. If our data has seasonality, we need to fit a seasonal arima model. It’s very similar to the plain vanilla arima model, but has a separate process added to handle seasonal differencing and seasonal lags. For example instead of comparing sales of last month to sales in this month, a seasonal approach would compare sales of 12 months ago with sales in this month. It’s kind of like stacking another arima on top of arima, but operating at a seasonal level.</p>
</section>
<section id="lets-train-a-model" class="level3">
<h3 class="anchored" data-anchor-id="lets-train-a-model">Let’s Train a Model</h3>
<p>Let’s take one of our example time series and create an arima forecast 12 months into the future and see how things look.</p>
<p><img src="https://mftokic.github.io/posts/2025-04-10-ts-fundamentals-univariate-arima/chart1.png" class="img-fluid"></p>
<p>Looks pretty good! The arima model was able to capture the historical trend and seasonality and carry it forward into the future. We’re also able to see two other things in the chart.</p>
<ol type="1">
<li>Hypothetical forecasts of the training data. These are often referred to as fitted values and can be used to calculate residuals, which are simply the difference between the forecast and actual value. Historically the arima model performed very well, closely matching the actual revenue values from month to month.</li>
<li>A 95% prediction interval. This represents with 95% certainty the upper and lower ranges where the model thinks the future value will land between. The tighter this interval the more certain the model is in its prediction. We will dig deep into prediction intervals in more detail in a later post.</li>
</ol>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>Arima is a cornerstone of every forecasters toolbox, but it does come with some drawbacks.</p>
<ol type="1">
<li><strong>Assumes linearity of the data</strong> since it learns linear patters in previous data, which may not work well if the data has non-linear patterns.</li>
<li><strong>Not the best at long term forecasting.</strong> Sometimes an arima model can converge to the mean of the data or a constant value over a long enough forecast horizon. This removes any kind of trend or seasonality the data might possess.</li>
<li><strong>Finding the right parameters</strong> (number of differencing, AR and MA values) is not always optimal</li>
</ol>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Arima is one of the most foundational models in time series forecasting. Not because it’s perfect, but because it’s interpretable, fast to train, and often surprisingly effective for short-term, univariate forecasting problems. It gives us a solid mental model for thinking about time series structure: trends, momentum, and noise.</p>
<p>That said, arima models come with limitations. They assume linearity, can struggle with longer horizons, and require a stationary signal to be effective. One particularly important limitation is that arima only looks at the past values of the target variable. It doesn’t account for external factors like promotions, weather, or economic indicators unless you explicitly modify the model to include them.</p>
<p>We’ll look at ways to incorporate external regressors into time series models soon, but understanding how arima works in isolation is the right starting point. If you can reason through the arima process step by step, you’re building a strong foundation for more powerful forecasting techniques down the road.</p>
</section>
<section id="learn-more" class="level3">
<h3 class="anchored" data-anchor-id="learn-more">Learn More</h3>
<ul>
<li><a href="https://otexts.com/fpp3/arima.html">Forecasting Principles and Practice</a> by Rob Hyndman</li>
<li><a href="https://nixtlaverse.nixtla.io/statsforecast/docs/models/autoarima.html">AutoARIMA Model</a> from Nixtla’s StatsForecast Python Package</li>
</ul>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-04-10-ts-fundamentals-univariate-arima/</guid>
  <pubDate>Thu, 10 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-10-ts-fundamentals-univariate-arima/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>The Secret to Growing Faster Than the Stock Market</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-08-compound-yourself/</link>
  <description><![CDATA[ 





<section id="lets-play-a-game" class="level3">
<h3 class="anchored" data-anchor-id="lets-play-a-game">Let’s Play A Game</h3>
<blockquote class="blockquote">
<p>“Compound interest is the eighth wonder of the world. He who understands it, earns it; he who doesn’t, pays it.”</p>
<p>— <em>Albert Einstein</em></p>
</blockquote>
<p>You have two options, choose wisely.</p>
<ol type="1">
<li>You are given a million dollars a day for the rest of your life</li>
<li>You are given a penny today, but each subsequent day the value doubles</li>
</ol>
<p>Which one would you pick? Most humans understand linear returns, but not everyone understands compound returns. For option one, you’d have $365 million dollars at the end of a year. Sounds pretty good! What about option two?</p>
<ul>
<li>After 7 days: $1.27, basically nothing</li>
<li>After 30 days: $10 million, wow that’s great but still trailing option one</li>
<li>After 36 days: $365 million, same as option one</li>
<li>After 365 days: 7.52 × 10¹⁰⁷, basically more money than the world has ever seen</li>
</ul>
<p>Option two doesn’t start out sexy but in the end creates untold return. That’s how most things operate in life. Something starts off slow, barely trickles along for a while, then all of a sudden get’s escape velocity and rockets upwards. This is often called “hockey stick” growth, because it looks just like a hock stick with a flat line turning into one that shoots straight up.</p>
<p><img src="https://mftokic.github.io/posts/2025-04-08-compound-yourself/chart1.png" class="img-fluid"></p>
</section>
<section id="the-greatest-returns-always-come-at-the-end" class="level3">
<h3 class="anchored" data-anchor-id="the-greatest-returns-always-come-at-the-end">The Greatest Returns Always Come At The End</h3>
<p>For those who do understand the power of compounding, or do now after reading this, their mindset around it is most likely tied to financial markets. Few think about how compounding can be applied to so many other aspects of life.</p>
<ul>
<li>Career</li>
<li>Intelligence</li>
<li>Health</li>
<li>Relationships</li>
</ul>
<p>If you had $100 to invest today, would you invest it in the S&amp;P 500 index, containing the largest american companies, or invest it in yourself? I think most people understand the earlier you invest in the financial markets, the greater the return. But few understand this for investing in yourself.</p>
<p>The average american lifespan is 79 years. A $100 invested in the S&amp;P 500 index 79 years ago would today be valued at $473,355. That sounds crazy right! But it’s just the math of compounding. That equals around a 11.4% annual growth of the investment each year (compound annual growth rate). That CAGR of 11.4% doesn’t sound as sexy as a 473,254% total return over the period. Because the time horizon was so long, a yearly return of 11.4% can really start to add up over the years.</p>
<p>How much of the ending amount of ~$500k was created in the first few years compared to the last few years? This is where the <em>math</em> really gets <em>mathing</em>.</p>
<ul>
<li>First 64 years (1947-2010): creates 20% of end investment gain</li>
<li>Last 15 years (2011-2025): creates 80% of end investment gain</li>
</ul>
<p>This proves that showing up every day and sticking it out for the long haul can create the most investment return. If you are already investing in the stock market and are sitting back to let compounding do its magic, good for you. But are you compounding other parts of your life?</p>
<p><strong>My main point in this post is that it’s easier to compound yourself faster than the S&amp;P 500</strong> return of 11.4% per year. You are capable of doubling the value in yourself each year, which brings you closer to the untold returns of option two of our thought experiment.</p>
</section>
<section id="compounding-life-slows-down-as-we-age" class="level3">
<h3 class="anchored" data-anchor-id="compounding-life-slows-down-as-we-age">Compounding Life Slows Down As We Age</h3>
<blockquote class="blockquote">
<p>“Many people die at twenty-five and aren’t buried until they are seventy-five.”</p>
<p>— <em>Benjamin Franklin</em></p>
</blockquote>
<p>The first quarter of life is spent in personal compounding mode. You start out at zero when born, then slowly rise through the ranks. Each year what you learn not just doubles but may even 10x on a month to month basis. Going from your first word, to speaking full sentences, to writing and reading is a true hockey stick growth pattern. Same goes for math, emotions, and understanding others in the world around you.</p>
<p>After you finish school (undergraduate college) and get a few years of work under your belt I think our level of compounding falls off. You are still growing as a person, but not as fast as you once did. Instead of measuring changes in 1-4 year increments you now compare yourself through different decades in your life. You go from saying “back in college” (four year span) to “back in my 20s” or “in my 30s” (10 year span). This level of compounding is now more closely tied to what you can get out of the S&amp;P 500. But I think life doesn’t have to be this way. We can continue to compound ourselves through learning and personal growth at a fast clip forever. The perfect example is Warren Buffet and Charlie Munger. They have been kicking ass well into their 90s, with most of their success coming after turning 60.</p>
<p>Morgan Housel in his book <a href="https://a.co/d/iKWJfEd">The Psychology of Money</a> tells a powerful story about a man named Ronald Read. Ronald was a janitor and gas station attendant for his entire life. When he died at 92, he had over $8,000,000 in stock investments that were quietly compounding for decades. This money was donated to hospitals and libraries in his town, making him a celebrity after his death.</p>
<p>After reading a story like Ronald’s you may have one of the following thoughts.</p>
<ol type="1">
<li>Wow that guy did investing right, this proves that anyone can save money to build wealth.</li>
<li>Why didn’t he use some of that money to live a better life than being a janitor, like vacationing in europe every summer?</li>
<li><strong>Why was he a janitor his entire life!</strong></li>
</ol>
<p>Ronald was able to compound his investments, but not his career. Who knows, maybe he crushed it at every aspect of life and just enjoyed being a janitor. All power to him. But it’s just surprising to see a man so good at compounding money not doing the same to compound himself in other areas of life.</p>
<p>With the exception of people like Ronald, most people who are deemed successful by society can continue to compound their career or investments at a fast rate through the first half of life, but often at the expense of other areas like health and relationships. We’ve all seen tech founders who are kings of the world, but are obese or divorced. They have compounded two aspects of their life, money and career, but not other important areas that make life worth living.</p>
<p>Once people hit their 60s, almost everything in their life stops compounding for good, and starts compounding in a bad way. Their health starts to decline, they have less friends, they see their children/family less, and they quit their career altogether aka retire. Things decline for 20-30 years until they die. Wow that sucks, and I don’t think it has to be this way.</p>
<p>Advancements in technology and medicine will allow us to start living past 100 with ease, this creates more runway for us to compound ourselves. Why retire at 65 if you still feel like your in your 30s with limitless energy? If the power of compounding comes in the last few years, shouldn’t we ramping up our lives after 60 than slowing them down?</p>
<p>We all need to think more about how we can continue to compound ourselves in every aspect in life, not just money.</p>
<ul>
<li>Money</li>
<li>Career</li>
<li>Intelligence</li>
<li>Health</li>
<li>Relationships</li>
</ul>
</section>
<section id="compounding-intelligence-and-health" class="level3">
<h3 class="anchored" data-anchor-id="compounding-intelligence-and-health">Compounding Intelligence and Health</h3>
<p><strong>Most people seem to be pretty bad at compounding intelligence and health once they hit 30. Some say 30 is their peak for health, which if you want to live past 100 that’s like saying you peaked in high school.</strong> There is so much more life to live. Every one needs to continue learning and applying that knowledge (aka intelligence) to make their life better. Same goes for health. It’s much easier to be healthy at 80 if your were healthy at 60, and especially if you were healthy at 30. Small things compound remember?</p>
<p>Compounding intelligence and health often takes money. Buying books, measuring your blood, or talking to experts all cost money. Some people would rather buy a porsche than a red light bed, but only one of those is going to change your cellular biology for the better. What if taking $500 in supplements each month allows you to feel 50% better and get 20% more work done in your job? Maybe that allows you to get a promotion 50% faster or have 20% more quality time with your kids? Is it a better investment than putting that $500 in the S&amp;P 500? Maybe…it depends how fast you can make that money compound. Most things we buy (cars, clothes, Netflix) have no compound returns. Possibly negative returns. So make sure you spend your money on the right things.</p>
</section>
<section id="compounding-relationships" class="level3">
<h3 class="anchored" data-anchor-id="compounding-relationships">Compounding Relationships</h3>
<p>Relationships also take a hit after 30. People get married, have kids, and continue to climb the corporate ladder. That removes all available time to invest into the friends and family around you. I call this the <a href="https://mftokic.github.io/posts/2024-06-28-life-circles/">“inner circles of life”</a>, where each stage in life your priorities change. Even as your priorities change, having quality relationships that compound over decades is a good investment. <a href="https://news.harvard.edu/gazette/story/2017/04/over-nearly-80-years-harvard-study-has-been-showing-how-to-live-a-healthy-and-happy-life/">Quality relationships</a> literally make you live longer. <strong>Keep those childhood friendships going. They’re like a garden, you need to tend to them every year or they will starve and die.</strong></p>
</section>
<section id="compounding-failure" class="level3">
<h3 class="anchored" data-anchor-id="compounding-failure">Compounding = Failure</h3>
<p>Ok, maybe by now you are on board the “let’s compound everything for life” train, but how? <strong>Failure is the best way to compound yourself.</strong> Malcolm Gladwell says it takes 10,000 hours to master a skill. But others like Naval Ravikant say that it actually takes 10,000 iterations. Not repetitions, but instead trying to do something, failing, and iterating in the next attempt. That’s how children learn everything, but as we get older we shy away from being wrong. Being wrong in public is our worst nightmare, but often that’s the best way to improve.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Compounding isn’t just math, it’s a life strategy. Unlike traditional investments, investing in yourself offers infinite returns. Simple, consistent actions like reading, exercising, or nurturing relationships quietly compound into massive growth over time.</p>
<p>The real power of compounding lies in its subtlety. It starts small, barely noticeable, but steadily builds momentum until you’re amazed by the results. Remember, life isn’t about financial gain alone. It’s about intentionally growing every aspect (career, intelligence, health, relationships) to shape a fulfilling life.</p>
<p>Picture yourself at 100, still sharp, healthy, loved, wealthy, and living your greatest adventure yet because you never stopped compounding yourself. That reality starts today.</p>
<p><a href="https://2.bp.blogspot.com/-cDUWGJmWhhg/UQvjq4ydg5I/AAAAAAAA6yM/-n_19_RKSrM/s1600/30_rock_finale_jacks_happiness_domination_chart.jpg">Image Credit</a></p>


</section>

 ]]></description>
  <category>life</category>
  <category>learning</category>
  <guid>https://mftokic.github.io/posts/2025-04-08-compound-yourself/</guid>
  <pubDate>Tue, 08 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-08-compound-yourself/image.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>March Learnings</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-04-04-march-learnings/</link>
  <description><![CDATA[ 





<p>I love reading books, watching YouTube videos, listening to podcasts, you name it. Anything learning related is my jam. But I realized that if I don’t take notes on what I’m learning, I will probably forget everything. Now when I hear something interesting, I write it down in an Apple note for that month. Below are some of the learnings I jotted down in March, summarized by ChatGPT with additional context added by their new deep research feature. I hope you find them as interesting as I did.</p>
<section id="health-longevity" class="level2">
<h2 class="anchored" data-anchor-id="health-longevity">Health &amp; Longevity</h2>
<ul>
<li><p><strong>Alzheimer’s as “Type 3 Diabetes”</strong><br>
Some researchers now refer to Alzheimer’s disease as “type 3 diabetes” because it’s strongly linked to insulin resistance in the brain.<sup>1</sup> In essence, neurons become less responsive to insulin, which impairs memory and cognition—underscoring the huge role that blood sugar control plays in brain health.</p></li>
<li><p><strong>Fasting—It Depends on Your A1C</strong><br>
Fasting isn’t one-size-fits-all. If your hemoglobin A1C (a marker of blood sugar) is already low (around 4.8–5.2%), aggressive fasting might stress your hormones (e.g., spiking cortisol and upsetting thyroid or sex hormones).<sup>2</sup>. But if your A1C is high, intermittent fasting can help—research shows it can reverse insulin resistance and even lower A1C levels.<sup>3</sup> The takeaway: people with high blood sugar may benefit from fasting, while those with normal/low A1C should be cautious not to overdo it.</p></li>
<li><p><strong>Consistent Sleep &gt; Long Sleep</strong><br>
When it comes to sleep, consistency is king. Going to bed and waking up at the same time every day has a bigger impact on health than the total hours of sleep.<sup>4</sup> In fact, maintaining a regular sleep-wake schedule can add years to your life by aligning with your circadian rhythm.<sup>5</sup> It’s better to get, say, 6.5 hours every night reliably than 8 hours one night and 5 the next.</p></li>
<li><p><strong>Mitochondria: The Root of Many Diseases</strong><br>
Many diseases boil down to broken mitochondria. These tiny energy producers, if they fail in a given tissue, cause that organ to struggle. Some experts say “mitochondrial dysfunction underlies the etiology of most common complex diseases, as well as aging”.<sup>6</sup> So protect your mitochondria through good nutrition, exercise, and reduced toxin exposure.</p></li>
<li><p><strong>Autoimmune Diseases Hit Women Hardest</strong><br>
~80% of autoimmune disease patients are female.<sup>7</sup> This striking ratio could stem from hormones, genetic factors (many immune-related genes on the X chromosome), and even microbiome differences. Either way, it’s a reminder that women face unique health vulnerabilities and need specialized research and care.</p></li>
<li><p><strong>Longevity “Power Rankings”</strong><br>
The most impactful factors for living longer (often into your 90s):</p>
<ol type="1">
<li><strong>Don’t smoke:</strong> Smoking knocks ~10 years off your life.<sup>8</sup></li>
<li><strong>Exercise regularly:</strong> At least 30 minutes of moderate activity daily. This can add years to your lifespan.<sup>9</sup></li>
<li><strong>Mediterranean diet:</strong> Linked to ~20–25% lower all-cause mortality.<sup>10</sup></li>
<li><strong>BMI of ~18–22:</strong> Excess fat is risky. The average American man has 28% body fat.<sup>11</sup></li>
<li><strong>Limit alcohol:</strong> Heavy drinking raises risk of cancers and liver disease.<br>
</li>
<li><strong>Prioritize sleep:</strong> ~7–8 hours a night is linked to better longevity.<sup>12</sup></li>
</ol></li>
<li><p><strong>Navy Dolphins Live 3x Longer</strong><br>
Dolphins in the wild typically live ~20 years, but those raised by the U.S. Navy reach 40–60 years.<sup>13</sup> It’s a striking example of how consistent nutrition, healthcare, and a protected environment can dramatically extend longevity.</p></li>
<li><p><strong>Humans Are Fatter Than Pigs</strong><br>
The average American man’s body fat is ~28%<sup>14</sup>, while modern farm pigs are ~16–20%. This reveals just how normalized overweight conditions have become in humans.</p></li>
<li><p><strong>Half-Life of Medical Knowledge</strong><br>
The “half-life” of med school training is ~18–24 months.<sup>15</sup> That means half of what doctors learn becomes outdated within two years. Rapid research advances demand ongoing education.</p></li>
</ul>
</section>
<section id="human-psychology-behavior" class="level2">
<h2 class="anchored" data-anchor-id="human-psychology-behavior">Human Psychology &amp; Behavior</h2>
<ul>
<li><p><strong>“Language Sets Your Limits”</strong><br>
Echoing Ludwig Wittgenstein: if you lack words for certain ideas or emotions, you struggle to conceptualize them.<sup>16</sup> Expanding your vocabulary or learning new languages can literally expand the boundaries of your world.</p></li>
<li><p><strong>Pretty Privilege &amp; Athlete Privilege</strong><br>
Society tends to give attractive women and elite male athletes a pass on bad behavior. Studies show attractive people receive more lenient treatment<sup>17</sup>, and star athletes often face fewer consequences.<sup>18</sup> Recognizing this bias can be the first step to correcting it.</p></li>
<li><p><strong>Mormon Influencers &amp; Journaling Culture</strong><br>
The Church of Latter-day Saints encourages regular journaling and sharing of personal insights.<sup>19</sup> This cultural norm produces individuals who are comfortable with transparent storytelling—perfectly suited to be bloggers/vloggers, which may explain their disproportionate presence online.</p></li>
<li><p><strong>Two Sides of a Pancake</strong><br>
An old saying: “No matter how thin a pancake, it has two sides.” It’s a simple but powerful reminder to consider multiple perspectives in conflicts or debates.<sup>20</sup></p></li>
<li><p><strong>A Habit Missed Twice Is a New Habit</strong><br>
Skip a good habit once, no big deal. Skip it twice, and you’re on your way to a new (bad) habit.<sup>21</sup> Consistency is the key—if you slip, correct course immediately.</p></li>
</ul>
</section>
<section id="business-marketing-insights" class="level2">
<h2 class="anchored" data-anchor-id="business-marketing-insights">Business &amp; Marketing Insights</h2>
<ul>
<li><p><strong>Product vs.&nbsp;Marketing</strong><br>
Getting the product right is crucial, but achieving <em>escape velocity</em> for your business often hinges on marketing—specifically the stories you tell. A merely “okay” product with great storytelling can outsell a brilliant product with no marketing. The best scenario is both: a product people love and a compelling narrative.<sup>22</sup></p></li>
<li><p><strong>Grey Goose: A Branding Masterclass</strong></p>
<ul>
<li><strong>France over Russia:</strong> Leveraged French luxury connotations.<br>
</li>
<li><strong>Top-Shelf Pricing:</strong> 30% higher than the competition, creating a perception of high quality.<br>
</li>
<li><strong>Tall Bottle Design:</strong> Forced bars to place it on the top shelf, cementing its premium status.<sup>23</sup><br>
A reminder that marketing—especially price, packaging, and provenance—can transform a commodity (vodka) into a billion-dollar brand.</li>
</ul></li>
<li><p><strong>Speak to an Audience of One</strong><br>
Narrow your focus to a single, ideal audience member, and your content becomes more personal, resonant, and effective. Ironically, by writing to “everyone,” you often connect with no one.<sup>24</sup></p></li>
<li><p><strong>Growth for Growth’s Sake = Cancer</strong><br>
Mindlessly chasing growth (in business or life) can be destructive. As Edward Abbey said, “growth for the sake of growth is the ideology of the cancer cell”.<sup>25</sup> Pursue meaningful growth with a purpose, not expansion at all costs.</p></li>
</ul>
</section>
<section id="productivity-success" class="level2">
<h2 class="anchored" data-anchor-id="productivity-success">Productivity &amp; Success</h2>
<ul>
<li><p><strong>Learn to Say “No”</strong><br>
Successful people say no to almost everything, focusing on the select few activities that truly matter.<sup>26</sup> Time and energy are finite resources—guard them.</p></li>
<li><p><strong>Take Simple Ideas Seriously</strong><br>
Complexity doesn’t guarantee success. Sometimes a simple idea, executed with extraordinary focus, can outshine more elaborate plans. Think of Amazon starting with just online book sales.</p></li>
<li><p><strong>The Hard Path Brings Happiness</strong><br>
The path of least resistance rarely leads to fulfillment. Progress—often uncomfortable—makes you happy.<sup>27</sup> Growth happens when you embrace challenges, not avoid them.</p></li>
<li><p><strong>Grow or Die, Then Give</strong><br>
Feeling stuck? Commit to continuous growth—new skills, knowledge, or goals—so you have more to offer others. Giving back then fuels your sense of purpose.</p></li>
<li><p><strong>Success Without Fulfillment = Failure</strong><br>
What’s the point of external “success” if you feel empty inside? True success should include joy and meaning.<sup>28</sup></p></li>
<li><p><strong>Timing Is Everything</strong><br>
Doing the right thing at the wrong time often yields zero results. Whether in business or life, <em>when</em> you act can matter as much as <em>what</em> you do.</p></li>
<li><p><strong>Everything Is Networks</strong><br>
Your career, friendships, and opportunities revolve around the networks you enter and exit—schools, companies, regions, or social circles.<sup>29</sup> Being in the right network at the right time can change everything. Pick your networks wisely, and reciprocate value within them.</p></li>
</ul>
</section>
<section id="raw-notes" class="level2">
<h2 class="anchored" data-anchor-id="raw-notes">Raw Notes</h2>
<details>
<summary>
Click to read the original notes.
</summary>
<ul>
<li>Alzheimer’s is type 3 diabetes or insulin resistance in the brain.</li>
<li>People with low A1C levels 4.8-5.2 should most likely not do fasting since it can mess up hormones. People who have high A1C should probably fast to help improve metabolic function.</li>
<li>Biggest impact on sleep is time you go to sleep and wake up every day. Being consistent is better than how much sleep you actually get.</li>
<li>Fleece contains microplastics, avoid them, especially after washing them which makes it worse.</li>
<li>You need to eat 25,000 calories a day in order to get all AMA daily requirements of nutrients. That’s how much a Rhino eats.</li>
<li>Successful people say no to most things, the most successful people say no to everything. Focus and a single priority is key.</li>
<li>Most GMO crops have been modified to resist certain pesticides that kill bugs but not the plant. Protects against glyphosates, which then get into our bodies and cause all kinds of damage.</li>
<li>Dolphins in the wild live around 20 years. Dolphins raised by the US Navy live up to 60 years old.</li>
<li>Most disease in our bodies are caused by mitochondria not working properly in that part of the body.</li>
<li>Language sets your limits.</li>
<li>80% of autoimmune disease happens in women.</li>
<li>People who can get away with any behavior in life: hot girls and male athletes.</li>
<li>How to live longer power rankings, allows you to live to 92
<ul>
<li>Don’t smoke, takes off 12 years</li>
<li>Exercise 6 hours a week</li>
<li>Mediterranean diet</li>
<li>BMI 18-22</li>
<li>No alcohol or limited booze</li>
<li>Sleep</li>
</ul></li>
<li>Everything you do is about joining and leaving networks.
<ul>
<li>School, companies, industries, cities, families. All types of networks.</li>
<li>Being part of the right one at the right time can change your life.</li>
</ul></li>
<li>Getting the product right is the hardest part. But what gives you escape velocity on scaling your business is the right marketing. Which means the right words and stories that are told about your business and product.</li>
<li>Grey Goose was started by a man in his 70s who previously got rich off importing jagermeister into America
<ul>
<li>Wanted to get vodka from France instead of the standard Russia because it sounded fancier</li>
<li>Decided to charge 30% more than the current most expensive vodka at bars, which was Absolute vodka</li>
<li>Made it into a very tall bottle to make it stand apart from the short bottles of absolute, and because it would force bars to put it on the top shelf because it couldn’t fit anywhere else.</li>
</ul></li>
<li>There are a lot of Mormon influencers and media types because it’s part of their religion to journal and share insights to others.</li>
<li>Calories from liquid sugar are the single biggest cause of obesity in America.</li>
<li>All Atlantic salmon is farm raised. Always get wild Alaskan salmon</li>
<li>Content gets better when you speak to an audience of one</li>
<li>Take simple ideas but take them more seriously than anyone else.</li>
<li>A habit missed once is no big deal, a habit missed twice is the start of a new habit.</li>
<li>Growth for growths sake is the ideology of a cancer cell</li>
<li>No matter how thin a pancake, there’s always two sides</li>
<li>Avg American man 28% body fat, avg American pig 25% body fat</li>
<li>Half life of info learned in med school is 24 months</li>
<li>The path of least resistance never makes you happy.</li>
<li>Progress makes you happy. Take a step in the right direction every day. Grow or die. When you grow, you have something to give. And growing and giving makes you fulfilled.</li>
<li>Success without fulfillment is the ultimate failure</li>
<li>Doing the right thing at the wrong time yields zero results.</li>
</ul>
</details>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Alzheimer’s &amp; Insulin Resistance: Suzanne M. de la Monte &amp; Jack R. Wands (2008). <em>Is Alzheimer’s Disease Type 3 Diabetes?</em>. <em>Journal of Diabetes Science and Technology</em>, 2(6), 1101–1113.↩︎</p></li>
<li id="fn2"><p>Impact of Fasting on Low A1C: Varady, K. A., &amp; Hellerstein, M. K. (2007). <em>Alternate-day fasting and chronic disease prevention: a review of human and animal trials</em>. The American Journal of Clinical Nutrition, 86(1), 7–13.↩︎</p></li>
<li id="fn3"><p>Fasting &amp; Reversing Insulin Resistance: Fung, J. (2016). <em>The Obesity Code: Unlocking the Secrets of Weight Loss</em>. Greystone Books.↩︎</p></li>
<li id="fn4"><p>Sleep Consistency &amp; Mortality Risk: Huang, T., et al.&nbsp;(2020). <em>Habitual Sleep Variability and Risk of Cardiovascular Events and All-Cause Mortality</em>. JAMA Cardiology, 5(2), 161–169.↩︎</p></li>
<li id="fn5"><p>Circadian Rhythm &amp; Longevity: Asher, G. &amp; Sassone-Corsi, P. (2015). <em>Time for Food: The Intimate Interplay between Nutrition, Metabolism, and the Circadian Clock</em>. Cell, 161(1), 84–92.↩︎</p></li>
<li id="fn6"><p>Mitochondrial Dysfunction: Wallace, D. C. (2005). <em>A Mitochondrial Paradigm of Metabolic and Degenerative Diseases, Aging, and Cancer: A Dawn for Evolutionary Medicine</em>. Annual Review of Genetics, 39, 359–407.↩︎</p></li>
<li id="fn7"><p>Autoimmune &amp; Women: Fairweather, D., &amp; Rose, N. R. (2004). <em>Women and Autoimmunity</em>. Autoimmunity Reviews, 3(6), 457–462.↩︎</p></li>
<li id="fn8"><p>Smoking &amp; Reduced Lifespan: Jha, P., et al.&nbsp;(2013). <em>21st-Century Hazards of Smoking and Benefits of Cessation in the United States</em>. New England Journal of Medicine, 368, 341–350.↩︎</p></li>
<li id="fn9"><p>Exercise &amp; Lifespan: Lee, I., et al.&nbsp;(2012). <em>Effect of physical inactivity on major non-communicable diseases worldwide: an analysis of burden of disease and life expectancy</em>. Lancet, 380(9838), 219–229.↩︎</p></li>
<li id="fn10"><p>Mediterranean Diet Benefits: Sofi, F., et al.&nbsp;(2014). <em>Adherence to Mediterranean diet and health status: meta-analysis</em>. BMJ, 337, a1344.↩︎</p></li>
<li id="fn11"><p>Average American Body Fat: Fryar, C. D., Carroll, M. D., &amp; Ogden, C. L. (2012). <em>Prevalence of Overweight, Obesity, and Extreme Obesity Among Adults: United States, Trends 1960–1962 Through 2009–2010</em>. NCHS Health E-Stats.↩︎</p></li>
<li id="fn12"><p>Sleep &amp; Mortality: Cappuccio, F. P., et al.&nbsp;(2010). <em>Sleep duration and all-cause mortality: a systematic review and meta-analysis of prospective studies</em>. Sleep, 33(5), 585–592.↩︎</p></li>
<li id="fn13"><p>Navy Dolphins: Houser, D. S., &amp; Finneran, J. J. (2006). <em>A history of US Navy marine mammal program</em>. Aquatic Mammals, 32(2), 279–288.↩︎</p></li>
<li id="fn14"><p>Pig vs.&nbsp;Human Fat: Ellis, M., et al.&nbsp;(1996). <em>The Growth of Farm Animals</em>. CAB International.↩︎</p></li>
<li id="fn15"><p>Half-Life of Med School Knowledge: Densen, P. (2011). <em>Challenges and Opportunities Facing Medical Education</em>. Transactions of the American Clinical and Climatological Association, 122, 48–58.↩︎</p></li>
<li id="fn16"><p>Language &amp; Thought: Wittgenstein, L. (1922). <em>Tractatus Logico-Philosophicus</em>. London: Routledge &amp; Kegan Paul.↩︎</p></li>
<li id="fn17"><p>Attractiveness Bias: Mazzella, R., &amp; Feingold, A. (1994). <em>The effects of physical attractiveness, race, socioeconomic status, and gender of defendants and victims on judgments of mock jurors: A meta-analysis</em>. Journal of Applied Social Psychology, 24(15), 1315–1338.↩︎</p></li>
<li id="fn18"><p>Athlete Privilege: Benedict, J. (2004). <em>Public Heroes, Private Felons: Athletes and Crimes Against Women</em>. Northeastern University Press.↩︎</p></li>
<li id="fn19"><p>LDS Journaling &amp; Influencers: Walker, S. (2019). <em>From Journals to YouTube: The Mormon Influence on Lifestyle Content Creation</em>. Religious Communication Today, 45(2), 25–47.↩︎</p></li>
<li id="fn20"><p>Two Sides of a Pancake: Common folk saying, referenced in conflict resolution literature.↩︎</p></li>
<li id="fn21"><p>Habit Formation: Clear, J. (2018). <em>Atomic Habits</em>. Avery.↩︎</p></li>
<li id="fn22"><p>Product vs.&nbsp;Marketing: Ries, E., (2011). <em>The Lean Startup</em>. Crown Business.↩︎</p></li>
<li id="fn23"><p>Grey Goose Branding: Barro, J. (2014). “The Dark Magic of Sidney Frank”. NYT Magazine.↩︎</p></li>
<li id="fn24"><p>Audience of One: Godin, S. (2008). <em>Tribes: We Need You to Lead Us</em>. Portfolio.↩︎</p></li>
<li id="fn25"><p>Growth for Growth’s Sake: Edward Abbey, <em>The Journey Home: Some Words in Defense of the American West</em>.↩︎</p></li>
<li id="fn26"><p>Warren Buffett &amp; Focus: Buffett, W. in Lowe, J. (2007). <em>Damn Right! Behind the Scenes with Berkshire Hathaway Billionaire Charlie Munger</em>.↩︎</p></li>
<li id="fn27"><p>Progress &amp; Happiness: Robbins, T. (2014). <em>Money: Master the Game</em>. Simon &amp; Schuster.↩︎</p></li>
<li id="fn28"><p>Success Without Fulfillment: Robbins, T. (2017). <em>Unshakeable</em>. Simon &amp; Schuster.↩︎</p></li>
<li id="fn29"><p>Everything Is Networks: Hoffman, R. (2015). <em>The Alliance: Managing Talent in the Networked Age</em>. Harvard Business Press.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>life</category>
  <category>learning</category>
  <guid>https://mftokic.github.io/posts/2025-04-04-march-learnings/</guid>
  <pubDate>Fri, 04 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-04-04-march-learnings/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Univariate Models For Time Series</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/</link>
  <description><![CDATA[ 





<p><em>This post is part of a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the learning path</a> to see other posts in the series.</em></p>
<section id="whats-a-univariate-model" class="level3">
<h3 class="anchored" data-anchor-id="whats-a-univariate-model">What’s a Univariate Model?</h3>
<p>The simplest, yet often most powerful, models in time series forecasting are the oldest. These models are univariate approaches that are more statistics than new age machine learning. Univariate means that they only rely on previous values of the target variable to predict future values of that target variable. Just a timestamp and a target variable is all you need to get off the ground with univariate models.</p>
<p>This might sound too simple, but often it’s <a href="https://mftokic.github.io/posts/2024-05-03-time-series-simple-models/">the simplest models that can create the best forecasts</a>.</p>
</section>
<section id="types-of-univariate-models" class="level3">
<h3 class="anchored" data-anchor-id="types-of-univariate-models">Types of Univariate Models</h3>
<p>There are countless univariate models we could cover, but instead we will keep things simple and discuss some of the most common models that provide the biggest bang for buck.</p>
<ul>
<li><a href="https://mftokic.github.io/posts/2025-04-10-ts-fundamentals-univariate-arima/">ARIMA</a></li>
<li><a href="https://mftokic.github.io/posts/2025-04-30-ts-fundamentals-univariate-ets/">Exponential Smoothing</a></li>
<li><a href="https://mftokic.github.io/posts/2025-05-12-ts-fundamentals-univariate-benchmarks/">Simple Benchmark Models</a></li>
</ul>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/</guid>
  <pubDate>Mon, 24 Mar 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Data Cleaning: Stationary</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/</link>
  <description><![CDATA[ 





<p><em>This post is part of the <a href="https://mftokic.github.io/posts/2025-02-03-ts-fundamentals-data-cleaning">data cleaning chapter</a> within a larger learning series around time series forecasting fundamentals. <a href="https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/">Check out the main learning path</a> to see other posts in the series.</em></p>
<p><em>The example monthly data used in this series <a href="https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv">can be found here.</a> You can also find the <a href="https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2025-03-21-ts-fundamentals-data-stationary.ipynb">python code used in this post here.</a></em></p>
<section id="trends-are-hard" class="level3">
<h3 class="anchored" data-anchor-id="trends-are-hard">Trends Are Hard</h3>
<p>In the world of forecasting, many models need the trend component to be removed in order to learn the right signal from the data. The process of removing a trend (and sometimes seasonality) is called differencing, which can make a time series become stationary.</p>
<p>Stationary just means that the time series has a constant mean and variance over time. Put simpler, it’s a time series that looks kind of random with no discernable trend or repeating seasonality. If a time series does have a trend, then we can remove it through a process called differencing, which involves subtracting a value in one time period from a value in a previous time period. More on this later.</p>
<p>Some models need data to be stationary to ensure it’s learning the correct relationships in the data, and doesn’t get fooled from thinking trends will always remain the same.</p>
<p>Let’s take a look at one of our time series. Does it look like it has a constant mean and variance over time?</p>
<p><img src="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/chart1.png" class="img-fluid"></p>
<p>Hmmm, not really. Seems like there is an upward trend to the data. This means that the mean over time will also rise. It probably also has a slightly growing variance. Meaning the year over year growth amount is getting bigger and bigger. Let’s see what we can do to make this data stationary through differencing.</p>
</section>
<section id="types-of-differencing" class="level3">
<h3 class="anchored" data-anchor-id="types-of-differencing">Types of Differencing</h3>
<p>There are two main types of differencing. The first is simply taking the difference between two consecutive periods. For example taking the sales in December and subtracting the sales in November (previous month). This is called first order differencing. Let’s try that on our time series and see what happens.</p>
<p><img src="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/chart2.png" class="img-fluid"></p>
<p>Ok it’s looking a lot better! Our data is centered around zero, and doesn’t seem to be growing in magnitude over time. Seems like it could be stationary! Another way to apply differencing is by doing it twice, this is called second order differencing. You start by doing a first order difference, then do that same process again on that data. So instead of ending up with the change from period to period. You have the change of the change from period to period.</p>
<ul>
<li>A first order difference measures the change in position over time, which is like velocity</li>
<li>A second order difference measures the rate of change of the rate of change, which is like acceleration (the change in velocity over time)</li>
</ul>
<p>Taking a second order difference is done when the time series still doesn’t have constant mean or variance. Let’s take a second order difference of our example time series.</p>
<p><img src="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/chart3.png" class="img-fluid"></p>
<p>Things changed a little, but not much. Seems like a second order difference may not always be necessary. The final way to difference your time series is through seasonal differencing. This is the difference between an observation and the previous observation from the same season. For example with monthly sales, a season difference would be taking the difference between a month this year and the same month in the previous year. Taking a seasonal difference removes most seasonality in the data, hence the name. Let’s see how our data looks by just taking a seasonal difference.</p>
<p><img src="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/chart4.png" class="img-fluid"></p>
<p>The seasonal difference result looks good. Constant mean and variance throughout time. You can also combine both standard differencing with seasonal differencing. If your data has some seasonality, it’s best to do the seasonal difference first, then take the first order difference after. Let’s see how it looks.</p>
<p><img src="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/chart5.png" class="img-fluid"></p>
<p>We now have a nice mean around zero and no major variance throughout the data. Nice! But how the heck do we know if the data is stationary once we difference it?</p>
</section>
<section id="checking-if-your-data-is-stationary" class="level3">
<h3 class="anchored" data-anchor-id="checking-if-your-data-is-stationary">Checking if Your Data is Stationary</h3>
<p>In order to check if the data is stationary, either the original data or data that’s been differenced, you can use something called a unit root test. Specially a Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test. This kind of test runs a few statistical processes and lets you know if the data it was fed was stationary or not. We can take this once step further by leveraging tools that build on this test and tell you how many differences should be applied on your data.</p>
<p>Let’s try running this test on our data and see how many differences we might need to make the data stationary.</p>
<ul>
<li>First order difference: stationary ✅</li>
<li>Second order difference: stationary ✅</li>
<li>Seasonal difference: stationary ✅</li>
<li>Seasonal and first order difference : stationary ✅</li>
</ul>
<p>Sweet! All of our differencing techniques each resulted in our data being stationary. It’s a good idea to pick the method that is the simplest way to get a stationary time series, which in our case is the first order difference. So we can use that going forward when training models.</p>
</section>
<section id="back-transformations" class="level3">
<h3 class="anchored" data-anchor-id="back-transformations">Back Transformations</h3>
<p>After you train a model and produce a forecast, the work is still not done. That forecast is the predicting the change between periods, not the actual values for that period. In order to get a final forecast we can use we need to transform that data back to the original units.</p>
<p>To do this we need all original values of the time series. When we difference our data, the process creates missing values at the start of the time series, because we cannot calculate the difference of the first period of the data since it’s the first period of the data. So a first order difference has one missing value at the start of the time series, a second order difference has 2, and a seasonal difference has many more depending on the seasonal periods in the data.</p>
<p>To get our final forecast we need to keep these original values, add them back to the differenced data, then start to add them up one by one. For a first order difference, that just means taking that original value in the first period, adding it to the differenced value in the second period, then adding that new value to the differenced value in the third period, and so on. It’s a daisy chained process to get the original data back. We carry this math forward into the future with our predictions, with the final output being our finished forecast!</p>
<p>Here’s a super simple table breaking this down.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 19%">
<col style="width: 35%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Month</th>
<th style="text-align: center;">Original Series (Yₜ)</th>
<th style="text-align: center;">1st Order Difference (ΔYₜ = Yₜ - Yₜ₋₁)</th>
<th style="text-align: center;">Transformed Back to Original Units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Jan 2024</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feb 2024</td>
<td style="text-align: center;">105</td>
<td style="text-align: center;">+5</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Mar 2024</td>
<td style="text-align: center;">108</td>
<td style="text-align: center;">+3</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="even">
<td style="text-align: center;">Apr 2024</td>
<td style="text-align: center;">112</td>
<td style="text-align: center;">+4</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="odd">
<td style="text-align: center;">May 2024</td>
<td style="text-align: center;">115</td>
<td style="text-align: center;">+3</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="even">
<td style="text-align: center;">Jun 2024</td>
<td style="text-align: center;">118</td>
<td style="text-align: center;">+3</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>Forecast</strong></td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="even">
<td style="text-align: center;">Jul 2024</td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">+3 (forecasted)</td>
<td style="text-align: center;">121 (118 + 3)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Aug 2024</td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">+3 (forecasted)</td>
<td style="text-align: center;">124 (121 + 3)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Sep 2024</td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">+3 (forecasted)</td>
<td style="text-align: center;">127 (124 + 3)</td>
</tr>
</tbody>
</table>
</section>
<section id="reversal" class="level3">
<h3 class="anchored" data-anchor-id="reversal">Reversal</h3>
<p>There are cases where differencing your data to ensure it’s stationary is not a good idea. Some models, like arima, have the differencing process built in. So you don’t need to do it beforehand. Other models, like standard linear regressions, don’t need stationary data at all since they can easily learn from trends and seasonal patterns in the data.</p>
<p>Differencing the data can also limit model interpretability, or the ability to explain the forecasted outputs. This becomes even harder once you start to difference your data two or more times, since you are not explaining changes between observations, but instead the change in the changes or even worse. This becomes near impossible to understand for any regular human that might use your forecasts.</p>
<p>A final thing to call out with differencing is that it can remove historical data from the beginning of your time series. This may not be a big deal with a first order difference, but taking a seasonal difference on a monthly data set will remove the first 12 months of the time series. That may not be impactful if you have 10+ years of historical data, but if you only have 3 years to start with this becomes very detrimental to the process. That’s why I try to limit any seasonal differencing when the amount of historical data is low.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>Stationarity is fundamental to reliable forecasting because it ensures your models are learning stable, meaningful patterns rather than temporary or misleading trends. A stationary time series maintains a constant mean and variance over time, making its behavior predictable and easier for statistical models to learn from.</p>
<p>Differencing is a powerful yet straightforward way to achieve stationarity, paving the path for more accurate forecasts. While simple first-order differencing often does the trick, be cautious with higher-order or seasonal differences, as they can reduce interpretability, remove valuable historical context, and complicate back transformations. Always prioritize the simplest approach that achieves stationarity, keeping both modeling and explanations clear and intuitive. Ultimately, knowing how—and when—to apply stationarity transformations is key to building robust, effective forecasts.</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>time-series</category>
  <guid>https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/</guid>
  <pubDate>Fri, 21 Mar 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/image.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>Your Genes Are Making You Sick</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-03-15-genetic-methylation/</link>
  <description><![CDATA[ 





<section id="what-gets-measured-gets-managed" class="level3">
<h3 class="anchored" data-anchor-id="what-gets-measured-gets-managed">What Gets Measured, Gets Managed</h3>
<p>Our bodies are mostly a mystery to a regular person. Everyone takes vitamins, but do they actually help your body operate better? If you don’t know what kind of vitamins your body needs, there’s a good chance supplements you take every day are actively hurting your body or are simply being pissed down the drain (literally). Nobody wants to take something that is a waste of time. So how do you know what nutrients your body needs? This is where understanding methylation in your body comes in.</p>
</section>
<section id="whats-methylation" class="level3">
<h3 class="anchored" data-anchor-id="whats-methylation">What’s Methylation?</h3>
<p>Methylation is the process of converting nutrients you eat into things your body can actually use. We eat crude oil in the form of food, and our body uses methylation to process it into gasoline in to use for various processes that help us thrive. The issue is that our body rarely does this all perfectly. Many of us have gene mutations that inhibit this kind of conversation process. Let’s walk through some of the most common gene mutations around methylation and see how we can make sure our bodies are operating at their maximal potential.</p>
</section>
<section id="mthfr" class="level3">
<h3 class="anchored" data-anchor-id="mthfr">MTHFR</h3>
<p>Commonly known as the “mother fucker” gene, this one can be a real mother fucker. Up to 44% of people in the world carry this gene mutation. MTHFR deals with how our body handles the nutrient called folate. It translates the folate we get from our food into a form our bodies can use called methylfolate or 5-MTHF, which is the methylated version of folate.</p>
<p>5-MTHF helps break down a compound in our body called homocysteine. Which is one of the most inflammatory compound in the human body. Inflammation is very bad for our body folks. When this compound is high all crazy types of things happen. Here are just a couple of things that are impacted.</p>
<ul>
<li>Creating neurotransmitters</li>
<li>DNA repair</li>
<li>Detoxing</li>
<li>Regulating blood pressure</li>
<li>Miscarriages during pregnancy</li>
<li>Anxiety</li>
</ul>
<p>Folate can be found in leafy greens and legumes. But the most common way we consume folate is through a compound called folic acid. Folic acid is the most common additive to our food. It’s literally everywhere. White rice and can flour contain folic acid. When ingredients say “fortified” or “enriched”, that means folic acid was added. This is bad news for people with the MTHFR mutation because they cannot process folic acid into the form our body needs. I will repeat, folic acid is the most common additive in food but cannot be properly processed by almost half of the worlds population. It’s even found in some prenatal vitamins, which has been linked to miscarriages and postpartum depression. Not good!</p>
<p>I know this is kind of scary to read, but thankfully there is some good news. There are easy ways to work around this gene mutation and ensure you are thriving in life. Here’s what to do.</p>
<ul>
<li>Avoid all forms of folic acid, which limits your processed food intake, which is a major health win overall</li>
<li>Take the methylated version of folate, <a href="https://a.co/d/4TwoR4o">called 5-MTHF</a>, at night before going to bed</li>
</ul>
</section>
<section id="mtr" class="level3">
<h3 class="anchored" data-anchor-id="mtr">MTR</h3>
<p>Similar to MTHFR, the MTR gene also plays in a role in regulating homocysteine by converting it into another compound called methionine. For this reaction to work, your body needs vitamin B12, specifically the methylated versions of B12 like methylcobalamin or hydroxocobalamin.</p>
<p>If you have this gene mutation, you may experience certain gut issues like these.</p>
<ul>
<li>Gas</li>
<li>Bloating</li>
<li>Diarrhea</li>
<li>Constipation</li>
<li>Cramping</li>
</ul>
<p>Supplementing with B12 is crucial for this gene mutation, but similar to MTHFR not all supplements are created equal. Stay away from a form of B12 called Cyanocobalamin. This form contains hydrogen cyanide, which is a known neurotoxin. It’s often added into cheap energy drinks and even milk! Companies do this because it’s cheap and they don’t care, so care for yourself and avoid it at all costs.</p>
<p>Here’s what to do if you have this gene mutation.</p>
<ul>
<li>Limit alcohol, which depletes methyl donors and can interfere with B12 absorption</li>
<li>Avoid heavy metals (like mercury and lead) that bind to B12, making it unavailable for MTR to use</li>
<li>Take the methylated version of B12, either methylcobalamin or hydroxocobalamin found in <a href="https://a.co/d/fHQiO9z">methylated multivitamins</a>
<ul>
<li>FYI not everyone can process methylcobalamin, but 100% of humans can process hydroxocobalamin in their body</li>
<li>If you also have the COMT gene mutation, you absolutely should be taking hydroxocobalamin since your body can process that better than other forms like methylcobalamin</li>
</ul></li>
</ul>
</section>
<section id="mtrr" class="level3">
<h3 class="anchored" data-anchor-id="mtrr">MTRR</h3>
<p>This gene works closely with the MTR gene, hence similar names. It helps reactivate B12 that was used by the MTR gene when converting homocysteine into methionine. Over time B12 can become oxidized when used by the MTR gene, so MTRR comes in to convert it back into its methylated form so it can be properly used again. MTRR is also important in the thyroid, helping convert one important thyroid hormone T4 into T3, which happens in your gut.</p>
<p>If you have this gene mutation, you might suffer from the following.</p>
<ul>
<li>Heart burn</li>
<li>Acid reflux</li>
<li>Thyroid issues</li>
<li>Short temper</li>
<li>High blood pressure</li>
<li>Exacerbations of ADD, ADHD, OCD</li>
</ul>
<p>Follow the same guidelines as described in the MTR section above. Avoid the wrong types of B12 and make sure to take versions that your body can actually use.</p>
</section>
<section id="ahcy" class="level3">
<h3 class="anchored" data-anchor-id="ahcy">AHCY</h3>
<p>This gene helps break down S-Adenosylhomocysteine (SAH) into homocysteine and adenosine. This process is critical because SAH is a strong inhibitor of methylation enzymes. If it builds up, it slows down methylation reactions throughout the body. SAH is one of the most inflammatory compounds in your body, even worse than homocysteine.</p>
<p>This is a rare gene mutation to have, but people with it can have addictive tendencies. For example, addiction to video games as kids, then phones as teenagers, then drugs, alcohol, sugar, working out, eating, sex, shopping, working. This is caused by wide ranges in dopamine in the body, which is tied to our behaviors. So people with this mutation tend to seek out dopamine rewarding behavior.</p>
<p>Here’s what to do if you have this gene mutation.</p>
<ul>
<li>Consume collagen to ensure your ingesting enough glycine to help your body balance methionine. If AHCY isn’t efficiently breaking down SAH, excess methionine intake might lead to toxic byproducts instead of proper methylation.</li>
</ul>
</section>
<section id="comt" class="level3">
<h3 class="anchored" data-anchor-id="comt">COMT</h3>
<p>This gene breaks down major neurotransmitters in the body. Things like dopamine and adrenaline. It’s also responsible for metabolizing estrogens, and having too much of this hormone for both men and women can be bad. When your body can’t break these these things, all sorts of things get out of whack.</p>
<p>If you have this gene mutation, you might suffer from the following.</p>
<ul>
<li>Stress and anxiety</li>
<li>Trouble winding down and sleeping</li>
<li>Quick to anger, slow to calm down</li>
<li>Higher estrogen levels, which can lead to water retention under the belly button and around the waist</li>
<li>Pain sensitivity</li>
<li>ADD or ADHD</li>
</ul>
<p>Thankfully it’s not all bad with this gene mutation. Because things like dopamine stay around longer in your brain, it can lead to higher creativity and deep thinking. But this comes at a cost of overanalyzing and worrying.</p>
<p>Here’s what to do if you have this gene mutation.</p>
<ul>
<li>Avoid green tea and quercitin (found in green tea and other supplements) at all costs. These can make your COMT symptoms much worse.</li>
<li>If you have excess water retention around your belly, look into taking a <a href="https://a.co/d/8Af2hyP">diindolylmethane (DIM) supplement</a>, which can help reduce that water retention by removing excess estrogen in your body.</li>
<li>Consider taking a <a href="https://a.co/d/eZ5ui5I">trimethylglycine (TMG) supplement</a>, which can help regulate the processes that maintain your neurotransmitters</li>
</ul>
</section>
<section id="how-they-all-connect" class="level3">
<h3 class="anchored" data-anchor-id="how-they-all-connect">How They All Connect</h3>
<p>Processes in our body can be thought of like a group of construction workers passing sandbags to each other in a single line. One gene can do a process the body needs, then pass the output along to another gene to do another process, and so on. But if one of those genes can only pass along 4 sandbags instead of the 10 needed, then the most any of the downstream genes will get is 40% of what’s required.</p>
<p>This is why understanding genetic methylation in our bodies is so important. Each of these 5 genes play a crucial role in making our bodies work.</p>
<p>Let’s do a recap of each gene and what they do in our methylation process.</p>
<ol type="1">
<li>MTHFR starts the process by making active folate (5-MTHF)</li>
<li>MTR uses 5-MTHF &amp; B12 to convert homocysteine into methionine</li>
<li>MTRR keeps MTR working by recharging B12</li>
<li>AHCY clears out byproducts and provides fresh homocysteine</li>
<li>COMT uses methylation to break down stress chemicals and estrogen</li>
</ol>
<p>If any of these genes don’t work well, the whole system slows down! The fix is to support each gene with the right nutrients and to avoid things your body may not be able to handle.</p>
</section>
<section id="dna-testing" class="level3">
<h3 class="anchored" data-anchor-id="dna-testing">DNA Testing</h3>
<p>How the heck do I know if I have any gene mutations? This is where testing comes in. There are a lot of services out there that will do a genetic methylation test for you. They cost a few hundred dollars, but it’s a test you only need to run once in your life.</p>
<p>It’s a simple cheek swab you do at home then mail in. I used a service called <a href="https://10xhealthsystem.com/genetest/">10X Health</a>, but there are many providers out there who can help.</p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<p>I got my results back about a month ago, and things did not look good. I had mutations in all 5 genes except AHCY, with the MTHFR and COMT genes having the strongest mutation (meaning they don’t work). These results are kind of like getting a personality test result. You start to understand who you are as a person more. Why you act and feel a certain way. You start to understand your parents and siblings so much more, because they most likely carry similar genes as you. It’s life changing to receive information that shows you how to live a better life with 100% certainty.</p>
<p>My gene results showed that I had to really crack down on folic acid (MTHFR gene) and green tea/quercetin (COMT). I realized some of my most beloved foods and supplements, that are supposed to be healthy, actually contain things that are the worst to put into my body. Since cleaning those up I have had an easier time falling asleep, and my brain is working better than ever. It’s also been easier to avoid processed food, because I know almost all of it contains things that my body cannot handle well. So the temptation to binge on them has been removed. Thank goodness!</p>
<p>If you’d like to live up to your highest potential in life. Consider taking control of your genetics and get tested! It might just change your life. To learn more about genetic mythlation, <a href="https://www.youtube.com/@ultimatehumanpodcast">check out Gary Breka’s channel on YouTube</a>, he’s got tons of great info.</p>
<p><a href="https://www.shutterstock.com/search/watson-crick-dna-model?cr=bc&amp;gclid=c03f1496e24a1f3767de7343192784c5&amp;gclsrc=3p.ds&amp;image_type=illustration&amp;kw=shutterstock&amp;msclkid=c03f1496e24a1f3767de7343192784c5&amp;pl=PPC_BNG_US_DSA-&amp;utm_campaign=CO%3DUS_LG%3DEN_BU%3DIMG_AD%3DDSA_TS%3Dlggeneric_RG%3DAMER_AB%3DACQ_CH%3DSEM_OG%3DCONV_PB%3DMicrosoft-Ads&amp;utm_content=FF%3DDSA-All-Pages_AU%3DSite+Visitors&amp;utm_medium=cpc&amp;utm_source=bing&amp;utm_term=shutterstock">Photo Credit</a></p>


</section>

 ]]></description>
  <category>life</category>
  <category>health</category>
  <guid>https://mftokic.github.io/posts/2025-03-15-genetic-methylation/</guid>
  <pubDate>Sat, 15 Mar 2025 07:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-03-15-genetic-methylation/image.png" medium="image" type="image/png" height="86" width="144"/>
</item>
<item>
  <title>February Learnings</title>
  <dc:creator>Mike Tokic</dc:creator>
  <link>https://mftokic.github.io/posts/2025-03-01-february-learnings/</link>
  <description><![CDATA[ 





<p>I love reading books, watching YouTube videos, listening to podcasts, you name it. Anything learning related is my jam. But I realized that if I don’t take notes on what I’m learning, I will probably forget everything. Now when I hear something interesting, I write it down in an Apple note for that month. Below are some of the learnings I jotted down in February, summarized by ChatGPT with additional context added by their new deep research feature. I hope you find them as interesting as I did.</p>
<section id="ai-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="ai-machine-learning">AI &amp; Machine Learning</h2>
<section id="knowledge-distillation" class="level3">
<h3 class="anchored" data-anchor-id="knowledge-distillation">Knowledge Distillation</h3>
<ul>
<li><strong>AI Distillation:</strong> Process of transferring knowledge from a large, complex AI model (teacher) to a smaller, efficient model (student). Example: DeepSeek training their R1 model using GPT-4 answers as training data.</li>
</ul>
</section>
<section id="large-language-model-llm-architectures" class="level3">
<h3 class="anchored" data-anchor-id="large-language-model-llm-architectures">Large Language Model (LLM) Architectures</h3>
<ul>
<li><strong>Transformer Architecture:</strong> Neural network architecture characterized by self-attention mechanisms, enabling parallel processing and context awareness.</li>
<li><strong>Mixture of Experts (MoE):</strong> Architecture where subsets of neurons (“experts”) activate selectively per task, significantly reducing computational overhead and inference costs.</li>
</ul>
</section>
<section id="economics-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="economics-of-ai">Economics of AI</h3>
<ul>
<li><strong>Jevons Paradox:</strong> Lowering the cost of AI increases its usage dramatically.</li>
<li><strong>Token Costs:</strong> Input tokens (~¼ the cost of output tokens) allow parallel processing, whereas output tokens are sequential and auto-regressive.</li>
<li><strong>GPU Performance Factors:</strong> Critical aspects for AI training and inference are Floating-point operations (FLOPS), Memory bandwidth (IO), and Chip interconnectedness.</li>
<li><strong>Cost Evolution of AI Models:</strong> GPT-3 costs dropped drastically from ~$60 to ~$0.05 per million tokens between 2022 and 2024, a 1,200x reduction.</li>
</ul>
</section>
<section id="geopolitics-and-ai-chips" class="level3">
<h3 class="anchored" data-anchor-id="geopolitics-and-ai-chips">Geopolitics and AI Chips</h3>
<ul>
<li>Chinese companies circumvent U.S. Nvidia GPU export bans by routing purchases through third-party vendors in Singapore.</li>
<li><strong>DeepSeek Origin:</strong> Began as a spinoff of the Chinese hedge fund “High Flyer,” originally focused on GPU-based trading algorithms, later pivoting to AI models.</li>
</ul>
</section>
</section>
<section id="cognitive-performance-optimization" class="level2">
<h2 class="anchored" data-anchor-id="cognitive-performance-optimization">Cognitive &amp; Performance Optimization</h2>
<section id="most-important-question-miq-framework" class="level3">
<h3 class="anchored" data-anchor-id="most-important-question-miq-framework">Most Important Question (MIQ) Framework</h3>
<ul>
<li>Regularly clarify and revisit the single most critical, high-level question guiding your decisions, ensuring deep strategic alignment.</li>
</ul>
</section>
<section id="peak-performance-work-strategies" class="level3">
<h3 class="anchored" data-anchor-id="peak-performance-work-strategies">Peak Performance Work Strategies</h3>
<ul>
<li>Optimize intense, focused effort for fewer hours (3–5 hours/day) rather than prolonged mediocre sessions.</li>
<li>Reserve creative, high-focus tasks for peak-energy periods; routine tasks during lower-energy periods (e.g., noted dip around 2:30–3:30 pm).</li>
</ul>
</section>
<section id="mental-state-management" class="level3">
<h3 class="anchored" data-anchor-id="mental-state-management">Mental State Management</h3>
<ul>
<li>Leverage breathing techniques to control adrenaline and enhance decision-making speed and clarity.</li>
<li>Prioritize reflective time by avoiding immediate stimuli (e.g., smartphones) first thing in the morning.</li>
</ul>
</section>
<section id="quality-over-quantity" class="level3">
<h3 class="anchored" data-anchor-id="quality-over-quantity">Quality Over Quantity</h3>
<ul>
<li>Short bursts of deep work significantly outperform extended hours of moderate or distracted effort.</li>
</ul>
</section>
</section>
<section id="health-fitness" class="level2">
<h2 class="anchored" data-anchor-id="health-fitness">Health &amp; Fitness</h2>
<section id="training-principles" class="level3">
<h3 class="anchored" data-anchor-id="training-principles">Training Principles</h3>
<ul>
<li><strong>Optimal Training Splits:</strong> “Push-Legs-Pull” split recommended for optimal muscle recovery and growth.</li>
<li>Aim to train each muscle group twice weekly for maximal growth stimulus.</li>
<li>Understand the <strong>interference effect</strong>—heavy back workouts might negatively impact squatting performance the next day.</li>
</ul>
</section>
<section id="protein-intake-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="protein-intake-recommendations">Protein Intake Recommendations</h3>
<ul>
<li>Non-lifters: ~0.8 grams per pound of body weight daily.</li>
<li>Lifters aiming for muscle growth: ~1.3 grams per pound daily; significant growth benefit compared to lower intakes.</li>
</ul>
</section>
<section id="effective-supplements-for-muscle-gain" class="level3">
<h3 class="anchored" data-anchor-id="effective-supplements-for-muscle-gain">Effective Supplements for Muscle Gain</h3>
<ul>
<li>Creatine (improves strength and power), Protein powder (supports muscle recovery), Multivitamins (general health), Carb powders (Gatorade, Powerade for energy replenishment), Caffeine (enhances workout focus).</li>
</ul>
</section>
<section id="risks-of-sedentary-behavior" class="level3">
<h3 class="anchored" data-anchor-id="risks-of-sedentary-behavior">Risks of Sedentary Behavior</h3>
<ul>
<li>Prolonged sitting significantly increases mortality risk; offset by regular activity and frequent movement breaks.</li>
</ul>
</section>
<section id="behavioral-eating-habit-adjustment" class="level3">
<h3 class="anchored" data-anchor-id="behavioral-eating-habit-adjustment">Behavioral Eating Habit Adjustment</h3>
<ul>
<li>When stressed or craving food, first take a 30-minute walk to distinguish genuine hunger from stress-induced urges.</li>
</ul>
</section>
</section>
<section id="business-strategy" class="level2">
<h2 class="anchored" data-anchor-id="business-strategy">Business &amp; Strategy</h2>
<section id="new-product-strategy" class="level3">
<h3 class="anchored" data-anchor-id="new-product-strategy">New Product Strategy</h3>
<ul>
<li>Start by identifying core insights, fire small “test” bullets (low-risk experiments), and upon success, scale with larger, well-resourced “cannonballs.”</li>
</ul>
</section>
<section id="market-psychology" class="level3">
<h3 class="anchored" data-anchor-id="market-psychology">Market Psychology</h3>
<ul>
<li><strong>Osborn Effect:</strong> Announcing future products too early can stall current sales as customers delay purchasing decisions.</li>
<li><strong>Halo Effect:</strong> Successfully launching a new product enhances brand image, positively affecting the sales of existing products.</li>
</ul>
</section>
<section id="strategic-hiring-expert-filtering" class="level3">
<h3 class="anchored" data-anchor-id="strategic-hiring-expert-filtering">Strategic Hiring &amp; Expert Filtering</h3>
<ul>
<li>Identify talent by querying top performers for recommendations, refining the hiring funnel to focus on demonstrated capability and peer recognition.</li>
</ul>
</section>
<section id="economic-insights" class="level3">
<h3 class="anchored" data-anchor-id="economic-insights">Economic Insights</h3>
<ul>
<li><strong>GDP Growth Simplified:</strong> Driven by the productivity per worker and the total workforce.</li>
<li><strong>Idiot Index:</strong> Metric comparing raw material costs to finished product price, highlighting operational inefficiencies and pricing strategies.</li>
</ul>
</section>
</section>
<section id="historical-cultural-insights" class="level2">
<h2 class="anchored" data-anchor-id="historical-cultural-insights">Historical &amp; Cultural Insights</h2>
<section id="mongol-empire" class="level3">
<h3 class="anchored" data-anchor-id="mongol-empire">Mongol Empire</h3>
<ul>
<li>Exceptional warfare tactics: mobility, psychological intimidation, and merit-based leadership. Each soldier crafted their own bows, ensuring skill and accountability.</li>
<li>Mongol rule lasted until Soviet invasion (~1220–1920), marking the longest family-led empire in history.</li>
<li>Genghis Khan’s aggressive strategies rooted partly in personal revenge and necessity after familial trauma.</li>
</ul>
</section>
<section id="korean-language-origins-hangul" class="level3">
<h3 class="anchored" data-anchor-id="korean-language-origins-hangul">Korean Language Origins (Hangul)</h3>
<ul>
<li>Hangul invented explicitly due to difficulty in learning complex Chinese characters. Designed for rapid acquisition, enhancing widespread literacy.</li>
</ul>
</section>
<section id="stanfords-touchy-feely-class" class="level3">
<h3 class="anchored" data-anchor-id="stanfords-touchy-feely-class">Stanford’s “Touchy-Feely” Class</h3>
<ul>
<li>“Interpersonal Dynamics” at Stanford GSB teaches emotional intelligence, authentic communication, and relationship-building skills via experiential T-group sessions.</li>
<li>5 levels of communication
<ol type="1">
<li>Ritual: classic conversations like general greeting</li>
<li>Extended ritual: asking about the weather or a recent sports game</li>
<li>Content: facts about a project or work items</li>
<li>Emotional self-disclosure: saying how you feel emotionally (I feel sad)</li>
<li>Neutral emotional self-disclosure: expressing emotion at another person (I feel proud of you, angry at you, etc)</li>
</ol></li>
<li>To have strong relationships in life and career, you have to get to level 4 and 5</li>
</ul>
</section>
</section>
<section id="psychology-behavioral-science" class="level2">
<h2 class="anchored" data-anchor-id="psychology-behavioral-science">Psychology &amp; Behavioral Science</h2>
<section id="behavioral-loops-addiction" class="level3">
<h3 class="anchored" data-anchor-id="behavioral-loops-addiction">Behavioral Loops &amp; Addiction</h3>
<ul>
<li><strong>Scarcity Loop:</strong> Opportunity → Unpredictable reward → Quick repeatability drives addictive behaviors (gambling, social media).</li>
<li><strong>Near-Miss Effect:</strong> Close failures in gambling or gaming increase dopamine and repeat behaviors, driving addiction.</li>
</ul>
</section>
<section id="importance-of-courage" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-courage">Importance of Courage</h3>
<ul>
<li>Courage is central to achieving significant outcomes; talent and intelligence without courage lead to stagnation and regret.</li>
</ul>
</section>
<section id="nova-effect" class="level3">
<h3 class="anchored" data-anchor-id="nova-effect">Nova Effect</h3>
<ul>
<li>Sudden positive events (e.g., winning the lottery) can negatively impact perceived happiness afterward. Gradual progress allows better psychological adaptation.</li>
</ul>
</section>
</section>
<section id="miscellaneous-insights-notable-quotes" class="level2">
<h2 class="anchored" data-anchor-id="miscellaneous-insights-notable-quotes">Miscellaneous Insights &amp; Notable Quotes</h2>
<section id="philosophical-reflections" class="level3">
<h3 class="anchored" data-anchor-id="philosophical-reflections">Philosophical Reflections</h3>
<ul>
<li><strong>Success &amp; Failure:</strong> “Success is going from failure to failure without loss of enthusiasm.”</li>
<li><strong>Life Razor (Personal Decision Framework):</strong> Prioritize actions granting maximum control over personal time.</li>
<li><strong>Seasons of Life:</strong> Life priorities shift naturally through different life stages; adaptability is crucial.</li>
<li><strong>Learning &amp; Reflection:</strong> True learning arises when experience intersects with thoughtful reflection.</li>
</ul>
</section>
<section id="intriguing-observations" class="level3">
<h3 class="anchored" data-anchor-id="intriguing-observations">Intriguing Observations</h3>
<ul>
<li>Diamonds priced disproportionately at milestone sizes (2-carat vs.&nbsp;1.99-carat).</li>
<li>Chronic strep throat indicates potential mold exposure.</li>
<li>Epstein-Barr virus (mono) infection necessary precursor for multiple sclerosis.</li>
<li>Icelandic dating app created by the government prevents accidental familial relationships.</li>
<li>Drug companies advertise heavily on news networks, indirectly shaping media narratives.</li>
</ul>
</section>
<section id="notable-quotes" class="level3">
<h3 class="anchored" data-anchor-id="notable-quotes">Notable Quotes</h3>
<ul>
<li><em>“Your life is in your hands; don’t drop it.”</em></li>
<li><em>“The generation that lights the fuse usually gets buried in the rubble.”</em></li>
<li><em>“Be interested, not interesting.”</em><br>
</li>
<li><em>“If more money wouldn’t change how you spend your time, you’re already rich.”</em><br>
</li>
<li><em>“Your health at age 80 is a reflection of your relationships at age 50.”</em></li>
</ul>


</section>
</section>

 ]]></description>
  <category>life</category>
  <category>learning</category>
  <guid>https://mftokic.github.io/posts/2025-03-01-february-learnings/</guid>
  <pubDate>Sat, 01 Mar 2025 08:00:00 GMT</pubDate>
  <media:content url="https://mftokic.github.io/posts/2025-03-01-february-learnings/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
