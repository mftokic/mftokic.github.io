---
title: "Time Series First Principles: The Future Is Similar To The Past"
description: "If you expect the future to be drastically different than past data, you will have a hard time training accurate models"
author: "Mike Tokic"
date: "2024-04-10"
categories: [time-series, machine-learning, finance]
image: "image.png"
---

![](./image.png)

### Time Series First Principles Series

This post dives into the third principle of a good time series forecast, the future is similar to the past. Check out the [initial post](https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/) in this series to get a high level view of each principle. 

1. [Domain Expertise](https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/)
2. [Garbage In Garbage Out](https://mftokic.github.io/posts/2024-04-08-time-series-garbage/)
3. **The Future Is Similar To The Past**
4. Higher Grain Higher Accuracy
5. Order Is Important
6. The Magic Is In The Feature Engineering
7. Simple Models Are Better Models
8. Capture Uncertainty
9. Model Averages Are King
10. Deep Learning Last

### Here Comes The Sun 

This principle is very straightforward. For whatever you're trying to forecast, it will be a lot easier to do with with machine learning (ML) if the future is similar to the past. 

When you open the weather app on your phone, have you ever looked at when the sun is expected to rise and set? If you're on the new human optimization craze about getting morning sunlight, you most likely have. That forecast is down to the minute, most likely even second, and has a high degree of accuracy. Is the forecast accurate because of expert human judgement, or the type of weather related features fed into a ML model? Nope. It's accurate because the sun has risen and set at relatively the same time, based on time of year, for millions of years. We don't expect future sun rises and sun sets to change that much going forward, that's why your weather app gives you an exact time for the sun rise but gives you only a percent probability of rain. Even then that chance of rain may not even be accurate. It's almost a joke now how many times in Seattle I've seen a dry forecast only to step out of my house and have it immediately start raining. At least I know the exact minute when the sun will set that day. 

### Handling A Changing Future

Your business is most likely not like the sun. It's constantly changing, reacting to market forces and industry competitors. The best way to teach a model about your expectations of the future is to give it data about the past and future. 

Let's use an example of a monthly revenue forecast for a product. If you only use historical sales data to forecast the product, then you are making the assumption that the future of the product will be almost identical to the past, especially the most recent past. For some established products in mature industries this could be totally fine, but often this is not the case. 

One thing to try is adding features that can help explain how outside forces impact the product. For example, how much money consumers have to spend might greatly impact who buys your product. So using an economic feature like consumer sentiment can help a model to adjust it's predictions based on changes in consumer spending habits. 

We can add features into our data in two ways. The first is to just give historical values of that feature. This will force us to only use historical lags of the feature when training a ML model, since we don't know what the future value of that feature will be. We can take that original feature and create new features (this is called feature engineering). Ones that are a 3 month lag, 6 month lag, or 12 month lag of the original data. Often macro data like consumer sentiment can be a lagging indicator. Meaning their impact is delayed and takes a while to flow through the economy. Changes in consumer sentiment from 6 months ago can actually have a strong correlation with how customers purchase our product today. 

A second way is to use both historical values and future values. We could use a future forecast of consumer sentiment in our model, in addition to using the historical data. That way a model can learn from any lagged relationships as well as understand how changes in consumer sentiment impact our product in real time. These future values can either come from an expert forecast (like from famous economists) or created by your own ML solution. 

### The Future Always Must Learn From The Past

You might have a ton of ideas for new kinds of future information your can encode as features to train a model. In order to use this data we need to make sure there are historical examples for a model to learn from. The upcoming 2024 presidential election in the US could have a large impact on your business, which will impact your future forecast for the rest of 2024. We know exactly when the election is going to happen, so it's easy to give that information into a ML model to learn from. 

The catch is we need to make sure that we show examples from the past to allow the model to learn how did previous elections impact our business and how the model should handle similar events in the future. If we only have product sales data from the last three years, then we cannot feed it future election data because we don't have the data from the 2020 or 2016 presidential elections. 

If we know something is going to happen in the future, but we can't quantify it with historical data for a model, then we need to go old school. Instead we need to use our domain expertise about the business to take the ML output, without knowledge of the future event, and make a manual adjustment to the forecast based on the expected impact of the future. For the election example, maybe your product sales will grow as we get closer to the election, so if you don't have enough historical data for a model to learn about the election's impact you can make a manual adjustment to the ML forecast based on your assumption about the election's impact. 

This kind of hybrid approach, ML first with a light human touch second, can create a powerful combination. A ML model can do 80-90% of the initial work and a human can make the final adjustments based on their domain expertise. This allows a human to add more insight into a forecast that is not easily quantifiable for a ML model to learn from. 

### New Time Series

A new product at your company might be exciting, but is harder to forecast accurately with ML models. The lack of historical data will make it hard for any new ML model to learn from. Initial trends and seasonality may not always carry into the future. For example there might be a big spike in initial sales around release but then taper off over time. The new product may not even be on sale yet, so you are now tasked with forecasting something with zero historical data. 

If the time series in question has some historical data, ideally more than one historical observation, a good way to deal with it is to train a ML model with the new time series alongside similar existing products with a lot of historical data. This is sometimes called a "global model", where a model learns from multiple time series instead of one. Training on one specific time series is sometimes called a "local model". Training a global model allows the ML model to learn general trends and seasonality patters across similar time series and apply it to the newer time series. 

### Reversal

Wrong future feature values compound forecast inaccuracy. 

Manual adjustments add human bias that can hurt accuracy. 

### Final Thoughts
