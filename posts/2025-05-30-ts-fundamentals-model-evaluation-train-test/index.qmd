---
title: "Model Evaluation: Train Test Splits"
description: "Analyzing how your forecast performs on unseen data"
author: "Mike Tokic"
date: "2025-05-30"
categories: [machine-learning, time-series]
image: "image.png"
draft: True
---

*This post is part of the [model evaluation chapter](https://mftokic.github.io/posts/2025-05-13-ts-fundamentals-model-evaluation/) within a larger learning series around time series forecasting fundamentals. [Check out the main learning path](https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/) to see other posts in the series.* 

*The example monthly data used in this series [can be found here.](https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv) You can also find the [python code used in this post here.](https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2025-05-30-ts-fundamentals-model-evaluation-train-test-split.ipynb*

### Building Trust In The Forecast

Let's say your companies CFO is asking you, the hotshot data & AI person, to produce a revenue forecast for the next 12 months. The CFO needs this forecast to communicate expectations to wall street, help optimize product inventory, and make future capital allocation decisions based on where the business is headed the next year. You take a model like ARIMA off the shelf and produce that 12 month forecast, shown below using a time series from our example dataset. Let's take a look. 

![](./chart1.png)

The future 12 month forecast seems to capture the seasonality from month to month, and even the upward trend. You show the results to the CFO, even calling out the 95% prediction interval, which shows the upper of lower bounds with 95% certainty that the future revenue values are likely to fall in between. The CFO looks at it for one second, then says "so what", I can't use this forecast. How do I know it's accurate, this is a black box. You're hopes and dreams, including that potential promotion, are now crushed. Congrats, you learned one of your first hard lessons in the forecast game. **Building trust in the forecast is harder than creating one in the first place.** It might take seconds to train an ARIMA model, but convincing people to use it might take years. 

Hang on a second, you just remembered in our chapter covering [univariate models](https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/) that there is this thing called a residual, which allows you to see historical forecasts on the training data.

### Residuals

Let's calculate the residuals for the ARIMA model we trained and plot them on a nice chart. 

insert chart. 

Calculating residuals, visualizing residuals, summarizing residuals (first evaluation metric, MAE)

### Train vs Test Data

Importance of hold out data. Having a model generalize well to future unseen data. In sample vs out of sample. How to split the data by time.  

### Final Thoughts


### Learn More