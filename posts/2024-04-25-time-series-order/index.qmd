---
title: "Time Series First Principles: Order is Important"
description: "When time is involved, how your data is ordered makes all the difference"
author: "Mike Tokic"
date: "2024-04-25"
categories: [time-series, machine-learning, finance]
image: "image.png"
draft: true
---

![](./image.png)

### Time Series First Principles Series

This post dives into the fifth principle of a good time series forecast, order is important. Check out the [initial post](https://mftokic.github.io/posts/2024-03-26-time-series-first-principles-initial/) in this series to get a high level view of each principle. 

1. [Domain Expertise](https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/)
2. [Garbage In Garbage Out](https://mftokic.github.io/posts/2024-04-08-time-series-garbage/)
3. [The Future Is Similar To The Past](https://mftokic.github.io/posts/2024-04-11-time-series-past-future/)
4. [Higher Grain Higher Accuracy](https://mftokic.github.io/posts/2024-04-18-time-series-grain/)
5. **Order Is Important**
6. The Magic Is In The Feature Engineering
7. Simple Models Are Better Models
8. Capture Uncertainty
9. Model Averages Are King
10. Deep Learning Last

### Baking Cakes Over Making Smoothies

Machine learning (ML) is a lot like cooking. You have various ingredients and you can combine them together in clever ways to make for a tasty dish. Most machine learning approaches like classification (predicting an outcome) and regression (predicting a number) can follow a similar process to making a smoothie. Where we can take some data (fruits and veggies) and blend it all together inside of our model blender. 

Time series forecasting is a whole other beast. It still technically falls under the regression family tree but has to be handled very differently. Forecasting is more like baking a cake, where the order in which you do things is very important. For example, you cannot switch when you add the eggs and when you add the frosting. If you do you will certainly not be invited back to your nephew's birthday party next year. In order to bake something tasty please follow the below guidance. 

### Time Series Training

Training any sort of machine learning model often requires two separate historical data sets. One that is used to train the initial model, then another that is set aside to create predictions based on the initial model. We can then see how accurate the predictions were on the test data set. This ensures that our new ML model can generalize well to new and unseen data. Making sure our model doesn't overfit to the training data. 

Common ML approaches like classification and regression don't need a lot of sophistication when splitting up the historical data between a training set and a testing set. Often it will be split randomly. This is similar to making a smoothie. You can randomly throw in bananas, apples, spinach, and blueberries. All without having to think about the oder of when you do it. 

Take the below housing data. This is a traditional regression problem. Where we can use the total square feet and number of bedrooms to predict how much the house will cost. We can randomly split 80% of the data to train the model, then hold out 20% of the data to test how accurate the model is. We can randomly split the data to ensure we can a healthy mix of different data in each split.

| Square_Feet | Bedrooms | Total_Cost | Split    |
|-------------|----------|------------|----------|
| 3774        | 2        | 822732     | Training |
| 1460        | 1        | 245280     | Training |
| 1894        | 4        | 602292     | Training |
| 1730        | 4        | 550140     | Training |
| 1695        | 4        | 539010     | Testing  |
| 3692        | 5        | 1358656    | Training |
| 2238        | 1        | 375984     | Training |
| 2769        | 5        | 1018992    | Training |
| 1066        | 5        | 392288     | Testing  |
| 1838        | 1        | 308784     | Training |

: Example fake housing data for a regression model

A time series has a built in order to it. It's said right there in the name, time. Ignoring the order based on time can have disastrous consequences, resulting in your final future forecast not being accurate. Just like baking a cake we need to make sure how we train a model is done in the right order. When splitting a historical time series into a training set and a testing set, splitting not at random but based on time is the proper way to go. Using the oldest data as the training set and the newest data as the testing set makes sure we respect the order of our data based on time. The example table below 

| Date           | Interest_Rate | GDP_Growth | Total_Cost |
|----------------|---------------|------------|------------|
| January 2002   | 3.43635       | 1.58111    | 315052     |
| February 2002  | 4.87679       | 0.03085    | 314723     |
| March 2002     | 4.32998       | -0.04544   | 312854     |
| April 2002     | 3.99665       | -0.04149   | 311865     |
| May 2002       | 2.89005       | 0.26061    | 309452     |
| June 2002      | 2.88999       | 0.81189    | 311106     |
| July 2002      | 2.64521       | 0.57986    | 309675     |
| August 2002    | 4.66544       | 0.22807    | 314681     |
| September 2002 | 4.00279       | 1.02963    | 315097     |
| October 2002   | 4.27018       | -0.15127   | 312357     |
| November 2002  | 2.55146       | 0.23036    | 308345     |
| December 2002  | 4.92477       | 0.41591    | 316022     |

: Example fake time series for the price of a specific house

### Data Leakage

### finnts

### Final Thoughts
