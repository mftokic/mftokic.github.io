---
title: "Univariate Models: Simple Benchmark Models"
description: "Creating simple models to benchmark against complex ones"
author: "Mike Tokic"
date: "2025-05-30"
categories: [machine-learning, time-series]
image: "image.png"
draft: True
---

*This post is part of the [univariate models chapter](https://mftokic.github.io/posts/2025-03-24-ts-fundamentals-univariate-models/) within a larger learning series around time series forecasting fundamentals. [Check out the main learning path](https://mftokic.github.io/posts/2024-09-25-ts-fundamentals/) to see other posts in the series.* 

*The example monthly data used in this series [can be found here.](https://github.com/mftokic/mftokic.github.io/blob/main/posts/2024-10-02-ts-fundamentals-whats-a-time-series/example_ts_data.csv) You can also find the [python code used in this post here.](https://github.com/mftokic/mftokic.github.io/blob/main/notebooks/2025-04-30-ts-fundamentals-univariate-ets.ipynb)*

### What Are Benchmark Models?  

A benchmark model is a simple model that can be used as a forecast or to compare its forecast outputs against another model that is more complex. These models do not incorporate statistical or machine learning methods, instead they use standard formulas to produce forecasts. 

### Type of Benchmark Models

There are three main benchmarking models we'll discuss today. They are many other models/methods that can be used as benchmarks but these are the three most common. 

- **Mean Forecast**
    - Simple average of the last few periods of the time series. You could take the average of the last 12 months and use that as the forecast, the time period you use to create the average is up to you. 
- **Naive Forecast**
    - Take the last value in the time series and use that as the forecast. This is the simplest forecast method possible, that's why it's called "naive".
- **Seasonal Naive Forecast**
    - Similar to the naive method, but you take the value from the previous season and use that as the forecast. For example with monthly data, next months forecast could be the value for that month in the previous year. 

### Let's Create a Forecast

Let's take one of our example time series and create these benchmark forecasts. 

![](./chart1.png)

Looks like our future forecast for each model does not look good. No trends were captured, same goes for seasonality outside of the seasonal naive model. These models produced future forecasts, just none that we want to use for our final forecast. 

### How to Use Them

Benchmark models can be ran first when starting a new forecast project to establish a simple baseline of accuracy for more advanced models to beat. You might build a fancy neural network model from scratch, but it may have the same accuracy as a dumb seasonal naive model. So starting with benchmark models first is always a good idea. 

Another interesting way you can use benchmark models is by removing the trend and seasonal components through differencing before running these models. By [making the data stationary](https://mftokic.github.io/posts/2025-03-21-ts-fundamentals-data-cleaning-stationary/), we can allow simple benchmark models to work their magic on the cleaner data to produce more robust forecasts. Let's try each method of differencing and see how it impacts the benchmark forecasts. Also it's important to note that after we create the forecast on the differenced data, we need to undifference the data to return it back to its original scale. 



Running benchmarks on differenced data. 

### Other Benchmark Methods

### Final Thoughts

### Learn More 

https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#windowaverage