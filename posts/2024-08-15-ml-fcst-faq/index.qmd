---
title: "FAQ on Machine Learning Forecasting"
description: "Straightforward answers to all of your ML forecast questions"
author: "Mike Tokic"
date: "2024-08-15"
categories: [finance, machine-learning, forecasting]
image: "image.png"
draft: true
---

Over the last few years I've presented to hundreds of people outside of Microsoft around how we approach machine learning (ML) forecasting within Microsoft finance. A lot of great questions were asked during those conversations. With many overlaps around common themes. In this post I want to highlight some of the most commonly asked questions and my take on answering them. Hopefully this can be a quick reference for anyone ML curious or want to deepen the ML work being done on their teams. Use the table of contents to skip around to the sections you're most interested in. If there are any topics missing please reach out to me and I will continue to update this post. 

## FAQ Table of Contents {#toc}

### [Data](#data)

- [Getting high quality historical data](#historical-data)
- [Using third party data](#third-party-data)
- [New info not found in the training data, one time events](#one-time-events)
- [Handling outliers](#outliers)

### [Technical](#technical) 

- [Interpreting the black box](#black-box)
- [What models to use, should we use deep learning](#models)
- [What programming language or framework to use](#language)
- [Using large language models like ChatGPT to forecast](#llm)
- [What level of accuracy is good](#accuracy)

### [Humans](#humans)

- How to make forecast owners accountable for the ML number
- Building Trust in the ML forecast
- Who owns the ML creation process 
- How to get started with ML
- Going from ML as a triangulation point to replacing manual human forecasts
- Building data science talent in finance

## Data {#data}

### Getting high quality historical data {#historical-data}

[Garbage in, garbage out](https://mftokic.github.io/posts/2024-04-08-time-series-garbage/). That's probably the most common saying in the world of ML. If you cannot get high quality historical data, then there is no easy way to produce an accurate ML forecast. You can't work your way around noisy or incomplete data. If your data is messy, hard to find, and comes from 10 different systems, then ML is not something you should be worried about. Fix your data first, then focus on using that data in combination with other things like ML. A nice bow on top of a pile of crap is still a pile of crap. Fix your data first, then focus on ML after.  

[Back to Table of Contents](#toc)

### Using third party data {#third-party-data}

Your company's business is most likely impacted by greater market forces outside of your control. For example the health of the economy or how much money customers have to spend. Adding data from outside of your company (third party data) as features in your ML models is a good way to improve forecast accuracy, while also being able to describe what outside forces impact your business the most. Some data is freely available, while others have to be paid for. What data you use is up to your domain knowledge of your business.

Free Data

- [FRED](https://fred.stlouisfed.org/)
- [World Bank](https://data.worldbank.org/)
- [International Monetary Fund](https://data.imf.org/?sk=388dfa60-1d26-4ade-b505-a05a558d9a42)
- [United Nations](https://data.un.org/)
- [Google Trends](https://trends.google.com/trends/)

Paid Data

- [IDC](https://www.idc.com/data-analytics)
- [Trading Economics](https://tradingeconomics.com/indicators)

[Back to Table of Contents](#toc)

### New info not found in training data and one time events {#one-time-events}

If you are changing the price of your product in three months, this is most likely going to impact your future revenue forecast. But if you have never changed the price of your product before, then a ML model cannot learn from that information. For a model to learn from one time events, it needs to be present in the historical data a model is trained on. [The future must always learn from the past](https://mftokic.github.io/posts/2024-04-11-time-series-past-future/).

[Back to Table of Contents](#toc)

### Handling Outliers {#outliers}

[Outliers](https://mftokic.github.io/posts/2024-04-11-time-series-past-future/) in your data can have a bad impact on your future forecast. It can hurt accuracy or give false signals of the future. There are many ways to deal with outliers. The easiest way is to use statistical methods to identify and remove them. Treating them as a missing value you can then replace. Sometimes outliers are more subtle, and take a trained eye to spot them. This is where the [domain expertise](https://mftokic.github.io/posts/2024-04-02-time-series-domain-expertise/) of a person comes into play. 

[Back to Table of Contents](#toc)

## Technical {#technical}

### Interpreting the black box {#black-box}

This one is a toughie. When a person creates a forecast manually, most often using excel, someone else can come into that financial model and trace cell by cell exactly what's going on. Going from input data, to assumptions, to the formulas that create the final output. This is the kind of exactitude that allows accountants to sleep peacefully at night. Everything is in order and everything is perfectly understood. But we are not accountants. This is finance. We have to make calls about the future that are uncertain. We can never have 100% certainty that something is going to happen. If that's the case then your company is doing something illegal. Get out now!

The biggest paradigm shift someone has to make with machine learning is giving up this total control of the forecast. And in essence take a [leap of faith](https://mftokic.github.io/posts/2024-07-15-msft-ml-fcst-journey-3/#leap-of-faith). Machine learning models are enigmas. Sometimes akin to magic. The cannot be perfectly understood because the capture non-linear relationships in data that a human never could. That's why we have them, because they can work better and faster than our human brains in some tasks. 

There are ways to understand these models, but they cannot be perfectly audited like a manual forecast done in excel. Instead they have to be interrogated. Not like a criminal wanted for war crimes but more like a therapist talking to their patient. There is no way to know exactly what's going on inside of their patients mind. But they can start to ask questions that can give clues into what's going on and see why the person has past decisions in their life. 

The best resource I know on explaining ML models is [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) by Christoph Molnar. Here's a quick overview of the method's described in the book. 

- **Model Specific:** These are models like linear regression or a single decision tree where we can see exactly what's going on under the hood. The model structure is more like an excel formula we can trace step by step. But because they are easy to explain, they are simple in nature and may not produce the most accurate forecast. That is the tradeoff between having a forecast that can be easily explained versus having a forecast that is the most accurate. The more accurate the forecast, the more likely you cannot explain it perfectly. 
- **Model Agnostic:** For more advanced models like gradient boosted trees and deep learning, we can use methods that approximate what's going on under the hood of a complex model. This is when we have to act like a therapist and start asking questions to our model and see what answers it gives back. There are two ways of doing this. 
    - **Global Interpretability:** This uses methods that can see overall what's impacting the model the most. For example you can see what input variable (or feature) is the most important in the model overall.  
    - **Local Interpretability:** This uses methods to see what's going on for each individual forecast data point. For example you can see for a specific future forecast what's impact that number the most. 

The last thought I'd leave you with is this. Have you ever not used ChatGPT because you couldn't get an explanation of its answer? For example maybe you asked it to help you write some excel formulas to format dates. Do you trust the output it gave you because the excel formula was correct or because it could tell you exactly how it came to that conclusion? What if the explanation it gave was made up or a hallucination? If the excel formula is correct you would still use it right? Even the CEO of OpenAI, Sam Altman, cannot explain how models like GPT-4 think under the hood. But hey, ChatGPT was still the fastest growing product of all time. Sometimes imperfect interpretability is ok. But maybe your CEO is demanding an explanation of the forecast numbers, so this is [still a hard problem to solve in finance](https://mftokic.github.io/posts/2023-02-11-three-levels-of-ml-adoption/).  

[Back to Table of Contents](#toc)

### What models to use, should we use deep learning {#models}

### What programming language or framework to use {#language}

### Using large language models like ChatGPT to forecast {#llm}

### What level of accuracy is good {#accuracy}

## Humans {#humans}

### Test